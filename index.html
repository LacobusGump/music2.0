<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>GUMP</title>
    <style>
        *{margin:0;padding:0;box-sizing:border-box}
        body{background:#000;overflow:hidden;touch-action:none;height:100vh}
        canvas{position:fixed;inset:0}
        #enter{position:fixed;inset:0;display:flex;align-items:center;justify-content:center;z-index:10;cursor:pointer}
        #enter.off{opacity:0;pointer-events:none;transition:opacity 2s}
        #enter div{width:120px;height:120px;border-radius:50%;border:1px solid rgba(255,255,255,0.1);display:flex;align-items:center;justify-content:center;font:9px system-ui;letter-spacing:4px;color:rgba(255,255,255,0.25);transition:0.5s}
        #enter:hover div{border-color:rgba(255,255,255,0.3);color:rgba(255,255,255,0.5)}
    </style>
</head>
<body>
<div id="enter"><div>ENTER</div></div>
<canvas id="c"></canvas>
<script>
// GUMP - Grand Unified Music Project
// EMERGENT DELICACY: Silence → One Voice → Layers Build One by One
// "The music must emerge from chaos as the highest probability path to sounding good"

const TAU = Math.PI * 2;

// ============ THE UNIVERSE ============

let ctx, master, verb, dly;
let canvas, vc;
let running = false;

// Field state (cursor position, tilt)
let field = {
    x: 0.5, y: 0.5,      // Normalized position (0-1)
    vx: 0, vy: 0,        // Velocity
    energy: 0,           // Movement energy
    time: 0,
    // PREDICTION: Where we think the user is GOING
    px: 0.5, py: 0.5,    // Predicted position (100ms ahead)
    predictionError: 0,   // How wrong our last prediction was (0-1)
    predictionTension: 0, // Musical tension from wrong predictions
    lastPredictedX: 0.5,  // What we predicted last frame
    lastPredictedY: 0.5,
    // Orb state
    orb: {
        active: false,    // Is an orb currently visible?
        x: 0, y: 0,       // Orb position
        freq: 220,        // Current frequency based on tilt
        predictedFreq: 220, // Where we PREDICT the pitch will be
        startTime: 0,     // When orb spawned
        velocity: 0.3     // How fast orb moves toward center
    }
};

// ============ THE LAYER SYSTEM ============
// Each layer is a recorded loop of pitch + timing
// Layers build ONE BY ONE through user action

const BASE_FREQ = 110; // A2 - foundation frequency
const MAX_LAYERS = 8;  // Maximum concurrent layers

let layers = [];      // Array of recorded layers
let activeVoice = null; // The SINGLE voice that follows tilt (before recording)

// ============ THE BEAT GRID ============
// THIS IS WHAT WAS MISSING: A common time structure for all layers
// Without this, layers loop independently = polyrhythmic chaos
// With this, layers align to a shared pulse = MUSIC

const BEAT = {
    BPM: 72,                    // Slow, meditative tempo (adjustable through movement)
    MIN_BPM: 50,                // Minimum tempo
    MAX_BPM: 120,               // Maximum tempo
    BARS: 4,                    // Phrase length in bars (4 = 8 seconds at 72 BPM)
    BEATS_PER_BAR: 4,           // Time signature: 4/4
    SUBDIVISIONS: 4,            // 16th note quantization
    QUANTIZE_STRENGTH: 0.8,     // How strongly notes snap to grid (0 = free, 1 = rigid)
    TEMPO_SMOOTH: 0.98,         // How slowly tempo changes (0.98 = very gradual)
    TEMPO_SENSITIVITY: 0.3,     // How much movement affects tempo
};

let beatState = {
    bpm: BEAT.BPM,              // Current tempo
    phase: 0,                   // Current position in the beat cycle (0-1)
    beat: 0,                    // Current beat number (0-15 for 4 bars of 4/4)
    lastBeatTime: 0,            // When the last beat occurred
    beatInterval: 60 / BEAT.BPM, // Seconds per beat
    barPhase: 0,                // Position within current bar (0-1)
    phrasePhase: 0,             // Position within the phrase (0-1)

    // Tempo tracking from user movement
    movementTaps: [],           // Timestamps of significant movements
    detectedTempo: null,        // User's natural tempo (if detected)
    tempoConfidence: 0,         // How confident we are in detected tempo

    // Visual pulse
    pulseIntensity: 0,          // For visual feedback
};

// Calculate beat-aligned loop length
function getQuantizedLoopLength(rawLength) {
    const beatDuration = 60 / beatState.bpm;
    const barDuration = beatDuration * BEAT.BEATS_PER_BAR;

    // Find the nearest musical loop length (1, 2, or 4 bars)
    const bars = rawLength / barDuration;

    let quantizedBars;
    if (bars < 1.5) {
        quantizedBars = 1;       // 1 bar loop
    } else if (bars < 3) {
        quantizedBars = 2;       // 2 bar loop
    } else {
        quantizedBars = 4;       // 4 bar loop
    }

    return quantizedBars * barDuration;
}

// Quantize a timing to the beat grid
function quantizeToGrid(time, strength = BEAT.QUANTIZE_STRENGTH) {
    const beatDuration = 60 / beatState.bpm;
    const subdivision = beatDuration / BEAT.SUBDIVISIONS;

    // Find nearest subdivision
    const nearestSubdiv = Math.round(time / subdivision) * subdivision;

    // Blend between raw and quantized based on strength
    return time * (1 - strength) + nearestSubdiv * strength;
}

// Update the beat state every frame
function updateBeat(dt) {
    // Update phase
    const prevPhase = beatState.phase;
    beatState.phase += dt / beatState.beatInterval;

    // Beat occurred?
    if (Math.floor(beatState.phase) > Math.floor(prevPhase)) {
        beatState.beat = (beatState.beat + 1) % (BEAT.BARS * BEAT.BEATS_PER_BAR);
        beatState.lastBeatTime = field.time;
        beatState.pulseIntensity = 1;

        // On beat 0 (start of phrase), could trigger events
        if (beatState.beat === 0) {
            // Start of new phrase - good moment for changes
        }
    }

    // Keep phase in range [0, 1] for current beat
    beatState.phase = beatState.phase % 1;

    // Calculate bar and phrase phase
    const totalBeats = BEAT.BARS * BEAT.BEATS_PER_BAR;
    beatState.barPhase = (beatState.beat % BEAT.BEATS_PER_BAR + beatState.phase) / BEAT.BEATS_PER_BAR;
    beatState.phrasePhase = (beatState.beat + beatState.phase) / totalBeats;

    // Decay pulse
    beatState.pulseIntensity *= 0.85;

    // ============ TEMPO ENTRAINMENT ============
    // Detect user's natural tempo from their movement patterns
    // If they're moving rhythmically, the system adjusts to match

    // Track significant movements as "taps"
    if (field.energy > 0.1) {
        const now = field.time;
        const lastTap = beatState.movementTaps[beatState.movementTaps.length - 1];

        // Only count as a new tap if enough time has passed
        if (!lastTap || now - lastTap > 0.2) {
            beatState.movementTaps.push(now);

            // Keep only recent taps (last 8 seconds)
            while (beatState.movementTaps.length > 20 &&
                   now - beatState.movementTaps[0] > 8) {
                beatState.movementTaps.shift();
            }
        }
    }

    // Analyze taps to detect tempo
    if (beatState.movementTaps.length >= 4) {
        const intervals = [];
        for (let i = 1; i < beatState.movementTaps.length; i++) {
            const interval = beatState.movementTaps[i] - beatState.movementTaps[i - 1];
            if (interval > 0.25 && interval < 2) { // Reasonable beat intervals
                intervals.push(interval);
            }
        }

        if (intervals.length >= 3) {
            // Use median for robustness
            intervals.sort((a, b) => a - b);
            const medianInterval = intervals[Math.floor(intervals.length / 2)];
            const detectedBpm = 60 / medianInterval;

            // Only accept if in reasonable range
            if (detectedBpm >= BEAT.MIN_BPM && detectedBpm <= BEAT.MAX_BPM) {
                beatState.detectedTempo = detectedBpm;

                // Calculate confidence based on consistency
                const avgInterval = intervals.reduce((a, b) => a + b) / intervals.length;
                const variance = intervals.reduce((sum, i) => sum + Math.pow(i - avgInterval, 2), 0) / intervals.length;
                const stdDev = Math.sqrt(variance);
                beatState.tempoConfidence = Math.max(0, 1 - stdDev * 2);
            }
        }
    } else {
        // Not enough data - decay confidence
        beatState.tempoConfidence *= 0.99;
    }

    // Gradually entrain to detected tempo
    if (beatState.detectedTempo && beatState.tempoConfidence > 0.3) {
        const targetBpm = beatState.detectedTempo;
        const entrainStrength = beatState.tempoConfidence * BEAT.TEMPO_SENSITIVITY;
        beatState.bpm = beatState.bpm * (1 - entrainStrength * 0.01) + targetBpm * (entrainStrength * 0.01);
    } else {
        // Drift back toward default tempo when user isn't establishing rhythm
        beatState.bpm = beatState.bpm * 0.999 + BEAT.BPM * 0.001;
    }

    // Clamp BPM
    beatState.bpm = Math.max(BEAT.MIN_BPM, Math.min(BEAT.MAX_BPM, beatState.bpm));

    // Update beat interval
    beatState.beatInterval = 60 / beatState.bpm;
}

// Layer structure:
// {
//   id: number,
//   freq: number,           // The pitch of this layer
//   startTime: number,      // When in the loop it plays
//   loopLength: number,     // How long the loop is (in seconds)
//   osc: OscillatorNode,
//   gain: GainNode,
//   filter: BiquadFilterNode,
//   recorded: boolean,      // Has this been recorded (or still live)?
//   volume: number          // 0-1, decreases with each layer
// }

// ============ MUSIC THEORY: HARMONIC PROBABILITY ============
// New layers should HARMONIZE with existing layers
// The system predicts what will sound GOOD

// Just intonation ratios - these are the "legal" intervals
const CONSONANT_RATIOS = [
    { ratio: 1,     name: 'unison',   consonance: 1.0 },
    { ratio: 2,     name: 'octave',   consonance: 0.95 },
    { ratio: 3/2,   name: 'fifth',    consonance: 0.9 },
    { ratio: 4/3,   name: 'fourth',   consonance: 0.85 },
    { ratio: 5/4,   name: 'maj3',     consonance: 0.8 },
    { ratio: 6/5,   name: 'min3',     consonance: 0.75 },
    { ratio: 5/3,   name: 'maj6',     consonance: 0.7 },
    { ratio: 8/5,   name: 'min6',     consonance: 0.65 },
    { ratio: 9/8,   name: 'maj2',     consonance: 0.5 },
    { ratio: 16/15, name: 'min2',     consonance: 0.3 },
];

// Calculate consonance between two frequencies
function getConsonance(freq1, freq2) {
    let ratio = freq1 > freq2 ? freq1 / freq2 : freq2 / freq1;
    // Normalize to within one octave
    while (ratio > 2) ratio /= 2;

    let bestConsonance = 0.2; // Default dissonance
    for (const interval of CONSONANT_RATIOS) {
        const diff = Math.abs(ratio - interval.ratio);
        if (diff < 0.03) { // Within 3% of a just interval
            bestConsonance = Math.max(bestConsonance, interval.consonance * (1 - diff * 10));
        }
    }
    return bestConsonance;
}

// Calculate how well a new frequency fits with existing layers
function getHarmonicFit(newFreq) {
    if (layers.length === 0) return 1; // First layer always fits

    let totalConsonance = 0;
    for (const layer of layers) {
        totalConsonance += getConsonance(newFreq, layer.freq);
    }
    return totalConsonance / layers.length;
}

// Quantize frequency toward most consonant nearby pitch
function quantizeToHarmony(rawFreq, strength = 0.5) {
    if (layers.length === 0) {
        // No existing layers - quantize to chromatic scale
        const semitone = Math.round(12 * Math.log2(rawFreq / BASE_FREQ));
        const quantizedFreq = BASE_FREQ * Math.pow(2, semitone / 12);
        return rawFreq * (1 - strength) + quantizedFreq * strength;
    }

    // Find the frequency that best fits with existing layers
    let bestFreq = rawFreq;
    let bestFit = getHarmonicFit(rawFreq);

    // Try nearby semitones
    for (let offset = -3; offset <= 3; offset++) {
        const testFreq = rawFreq * Math.pow(2, offset / 12);
        const fit = getHarmonicFit(testFreq);
        if (fit > bestFit) {
            bestFit = fit;
            bestFreq = testFreq;
        }
    }

    // Also try consonant intervals from existing layers
    for (const layer of layers) {
        for (const interval of CONSONANT_RATIOS) {
            // Try above and below
            for (const mult of [interval.ratio, 1 / interval.ratio]) {
                const testFreq = layer.freq * mult;
                // Bring into reasonable range
                while (testFreq < rawFreq * 0.5) testFreq *= 2;
                while (testFreq > rawFreq * 2) testFreq /= 2;

                if (Math.abs(testFreq - rawFreq) < rawFreq * 0.3) {
                    const fit = getHarmonicFit(testFreq);
                    if (fit > bestFit) {
                        bestFit = fit;
                        bestFreq = testFreq;
                    }
                }
            }
        }
    }

    return rawFreq * (1 - strength) + bestFreq * strength;
}

// ============ TILT TO PITCH ============
// Y position (tilt forward/back) controls pitch
// Higher Y = lower pitch (natural: tilt down to go down)

function tiltToFreq(y) {
    // Map Y (0-1) to frequency range
    // Y=0 (top) = high pitch, Y=1 (bottom) = low pitch
    const octaves = 3; // 3 octave range
    const normalizedPitch = 1 - y; // Invert so up = high
    const freq = BASE_FREQ * Math.pow(2, normalizedPitch * octaves);
    return freq;
}

// ============ PREDICTION SYSTEM ============
// The system looks 100ms into the future based on current velocity
// This creates ANTICIPATION - the harmony shifts BEFORE you arrive
// When prediction fails (direction change), it creates musical TENSION
//
// NEW: PREDICTIVE HARMONIC PULL
// The system doesn't just predict WHERE you're going - it predicts
// what HARMONY you're building toward and PULLS you there

const PREDICTION = {
    LOOKAHEAD_MS: 150,          // How far ahead we predict (ms) - increased for more anticipation
    TENSION_DECAY: 0.92,        // How fast tension decays per frame
    TENSION_THRESHOLD: 0.12,    // Prediction error above this = tension (more sensitive)
    ERROR_SMOOTH: 0.25,         // Smoothing for error calculation
    POSITION_SMOOTH: 0.7,       // Smoothing for predicted position (less smooth = more responsive)
    // NEW: Harmonic Pull parameters
    PULL_STRENGTH: 0.35,        // How strongly the system pulls toward harmony (0-1)
    PULL_RAMP_TIME: 0.08,       // Seconds to ramp to new pull target
    CONSONANCE_THRESHOLD: 0.6   // Minimum consonance to trigger strong pull
};

// Harmonic state - tracks the "home key" the user is establishing
let harmonicState = {
    root: BASE_FREQ,            // The root frequency of the user's harmonic center
    rootConfidence: 0,          // How confident we are in the root (0-1)
    targetPullFreq: null,       // The frequency we're pulling toward
    pullAmount: 0,              // Current pull amount (0-1)
    lastPullFreq: BASE_FREQ,    // For smooth transitions
    consonanceScore: 0          // How harmonious is the current state
};

// Find the most likely root from existing layers
function analyzeHarmonicCenter() {
    if (layers.length === 0) {
        harmonicState.root = BASE_FREQ;
        harmonicState.rootConfidence = 0;
        return;
    }

    // The first layer is often the "home" - weight it heavily
    // But also consider which frequency appears most as a consonant interval
    let rootCandidates = {};

    for (const layer of layers) {
        // Each layer's frequency is a candidate
        let normalizedFreq = layer.freq;
        // Bring to base octave range
        while (normalizedFreq > BASE_FREQ * 2) normalizedFreq /= 2;
        while (normalizedFreq < BASE_FREQ) normalizedFreq *= 2;

        const key = Math.round(normalizedFreq);
        rootCandidates[key] = (rootCandidates[key] || 0) + 1;

        // Also add fifths and octaves as potential roots
        const fifth = normalizedFreq / 1.5;
        const fifthNorm = fifth < BASE_FREQ ? fifth * 2 : fifth;
        const fifthKey = Math.round(fifthNorm);
        rootCandidates[fifthKey] = (rootCandidates[fifthKey] || 0) + 0.5;
    }

    // Find the most common root candidate
    let bestRoot = BASE_FREQ;
    let bestScore = 0;
    for (const [freqStr, score] of Object.entries(rootCandidates)) {
        if (score > bestScore) {
            bestScore = score;
            bestRoot = parseFloat(freqStr);
        }
    }

    // Smoothly update root
    harmonicState.root = harmonicState.root * 0.8 + bestRoot * 0.2;
    harmonicState.rootConfidence = Math.min(1, layers.length / 3); // Full confidence at 3+ layers
}

// Calculate the best harmonic target given predicted position
function calculateHarmonicTarget(predictedY) {
    const rawPredictedFreq = tiltToFreq(predictedY);

    if (layers.length === 0) {
        // No layers yet - just quantize to chromatic scale
        return quantizeToHarmony(rawPredictedFreq, 0.3);
    }

    // Find the most consonant frequency near the predicted frequency
    let bestFreq = rawPredictedFreq;
    let bestConsonance = 0;

    // Test frequencies in a range around the predicted frequency
    const testRange = 0.25; // +/- 25% of predicted freq (about 4 semitones)
    const steps = 12;

    for (let i = 0; i <= steps; i++) {
        const ratio = 1 - testRange + (testRange * 2 * i / steps);
        const testFreq = rawPredictedFreq * ratio;

        // Calculate consonance with existing layers
        let totalConsonance = getHarmonicFit(testFreq);

        // Bonus for being close to consonant intervals from root
        const rootRatio = testFreq / harmonicState.root;
        let normalizedRatio = rootRatio;
        while (normalizedRatio > 2) normalizedRatio /= 2;
        while (normalizedRatio < 1) normalizedRatio *= 2;

        for (const interval of CONSONANT_RATIOS) {
            const diff = Math.abs(normalizedRatio - interval.ratio);
            if (diff < 0.02) {
                totalConsonance += interval.consonance * 0.3;
            }
        }

        // Slight preference for frequencies closer to the raw prediction
        // (don't pull too far from user's intent)
        const proximityBonus = (1 - Math.abs(ratio - 1) / testRange) * 0.2;
        totalConsonance += proximityBonus;

        if (totalConsonance > bestConsonance) {
            bestConsonance = totalConsonance;
            bestFreq = testFreq;
        }
    }

    harmonicState.consonanceScore = bestConsonance;
    return bestFreq;
}

function updatePrediction(dt) {
    // Calculate how many frames ahead we're predicting
    const framesAhead = (PREDICTION.LOOKAHEAD_MS / 1000) / dt;

    // Raw predicted position based on velocity extrapolation
    const rawPx = field.x + field.vx * framesAhead;
    const rawPy = field.y + field.vy * framesAhead;

    // Clamp to valid range [0, 1]
    const clampedPx = Math.max(0, Math.min(1, rawPx));
    const clampedPy = Math.max(0, Math.min(1, rawPy));

    // Smooth the prediction to avoid jitter
    field.px = field.px * PREDICTION.POSITION_SMOOTH + clampedPx * (1 - PREDICTION.POSITION_SMOOTH);
    field.py = field.py * PREDICTION.POSITION_SMOOTH + clampedPy * (1 - PREDICTION.POSITION_SMOOTH);

    // Calculate prediction error: how wrong was our LAST prediction?
    // Compare where we predicted we'd be vs where we actually are
    const errorX = Math.abs(field.lastPredictedX - field.x);
    const errorY = Math.abs(field.lastPredictedY - field.y);
    const rawError = Math.sqrt(errorX * errorX + errorY * errorY);

    // Smooth the error
    field.predictionError = field.predictionError * (1 - PREDICTION.ERROR_SMOOTH) + rawError * PREDICTION.ERROR_SMOOTH;

    // Build tension when prediction is significantly wrong
    if (field.predictionError > PREDICTION.TENSION_THRESHOLD) {
        const tensionIncrease = (field.predictionError - PREDICTION.TENSION_THRESHOLD) * 0.5;
        field.predictionTension = Math.min(1, field.predictionTension + tensionIncrease);
    }

    // Decay tension over time
    field.predictionTension *= PREDICTION.TENSION_DECAY;

    // Store current prediction for next frame's error calculation
    field.lastPredictedX = field.px;
    field.lastPredictedY = field.py;

    // ============ PREDICTIVE HARMONIC PULL ============
    // This is the magic: we analyze where the user is GOING and
    // calculate the most HARMONIOUS destination, then PULL toward it

    // Update our understanding of the harmonic center
    analyzeHarmonicCenter();

    // Calculate the harmonic target based on predicted position
    const harmonicTarget = calculateHarmonicTarget(field.py);

    // Update pull state
    if (field.energy > 0.01 && layers.length > 0) {
        // Actively moving with layers established - apply pull
        harmonicState.targetPullFreq = harmonicTarget;

        // Pull strength increases with:
        // 1. Higher consonance score (we're confident in the target)
        // 2. Lower prediction tension (movement is predictable)
        // 3. More layers (more established harmony)
        const consonanceBonus = Math.max(0, harmonicState.consonanceScore - 0.5) * 2;
        const tensionPenalty = field.predictionTension * 0.5;
        const layerBonus = Math.min(1, layers.length / 4) * 0.3;

        const targetPull = Math.min(1, PREDICTION.PULL_STRENGTH * (1 + consonanceBonus + layerBonus - tensionPenalty));
        harmonicState.pullAmount = harmonicState.pullAmount * 0.9 + targetPull * 0.1;
    } else {
        // Not moving or no layers - decay pull
        harmonicState.pullAmount *= 0.95;
        harmonicState.targetPullFreq = null;
    }

    // Smooth the last pull frequency for transitions
    if (harmonicState.targetPullFreq) {
        harmonicState.lastPullFreq = harmonicState.lastPullFreq * 0.85 + harmonicState.targetPullFreq * 0.15;
    }

    // Update orb's predicted frequency (now includes harmonic pull!)
    const rawPredictedFreq = tiltToFreq(field.py);
    if (harmonicState.targetPullFreq && harmonicState.pullAmount > 0.1) {
        // Blend between raw prediction and harmonic target
        field.orb.predictedFreq = rawPredictedFreq * (1 - harmonicState.pullAmount) +
                                   harmonicState.targetPullFreq * harmonicState.pullAmount;
    } else {
        field.orb.predictedFreq = rawPredictedFreq;
    }
}

// ============ THE SINGLE VOICE ============
// Before recording, there is ONE voice that follows your tilt
// It's delicate, pure, singular

function createActiveVoice() {
    if (activeVoice) return; // Already exists

    const osc = ctx.createOscillator();
    const gain = ctx.createGain();
    const filter = ctx.createBiquadFilter();

    // Pure, delicate sine wave
    osc.type = 'sine';
    osc.frequency.value = BASE_FREQ * 2;

    filter.type = 'lowpass';
    filter.frequency.value = 2000;
    filter.Q.value = 1;

    // Start SILENT - only sound when moving
    gain.gain.value = 0;

    osc.connect(filter);
    filter.connect(gain);
    gain.connect(master);
    gain.connect(verb.input);

    osc.start();

    activeVoice = { osc, gain, filter, envelope: 0 };
}

function updateActiveVoice() {
    if (!activeVoice || !ctx) return;

    const now = ctx.currentTime;

    // Get raw frequency from tilt
    const rawFreq = tiltToFreq(field.y);

    // ============ HARMONIC PULL: The Magic ============
    // The system PREDICTS the most harmonious destination and PULLS you there
    // This is what makes the user say "it knew where I was going"

    let freq;

    if (harmonicState.pullAmount > 0.1 && harmonicState.targetPullFreq) {
        // PULL toward the harmonious target
        // The stronger the pull, the more the sound bends toward consonance
        const pullStrength = harmonicState.pullAmount;

        // Blend between raw frequency and the predicted harmonic target
        freq = rawFreq * (1 - pullStrength * 0.6) + harmonicState.lastPullFreq * (pullStrength * 0.6);

        // Also apply standard quantization (less strongly when pull is active)
        const quantizeStrength = Math.max(0, 0.3 - pullStrength * 0.2);
        freq = quantizeToHarmony(freq, quantizeStrength);
    } else {
        // No pull active - use standard quantization
        const predictionConfidence = 1 - field.predictionTension;
        const quantizeStrength = Math.min(0.8, layers.length * 0.2) * (0.5 + predictionConfidence * 0.5);
        freq = quantizeToHarmony(rawFreq, quantizeStrength);
    }

    // Update orb frequency (this is what gets recorded when orb hits center)
    field.orb.freq = freq;

    // TENSION EFFECT: Add pitch instability when prediction is wrong
    // This makes direction changes sound "surprising" / "tense"
    const tensionWobble = Math.sin(field.time * 30) * field.predictionTension * 0.02;

    // HARMONIC PULL EFFECT: Add subtle shimmer when being pulled toward harmony
    // This creates a "magnetic" feel - the note wants to go somewhere
    const pullShimmer = harmonicState.pullAmount > 0.2 ?
        Math.sin(field.time * 8) * harmonicState.pullAmount * 0.008 : 0;

    const finalFreq = freq * (1 + tensionWobble + pullShimmer);

    // Smooth frequency transition
    activeVoice.osc.frequency.linearRampToValueAtTime(finalFreq, now + 0.05);

    // Volume based on movement - stillness = silence, movement = sound
    const targetEnv = Math.min(1, field.energy * 8);
    activeVoice.envelope += (targetEnv - activeVoice.envelope) * 0.1;

    // TENSION EFFECT: Slightly louder when prediction fails (urgency)
    const tensionVolume = 1 + field.predictionTension * 0.3;

    // PULL EFFECT: Slightly louder when being pulled (significance)
    const pullVolume = 1 + harmonicState.pullAmount * 0.15;

    // Delicate volume - QUIET but audible
    const baseVolume = 0.09; // Slightly increased for better audibility
    const volume = baseVolume * activeVoice.envelope * tensionVolume * pullVolume;
    activeVoice.gain.gain.linearRampToValueAtTime(volume, now + 0.03);

    // Filter opens slightly with movement
    // TENSION EFFECT: Filter opens more when prediction fails (brighter, more urgent)
    const tensionFilter = field.predictionTension * 1500;

    // PULL EFFECT: Filter opens more when being pulled toward harmony (warmth)
    const pullFilter = harmonicState.pullAmount * 800;

    const filterFreq = 800 + field.energy * 2000 + tensionFilter + pullFilter;
    activeVoice.filter.frequency.linearRampToValueAtTime(filterFreq, now + 0.05);
}

// ============ THE ORB ============
// Visual representation of the sound
// When orb crosses center, that note gets RECORDED as a layer

function updateOrb(dt) {
    if (!field.orb.active) {
        // Spawn orb when there's enough movement
        if (field.energy > 0.02) {
            field.orb.active = true;
            field.orb.x = field.x;
            field.orb.y = field.y;
            field.orb.startTime = field.time;
            field.orb.velocity = 0.2 + field.energy * 0.5;
        }
        return;
    }

    // Orb moves toward center
    const dx = 0.5 - field.orb.x;
    const dy = 0.5 - field.orb.y;
    const dist = Math.sqrt(dx * dx + dy * dy);

    if (dist > 0.01) {
        const moveAmount = field.orb.velocity * dt;
        field.orb.x += (dx / dist) * moveAmount;
        field.orb.y += (dy / dist) * moveAmount;
    }

    // Update orb frequency based on current tilt
    field.orb.freq = tiltToFreq(field.y);

    // Check if orb crossed center
    if (dist < 0.03) {
        recordLayer();
        field.orb.active = false;
    }

    // Orb fades if no movement for too long
    if (field.energy < 0.01 && field.time - field.orb.startTime > 2) {
        field.orb.active = false;
    }
}

// ============ LAYER RECORDING ============
// When orb crosses center, record the current pitch as a new layer

function recordLayer() {
    if (layers.length >= MAX_LAYERS) {
        // Remove oldest layer to make room
        const oldLayer = layers.shift();
        oldLayer.osc.stop();
    }

    // ============ PREDICTIVE HARMONIC RECORDING ============
    // The system uses its prediction to record the MOST HARMONIOUS frequency
    // This is the payoff: "It knew what note I wanted"

    const currentFreq = field.orb.freq;
    const predictedFreq = field.orb.predictedFreq;
    const harmonicTarget = harmonicState.targetPullFreq || predictedFreq;

    // Calculate how confident we are in prediction
    const predictionConfidence = 1 - field.predictionTension;

    // Calculate blend factors:
    // 1. If we were actively being pulled toward a harmonic target, use that
    // 2. Otherwise blend current with predicted based on confidence
    let blendedFreq;

    if (harmonicState.pullAmount > 0.2 && harmonicTarget) {
        // Strong pull was active - the user was being guided
        // Trust the harmonic target more heavily
        const pullBlend = Math.min(0.6, harmonicState.pullAmount * 0.8);
        blendedFreq = currentFreq * (1 - pullBlend) + harmonicTarget * pullBlend;

        console.log(`Recording with harmonic pull: ${currentFreq.toFixed(1)}Hz → ${blendedFreq.toFixed(1)}Hz (${(pullBlend * 100).toFixed(0)}% pull)`);
    } else {
        // No strong pull - use prediction blending
        blendedFreq = currentFreq * (1 - predictionConfidence * 0.3) + predictedFreq * (predictionConfidence * 0.3);
    }

    // Apply strong harmonic quantization to the recorded frequency
    // More layers = stronger quantization (we have more context)
    const baseQuantize = 0.4 + layers.length * 0.1;
    const confidenceBonus = predictionConfidence * 0.2;
    const quantizeStrength = Math.min(0.9, baseQuantize + confidenceBonus);
    const freq = quantizeToHarmony(blendedFreq, quantizeStrength);

    const now = ctx.currentTime;

    // ============ RHYTHMIC QUANTIZATION ============
    // Instead of arbitrary loop lengths, quantize to the BEAT GRID
    // This is THE KEY to music emergence - shared time structure

    const travelTime = field.time - field.orb.startTime;
    const rawLoopLength = Math.max(0.5, Math.min(8, travelTime * 2));

    // Quantize to musical divisions (1, 2, or 4 bars)
    const loopLength = getQuantizedLoopLength(rawLoopLength);

    // Also quantize the START TIME so layers align
    // New layer starts at the next beat boundary
    const beatDuration = 60 / beatState.bpm;
    const startOffset = beatDuration - (field.time % beatDuration);

    console.log(`Loop length: ${rawLoopLength.toFixed(2)}s → ${loopLength.toFixed(2)}s (${(loopLength / beatDuration / BEAT.BEATS_PER_BAR).toFixed(1)} bars at ${beatState.bpm.toFixed(0)} BPM)`);

    // Create layer audio
    const osc = ctx.createOscillator();
    const gain = ctx.createGain();
    const filter = ctx.createBiquadFilter();

    // Vary timbre based on layer number
    const layerNum = layers.length;
    if (layerNum === 0) {
        osc.type = 'sine'; // First layer: pure sine
    } else if (layerNum === 1) {
        osc.type = 'triangle'; // Second: triangle
    } else {
        osc.type = 'sine'; // Rest: sine with slight detune for warmth
    }

    osc.frequency.value = freq;

    filter.type = 'lowpass';
    filter.frequency.value = 1500 + (1 - layerNum / MAX_LAYERS) * 2000;
    filter.Q.value = 0.5;

    // Volume decreases with each layer (prevent clashing)
    const baseVolume = 0.12;
    const volumeScale = Math.pow(0.75, layerNum); // Each layer is 75% of previous
    gain.gain.value = baseVolume * volumeScale;

    osc.connect(filter);
    filter.connect(gain);
    gain.connect(master);
    gain.connect(verb.input);

    osc.start();

    const layer = {
        id: Date.now(),
        freq,
        loopLength,
        osc,
        gain,
        filter,
        volume: baseVolume * volumeScale,
        phase: 0,
        birthTime: field.time
    };

    layers.push(layer);

    // Console feedback for debugging
    console.log(`Layer ${layers.length}: ${freq.toFixed(1)} Hz, loop: ${loopLength.toFixed(2)}s, fit: ${getHarmonicFit(freq).toFixed(2)}`);
}

// ============ LAYER PLAYBACK ============
// Layers are now BEAT-SYNCHRONIZED
// All layers share the same time grid = music emerges

function updateLayers(dt) {
    const now = ctx.currentTime;
    const beatDuration = 60 / beatState.bpm;

    for (const layer of layers) {
        // Update phase (0-1 within loop)
        layer.phase += dt / layer.loopLength;
        if (layer.phase >= 1) layer.phase -= 1;

        // ============ BEAT-SYNCED ENVELOPE ============
        // Instead of free-running decay, pulse ON THE BEAT
        // This creates rhythmic coherence between all layers

        // How many beats in this layer's loop?
        const beatsInLoop = Math.round(layer.loopLength / beatDuration);

        // Current beat within the loop
        const loopBeat = layer.phase * beatsInLoop;
        const beatFraction = loopBeat % 1;

        // Attack at the START of each beat, then decay
        // This creates a rhythmic pulse that aligns across all layers
        const beatEnvelope = Math.exp(-beatFraction * 3);

        // Stronger attack on beat 1 of the loop (the "downbeat")
        const isDownbeat = Math.floor(loopBeat) === 0;
        const downbeatBoost = isDownbeat ? 1.3 : 1;

        // Also accent when the global beat aligns
        const globalBeatSync = 1 + beatState.pulseIntensity * 0.2;

        // Combine envelopes
        const sustainLevel = 0.25; // Minimum volume between beats
        const envelope = sustainLevel + (1 - sustainLevel) * beatEnvelope * downbeatBoost;

        // Apply envelope to volume
        const targetGain = layer.volume * envelope * globalBeatSync;
        layer.gain.gain.linearRampToValueAtTime(targetGain, now + 0.02);

        // Subtle pitch drift for organic feel (but smaller now)
        const drift = Math.sin(field.time * 0.3 + layer.id) * 0.001;
        layer.osc.frequency.linearRampToValueAtTime(layer.freq * (1 + drift), now + 0.1);
    }
}

// ============ REVERB ============

function createVerb() {
    const input = ctx.createGain();
    const output = ctx.createGain();
    output.gain.value = 0.25; // Gentle reverb

    const times = [0.03, 0.07, 0.12, 0.19, 0.31, 0.5, 0.81, 1.3, 2.1];
    times.forEach((t, i) => {
        const d = ctx.createDelay(4);
        d.delayTime.value = t + Math.random() * 0.02;
        const g = ctx.createGain();
        g.gain.value = 0.3 * Math.pow(0.75, i);
        const f = ctx.createBiquadFilter();
        f.type = 'lowpass';
        f.frequency.value = 4000 - i * 350;
        input.connect(d);
        d.connect(f);
        f.connect(g);
        g.connect(output);
        if (i > 4) {
            const fb = ctx.createGain();
            fb.gain.value = 0.15;
            g.connect(fb);
            fb.connect(input);
        }
    });

    return { input, output };
}

// ============ DELAY ============

function createDelay() {
    const input = ctx.createGain();
    const output = ctx.createGain();
    output.gain.value = 0.15;

    const delayL = ctx.createDelay(2);
    const delayR = ctx.createDelay(2);
    delayL.delayTime.value = 0.375;
    delayR.delayTime.value = 0.5;

    const fbL = ctx.createGain();
    const fbR = ctx.createGain();
    fbL.gain.value = 0.25;
    fbR.gain.value = 0.2;

    const filterL = ctx.createBiquadFilter();
    const filterR = ctx.createBiquadFilter();
    filterL.type = filterR.type = 'lowpass';
    filterL.frequency.value = filterR.frequency.value = 2000;

    const panL = ctx.createStereoPanner();
    const panR = ctx.createStereoPanner();
    panL.pan.value = -0.7;
    panR.pan.value = 0.7;

    input.connect(delayL);
    delayL.connect(filterL);
    filterL.connect(fbL);
    fbL.connect(delayR);
    delayR.connect(filterR);
    filterR.connect(fbR);
    fbR.connect(delayL);

    filterL.connect(panL);
    filterR.connect(panR);
    panL.connect(output);
    panR.connect(output);

    return { input, output };
}

// ============ INIT ============

function init() {
    ctx = new (window.AudioContext || window.webkitAudioContext)();

    master = ctx.createGain();
    master.gain.value = 0.8;

    // Light compression for safety
    const comp = ctx.createDynamicsCompressor();
    comp.threshold.value = -12;
    comp.ratio.value = 4;
    comp.attack.value = 0.003;
    comp.release.value = 0.25;

    verb = createVerb();
    dly = createDelay();

    master.connect(comp);
    comp.connect(ctx.destination);
    verb.output.connect(master);
    dly.output.connect(master);

    // Create the single active voice
    createActiveVoice();

    canvas = document.getElementById('c');
    vc = canvas.getContext('2d');
    resize();
    window.addEventListener('resize', resize);
}

// ============ INPUT ============

function onMove(nx, ny) {
    nx = Math.max(0, Math.min(1, nx));
    ny = Math.max(0, Math.min(1, ny));

    field.vx = field.vx * 0.6 + (nx - field.x) * 0.4;
    field.vy = field.vy * 0.6 + (ny - field.y) * 0.4;
    field.x = field.x * 0.7 + nx * 0.3;
    field.y = field.y * 0.7 + ny * 0.3;

    const speed = Math.sqrt(field.vx * field.vx + field.vy * field.vy);
    field.energy = field.energy * 0.9 + speed * 0.5;
}

function onMotion(e) {
    const a = e.accelerationIncludingGravity;
    if (!a) return;

    const rawAx = (a.x || 0) / 8;
    const rawAy = (a.y || 0) / 8;

    field.vx = field.vx * 0.7 + rawAx * 0.3;
    field.vy = field.vy * 0.7 + rawAy * 0.3;

    field.x = Math.max(0, Math.min(1, field.x + field.vx * 0.1));
    field.y = Math.max(0, Math.min(1, field.y - field.vy * 0.1));

    field.energy = field.energy * 0.9 + Math.sqrt(rawAx * rawAx + rawAy * rawAy) * 0.3;
}

function onOrientation(e) {
    const gx = Math.max(-1, Math.min(1, (e.gamma || 0) / 40));
    const gy = Math.max(-1, Math.min(1, (e.beta || 0) / 40 - 1));
    onMove((gx + 1) / 2, (1 - gy) / 2);
}

// ============ VISUALIZATION ============

function resize() {
    const dpr = window.devicePixelRatio || 1;
    const w = window.innerWidth;
    const h = window.innerHeight;

    canvas.width = w * dpr;
    canvas.height = h * dpr;
    canvas.style.width = w + 'px';
    canvas.style.height = h + 'px';
    vc.setTransform(dpr, 0, 0, dpr, 0, 0);
}

function draw() {
    const w = window.innerWidth;
    const h = window.innerHeight;

    // Dark fade
    vc.fillStyle = 'rgba(0, 0, 0, 0.08)';
    vc.fillRect(0, 0, w, h);

    // ============ BEAT GRID VISUALIZATION ============
    // A subtle pulse at the center shows the rhythm
    // Users can FEEL and SEE the beat they're building on

    if (layers.length > 0 || beatState.pulseIntensity > 0.1) {
        // Expanding ring on each beat
        const pulseRadius = 15 + (1 - beatState.pulseIntensity) * 80;
        const pulseAlpha = beatState.pulseIntensity * 0.3;

        if (pulseAlpha > 0.02) {
            vc.strokeStyle = `rgba(255, 255, 255, ${pulseAlpha})`;
            vc.lineWidth = 1 + beatState.pulseIntensity * 2;
            vc.beginPath();
            vc.arc(w / 2, h / 2, pulseRadius, 0, TAU);
            vc.stroke();
        }

        // Beat indicator dots around center (shows position in phrase)
        const totalBeats = BEAT.BARS * BEAT.BEATS_PER_BAR;
        const indicatorRadius = 120;

        for (let i = 0; i < totalBeats; i++) {
            const angle = (i / totalBeats) * TAU - Math.PI / 2; // Start at top
            const ix = w / 2 + Math.cos(angle) * indicatorRadius;
            const iy = h / 2 + Math.sin(angle) * indicatorRadius;

            // Highlight current beat
            const isCurrent = i === beatState.beat;
            const isPast = i < beatState.beat;
            const isDownbeat = i % BEAT.BEATS_PER_BAR === 0;

            let dotAlpha = 0.1;
            let dotRadius = 2;

            if (isCurrent) {
                dotAlpha = 0.5 + beatState.pulseIntensity * 0.3;
                dotRadius = 4;
            } else if (isPast) {
                dotAlpha = 0.2;
            }

            if (isDownbeat) {
                dotRadius += 1;
                dotAlpha += 0.05;
            }

            vc.fillStyle = `rgba(255, 255, 255, ${dotAlpha})`;
            vc.beginPath();
            vc.arc(ix, iy, dotRadius, 0, TAU);
            vc.fill();
        }
    }

    // Center crosshair (subtle target for orb)
    const centerAlpha = 0.1 + (field.orb.active ? 0.15 : 0);
    vc.strokeStyle = `rgba(255, 255, 255, ${centerAlpha})`;
    vc.lineWidth = 1;
    vc.beginPath();
    vc.moveTo(w / 2 - 20, h / 2);
    vc.lineTo(w / 2 + 20, h / 2);
    vc.moveTo(w / 2, h / 2 - 20);
    vc.lineTo(w / 2, h / 2 + 20);
    vc.stroke();

    // Draw layers as concentric rings at center
    for (let i = 0; i < layers.length; i++) {
        const layer = layers[i];
        const pulse = Math.exp(-layer.phase * 3);
        const radius = 30 + i * 25 + pulse * 15;
        const alpha = 0.15 + pulse * 0.25;

        // Color based on frequency (higher = bluer, lower = warmer)
        const freqRatio = Math.log2(layer.freq / BASE_FREQ);
        const hue = 200 + freqRatio * 30; // Blue-ish range

        vc.beginPath();
        vc.arc(w / 2, h / 2, radius, 0, TAU);
        vc.strokeStyle = `hsla(${hue}, 50%, 60%, ${alpha})`;
        vc.lineWidth = 2 + pulse * 3;
        vc.stroke();
    }

    // Draw the orb (if active)
    if (field.orb.active) {
        const ox = field.orb.x * w;
        const oy = field.orb.y * h;
        const orbRadius = 8 + field.energy * 15;

        // Frequency-based color
        const freqRatio = Math.log2(field.orb.freq / BASE_FREQ);
        const hue = 200 + freqRatio * 30;

        // Orb glow
        const grad = vc.createRadialGradient(ox, oy, 0, ox, oy, orbRadius * 2);
        grad.addColorStop(0, `hsla(${hue}, 70%, 80%, 0.9)`);
        grad.addColorStop(0.5, `hsla(${hue}, 60%, 60%, 0.4)`);
        grad.addColorStop(1, 'transparent');

        vc.fillStyle = grad;
        vc.beginPath();
        vc.arc(ox, oy, orbRadius * 2, 0, TAU);
        vc.fill();

        // Core
        vc.fillStyle = `hsla(${hue}, 80%, 90%, 1)`;
        vc.beginPath();
        vc.arc(ox, oy, orbRadius * 0.5, 0, TAU);
        vc.fill();

        // Trail toward center
        vc.strokeStyle = `hsla(${hue}, 50%, 60%, 0.3)`;
        vc.lineWidth = 1;
        vc.beginPath();
        vc.moveTo(ox, oy);
        vc.lineTo(w / 2, h / 2);
        vc.stroke();
    }

    // PREDICTION GHOST: Show where the system thinks you're going
    // Only visible when moving and prediction differs from current position
    const predictionDist = Math.sqrt(
        Math.pow(field.px - field.x, 2) + Math.pow(field.py - field.y, 2)
    );

    if (predictionDist > 0.02 && field.energy > 0.02) {
        const predX = field.px * w;
        const predY = field.py * h;
        const predRadius = 8 + field.energy * 10;

        // Line from current to predicted
        vc.strokeStyle = `rgba(100, 180, 255, ${0.2 + field.energy * 0.3})`;
        vc.lineWidth = 1;
        vc.setLineDash([4, 4]);
        vc.beginPath();
        vc.moveTo(field.x * w, field.y * h);
        vc.lineTo(predX, predY);
        vc.stroke();
        vc.setLineDash([]);

        // Prediction ghost dot
        const ghostGrad = vc.createRadialGradient(predX, predY, 0, predX, predY, predRadius);
        ghostGrad.addColorStop(0, `rgba(100, 180, 255, ${0.3 + field.energy * 0.4})`);
        ghostGrad.addColorStop(0.5, `rgba(100, 180, 255, ${0.1})`);
        ghostGrad.addColorStop(1, 'transparent');

        vc.fillStyle = ghostGrad;
        vc.beginPath();
        vc.arc(predX, predY, predRadius, 0, TAU);
        vc.fill();
    }

    // TENSION RING: Red flash when prediction is wrong (direction change)
    if (field.predictionTension > 0.1) {
        const cx = field.x * w;
        const cy = field.y * h;
        const tensionRadius = 30 + field.predictionTension * 40;
        const tensionAlpha = field.predictionTension * 0.4;

        vc.strokeStyle = `rgba(255, 100, 100, ${tensionAlpha})`;
        vc.lineWidth = 2;
        vc.beginPath();
        vc.arc(cx, cy, tensionRadius, 0, TAU);
        vc.stroke();
    }

    // Cursor (follows tilt)
    const cx = field.x * w;
    const cy = field.y * h;
    const cursorRadius = 5 + field.energy * 20;

    const cursorGrad = vc.createRadialGradient(cx, cy, 0, cx, cy, cursorRadius);
    cursorGrad.addColorStop(0, `rgba(255, 255, 255, ${0.3 + field.energy * 0.5})`);
    cursorGrad.addColorStop(1, 'transparent');

    vc.fillStyle = cursorGrad;
    vc.beginPath();
    vc.arc(cx, cy, cursorRadius, 0, TAU);
    vc.fill();

    // Layer count and BPM
    if (layers.length > 0) {
        vc.fillStyle = 'rgba(255, 255, 255, 0.3)';
        vc.font = '10px system-ui';
        vc.textAlign = 'left';
        vc.fillText(`${layers.length} layer${layers.length > 1 ? 's' : ''}`, 20, 25);

        // BPM indicator
        const bpmColor = beatState.tempoConfidence > 0.5 ? '150, 255, 150' : '255, 255, 255';
        vc.fillStyle = `rgba(${bpmColor}, ${0.2 + beatState.tempoConfidence * 0.3})`;
        vc.fillText(`${Math.round(beatState.bpm)} BPM`, 20, 55);

        // Tempo sync indicator
        if (beatState.tempoConfidence > 0.3) {
            vc.fillStyle = `rgba(150, 255, 150, ${beatState.tempoConfidence * 0.4})`;
            vc.fillText('♪ synced', 70, 55);
        }
    }

    // Current pitch indicator
    const freqRatio = Math.log2(field.orb.freq / BASE_FREQ);
    const noteName = getNoteName(field.orb.freq);
    vc.fillStyle = `rgba(255, 255, 255, ${0.1 + field.energy * 0.3})`;
    vc.font = '12px system-ui';
    vc.textAlign = 'center';
    vc.fillText(noteName, w / 2, h - 30);

    // Harmonic fit indicator (when moving)
    if (field.energy > 0.02 && layers.length > 0) {
        const fit = getHarmonicFit(field.orb.freq);
        const fitColor = fit > 0.7 ? '120, 255, 150' : fit > 0.5 ? '255, 220, 100' : '255, 100, 100';
        vc.fillStyle = `rgba(${fitColor}, ${0.3 + fit * 0.4})`;
        vc.font = '9px system-ui';
        vc.fillText(fit > 0.7 ? 'consonant' : fit > 0.5 ? 'tension' : 'dissonant', w / 2, h - 15);
    }

    // PREDICTION indicator (top right)
    if (field.energy > 0.01) {
        const predictionConfidence = 1 - field.predictionTension;
        const confColor = predictionConfidence > 0.7 ? '100, 180, 255' : predictionConfidence > 0.4 ? '255, 180, 100' : '255, 100, 100';
        vc.fillStyle = `rgba(${confColor}, ${0.3 + field.energy * 0.3})`;
        vc.font = '9px system-ui';
        vc.textAlign = 'right';

        if (field.predictionTension > 0.3) {
            vc.fillText('surprise!', w - 20, 25);
        } else if (predictionConfidence > 0.7 && field.energy > 0.05) {
            vc.fillText('predicting...', w - 20, 25);
        }
        vc.textAlign = 'center'; // Reset
    }

    // ============ HARMONIC PULL VISUALIZATION ============
    // Shows when the system is pulling the user toward a harmonious pitch

    if (harmonicState.pullAmount > 0.15 && harmonicState.targetPullFreq && field.energy > 0.02) {
        // Calculate where the harmonic target is in screen space
        // Convert frequency to Y position (inverse of tiltToFreq)
        const targetRatio = Math.log2(harmonicState.targetPullFreq / BASE_FREQ) / 3;
        const targetY = (1 - targetRatio) * h;

        // Current cursor position
        const cx = field.x * w;
        const cy = field.y * h;

        // Draw a "magnetic field line" from cursor toward harmonic target
        const pullStrength = harmonicState.pullAmount;

        // Green glow around cursor when being pulled toward consonance
        if (harmonicState.consonanceScore > 0.6) {
            const consonanceGlow = vc.createRadialGradient(cx, cy, 0, cx, cy, 50 * pullStrength);
            consonanceGlow.addColorStop(0, `rgba(100, 255, 150, ${0.2 * pullStrength})`);
            consonanceGlow.addColorStop(1, 'transparent');
            vc.fillStyle = consonanceGlow;
            vc.beginPath();
            vc.arc(cx, cy, 50 * pullStrength, 0, TAU);
            vc.fill();
        }

        // Dashed line showing the pull direction
        const pullLineAlpha = 0.15 + pullStrength * 0.3;
        const pullDist = Math.abs(targetY - cy);

        // Only show if there's meaningful distance to the target
        if (pullDist > 20) {
            // Draw subtle curve toward target
            vc.strokeStyle = `rgba(100, 255, 150, ${pullLineAlpha})`;
            vc.lineWidth = 1;
            vc.setLineDash([3, 6]);
            vc.beginPath();
            vc.moveTo(cx, cy);

            // Curve toward the harmonic target
            const midY = (cy + targetY) / 2;
            vc.quadraticCurveTo(cx + 30 * pullStrength, midY, cx, targetY);
            vc.stroke();
            vc.setLineDash([]);

            // Small circle at target pitch
            vc.strokeStyle = `rgba(100, 255, 150, ${pullLineAlpha * 0.6})`;
            vc.beginPath();
            vc.arc(cx, targetY, 6, 0, TAU);
            vc.stroke();
        }

        // Show "pulling toward harmony" text when strong pull
        if (pullStrength > 0.4 && harmonicState.consonanceScore > 0.7) {
            vc.fillStyle = `rgba(100, 255, 150, ${0.3 + pullStrength * 0.3})`;
            vc.font = '8px system-ui';
            vc.textAlign = 'left';
            vc.fillText('→ harmony', 20, h - 20);
            vc.textAlign = 'center';
        }
    }

    // Show harmonic root indicator when established
    if (harmonicState.rootConfidence > 0.5 && layers.length >= 2) {
        const rootNote = getNoteName(harmonicState.root);
        vc.fillStyle = `rgba(255, 255, 255, ${0.15 + harmonicState.rootConfidence * 0.15})`;
        vc.font = '9px system-ui';
        vc.textAlign = 'left';
        vc.fillText(`key: ${rootNote}`, 20, 40);
        vc.textAlign = 'center';
    }
}

// Convert frequency to note name (approximate)
function getNoteName(freq) {
    const noteNames = ['A', 'A#', 'B', 'C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#'];
    const semitones = Math.round(12 * Math.log2(freq / 110)); // A2 = 110Hz
    const noteIndex = ((semitones % 12) + 12) % 12;
    const octave = Math.floor(semitones / 12) + 2;
    return noteNames[noteIndex] + octave;
}

// ============ LOOP ============

function tick() {
    if (!running) return;

    const dt = 0.016; // ~60fps
    field.time += dt;

    // Update BEAT GRID first - this provides the time structure
    updateBeat(dt);

    // Update PREDICTION - this informs harmony selection
    updatePrediction(dt);

    // Update orb physics
    updateOrb(dt);

    // Update active voice (follows tilt, affected by prediction tension)
    updateActiveVoice();

    // Update recorded layers (now beat-synchronized!)
    updateLayers(dt);

    // Draw
    draw();

    requestAnimationFrame(tick);
}

// ============ START ============

async function start() {
    document.getElementById('enter').classList.add('off');

    if (typeof DeviceMotionEvent !== 'undefined' &&
        typeof DeviceMotionEvent.requestPermission === 'function') {
        try { await DeviceMotionEvent.requestPermission(); } catch(e) {}
    }
    if (typeof DeviceOrientationEvent !== 'undefined' &&
        typeof DeviceOrientationEvent.requestPermission === 'function') {
        try { await DeviceOrientationEvent.requestPermission(); } catch(e) {}
    }

    init();

    window.addEventListener('devicemotion', onMotion);
    window.addEventListener('deviceorientation', onOrientation);

    document.addEventListener('mousemove', e => {
        onMove(e.clientX / window.innerWidth, e.clientY / window.innerHeight);
    });

    document.addEventListener('touchmove', e => {
        e.preventDefault();
        const t = e.touches[0];
        onMove(t.clientX / window.innerWidth, t.clientY / window.innerHeight);
    }, { passive: false });

    document.addEventListener('touchstart', e => {
        e.preventDefault();
        const t = e.touches[0];
        onMove(t.clientX / window.innerWidth, t.clientY / window.innerHeight);
    }, { passive: false });

    if (ctx.state === 'suspended') await ctx.resume();

    running = true;
    tick();
}

document.getElementById('enter').addEventListener('click', start);
</script>
</body>
</html>
