<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>GUMP: Enhanced Cinematic Void Engine</title>
  <style>
    * { margin: 0; padding: 0; box-sizing: border-box; }
    
    body {
      background: #0a0a0a;
      color: #fff;
      overflow: hidden;
      touch-action: none;
      height: 100vh;
      font-family: 'SF Mono', 'Monaco', 'Inconsolata', 'Roboto Mono', monospace;
      display: flex;
      align-items: center;
      justify-content: center;
      transition: all 2s cubic-bezier(0.25, 0.46, 0.45, 0.94);
    }
    
    .start-screen {
      text-align: center;
      z-index: 100;
    }
    
    .start-btn {
      width: 220px;
      height: 220px;
      border-radius: 50%;
      background: conic-gradient(from 0deg, rgba(255,255,255,0.1) 0%, rgba(74,144,226,0.2) 50%, rgba(155,89,182,0.2) 100%);
      border: 3px solid rgba(255,255,255,0.2);
      color: #fff;
      cursor: pointer;
      display: flex;
      align-items: center;
      justify-content: center;
      font-size: 18px;
      font-weight: 700;
      letter-spacing: 3px;
      backdrop-filter: blur(20px);
      transition: all 0.4s cubic-bezier(0.175, 0.885, 0.32, 1.275);
      animation: ethereal-pulse 8s ease-in-out infinite;
      position: relative;
    }
    
    .start-btn::before {
      content: '';
      position: absolute;
      top: -5px; left: -5px; right: -5px; bottom: -5px;
      border-radius: 50%;
      background: conic-gradient(from 0deg, transparent, rgba(255,255,255,0.1), transparent);
      animation: rotate 4s linear infinite;
      z-index: -1;
    }
    
    .start-btn:hover {
      border-color: rgba(255,255,255,0.8);
      background: conic-gradient(from 0deg, rgba(255,255,255,0.2) 0%, rgba(74,144,226,0.4) 50%, rgba(155,89,182,0.4) 100%);
      transform: scale(1.08);
      box-shadow: 0 0 80px rgba(255,255,255,0.3);
    }
    
    @keyframes ethereal-pulse {
      0%, 100% { transform: scale(1); box-shadow: 0 0 40px rgba(255,255,255,0.2); }
      50% { transform: scale(1.05); box-shadow: 0 0 100px rgba(74,144,226,0.4); }
    }
    
    @keyframes rotate {
      0% { transform: rotate(0deg); }
      100% { transform: rotate(360deg); }
    }
    
    .evolution-space {
      position: fixed;
      top: 0; left: 0;
      width: 100%; height: 100%;
      opacity: 0;
      transition: opacity 3s ease;
    }
    
    .evolution-space.active { opacity: 1; }
    
    .orb {
      position: absolute;
      width: 50px;
      height: 50px;
      border-radius: 50%;
      background: radial-gradient(circle, #fff 0%, rgba(255,255,255,0.4) 40%, transparent 80%);
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      transition: all 0.4s cubic-bezier(0.25, 0.46, 0.45, 0.94);
      box-shadow: 0 0 60px rgba(255,255,255,0.6);
      backdrop-filter: blur(8px);
      z-index: 10;
    }
    
    .orb::before {
      content: '';
      position: absolute;
      top: -10px; left: -10px; right: -10px; bottom: -10px;
      border-radius: 50%;
      background: conic-gradient(from 0deg, transparent, rgba(255,255,255,0.1), transparent);
      animation: orb-rotate 6s linear infinite;
      z-index: -1;
    }
    
    @keyframes orb-rotate {
      0% { transform: rotate(0deg) scale(1); }
      100% { transform: rotate(360deg) scale(1.1); }
    }
    
    .orb.pulse {
      animation: neural-beat 0.2s cubic-bezier(0.25, 0.46, 0.45, 0.94);
    }
    
    @keyframes neural-beat {
      0% { transform: translate(-50%, -50%) scale(1); box-shadow: 0 0 60px rgba(255,255,255,0.6); }
      50% { transform: translate(-50%, -50%) scale(2.5); box-shadow: 0 0 120px rgba(255,255,255,0.9); }
      100% { transform: translate(-50%, -50%) scale(1); box-shadow: 0 0 60px rgba(255,255,255,0.6); }
    }
    
    .orb.tribal {
      background: radial-gradient(circle, #ff6b35 0%, rgba(255,107,53,0.5) 40%, transparent 80%);
      box-shadow: 0 0 80px rgba(255,107,53,0.8);
    }
    
    .orb.orchestral {
      background: radial-gradient(circle, #4a90e2 0%, rgba(74,144,226,0.5) 40%, transparent 80%);
      box-shadow: 0 0 100px rgba(74,144,226,0.8);
    }
    
    .orb.transcendent {
      background: radial-gradient(circle, #9b59b6 0%, #e74c3c 30%, #f39c12 60%, transparent 90%);
      box-shadow: 0 0 150px rgba(155,89,182,0.9);
      animation: cosmic-transcend 4s ease-in-out infinite;
    }
    
    @keyframes cosmic-transcend {
      0%, 100% { transform: translate(-50%, -50%) scale(1); filter: hue-rotate(0deg); }
      50% { transform: translate(-50%, -50%) scale(1.6); filter: hue-rotate(180deg); }
    }
    
    .ui-corner {
      position: fixed;
      font-size: 11px;
      color: rgba(255,255,255,0.9);
      font-weight: 500;
      letter-spacing: 1px;
      background: rgba(0,0,0,0.4);
      padding: 12px;
      border-radius: 8px;
      backdrop-filter: blur(20px);
      border: 1px solid rgba(255,255,255,0.1);
    }
    
    .ui-corner.top-left {
      top: 20px;
      left: 20px;
    }
    
    .ui-corner.bottom-left {
      bottom: 20px;
      left: 20px;
    }
    
    .ui-corner.top-right {
      top: 20px;
      right: 20px;
    }
    
    .ui-corner.bottom-right {
      bottom: 20px;
      right: 20px;
    }
    
    .stage-name {
      font-size: 16px;
      color: rgba(255,255,255,1);
      margin-bottom: 10px;
      font-weight: 700;
      text-transform: uppercase;
      letter-spacing: 2px;
    }
    
    .metric {
      margin: 4px 0;
      font-size: 10px;
      display: flex;
      justify-content: space-between;
      align-items: center;
    }
    
    .bar {
      width: 100px;
      height: 4px;
      background: rgba(255,255,255,0.15);
      margin: 4px 0;
      border-radius: 2px;
      overflow: hidden;
      position: relative;
    }
    
    .bar-fill {
      height: 100%;
      background: linear-gradient(90deg, #4a90e2, #9b59b6, #e74c3c);
      width: 0%;
      transition: width 0.2s cubic-bezier(0.25, 0.46, 0.45, 0.94);
      border-radius: 2px;
      position: relative;
    }
    
    .bar-fill::after {
      content: '';
      position: absolute;
      top: 0; left: 0; right: 0; bottom: 0;
      background: linear-gradient(90deg, transparent, rgba(255,255,255,0.3), transparent);
      animation: sweep 2s ease-in-out infinite;
    }
    
    @keyframes sweep {
      0% { transform: translateX(-100%); }
      100% { transform: translateX(100%); }
    }
    
    .hidden { display: none !important; }
    
    .particles {
      position: fixed;
      top: 0; left: 0;
      width: 100%; height: 100%;
      pointer-events: none;
      z-index: 1;
    }
    
    .particle {
      position: absolute;
      width: 4px;
      height: 4px;
      border-radius: 50%;
      background: rgba(255,255,255,0.4);
      animation: quantum-float 15s linear infinite;
    }
    
    @keyframes quantum-float {
      0% { 
        transform: translateY(100vh) scale(0) rotate(0deg); 
        opacity: 0; 
        filter: blur(2px);
      }
      10% { opacity: 1; filter: blur(0px); }
      90% { opacity: 1; filter: blur(0px); }
      100% { 
        transform: translateY(-20vh) scale(2) rotate(720deg); 
        opacity: 0; 
        filter: blur(3px);
      }
    }
    
    .instruction {
      position: fixed;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      font-size: 16px;
      color: rgba(255,255,255,0.8);
      text-align: center;
      letter-spacing: 3px;
      opacity: 0;
      transition: opacity 3s ease;
      margin-top: 100px;
      font-weight: 600;
      text-transform: uppercase;
    }
    
    .instruction.show { opacity: 1; }

    .cinematic-overlay {
      position: fixed;
      top: 0; left: 0;
      width: 100%; height: 100%;
      pointer-events: none;
      background: radial-gradient(ellipse at center, transparent 20%, rgba(0,0,0,0.7) 100%);
      opacity: 0;
      transition: opacity 4s cubic-bezier(0.25, 0.46, 0.45, 0.94);
      z-index: 2;
    }
    
    .cinematic-overlay.active { opacity: 1; }
    
    .theme-text {
      position: fixed;
      bottom: 40px;
      right: 40px;
      font-size: 14px;
      color: rgba(255,255,255,0.7);
      text-transform: uppercase;
      letter-spacing: 4px;
      opacity: 0;
      transition: opacity 3s ease;
      font-weight: 700;
      text-shadow: 0 0 20px rgba(255,255,255,0.3);
    }
    
    .theme-text.visible { opacity: 1; }

    .spectrum-viz {
      position: fixed;
      bottom: 0;
      left: 0;
      width: 100%;
      height: 120px;
      pointer-events: none;
      z-index: 3;
    }
    
    .spectrum-bar {
      position: absolute;
      bottom: 0;
      width: 6px;
      background: linear-gradient(0deg, 
        rgba(74,144,226,0.9), 
        rgba(155,89,182,0.7), 
        rgba(231,76,60,0.5),
        rgba(255,255,255,0.3)
      );
      border-radius: 3px 3px 0 0;
      transition: height 0.08s cubic-bezier(0.25, 0.46, 0.45, 0.94);
      margin-right: 2px;
    }

    .neural-patterns {
      position: fixed;
      top: 0; left: 0;
      width: 100%; height: 100%;
      pointer-events: none;
      z-index: 1;
    }

    .neural-node {
      position: absolute;
      width: 3px;
      height: 3px;
      background: rgba(255,255,255,0.6);
      border-radius: 50%;
      animation: neural-pulse 4s ease-in-out infinite;
    }

    @keyframes neural-pulse {
      0%, 100% { opacity: 0.3; transform: scale(1); }
      50% { opacity: 1; transform: scale(1.5); }
    }

    .behavioral-indicator {
      font-size: 9px;
      color: rgba(255,255,255,0.6);
      margin: 2px 0;
      text-transform: uppercase;
      letter-spacing: 1px;
    }

    .mood-ring {
      width: 30px;
      height: 30px;
      border-radius: 50%;
      border: 2px solid rgba(255,255,255,0.3);
      margin: 8px auto;
      transition: all 0.5s ease;
      position: relative;
    }

    .mood-ring::before {
      content: '';
      position: absolute;
      top: 2px; left: 2px; right: 2px; bottom: 2px;
      border-radius: 50%;
      background: radial-gradient(circle, rgba(255,255,255,0.4), transparent);
      transition: all 0.5s ease;
    }

    .heart-rate-canvas {
      position: fixed;
      bottom: 150px;
      left: 20px;
      width: 100px;
      height: 100px;
      opacity: 0.5;
      z-index: 5;
      pointer-events: none;
    }
  </style>
</head>
<body>
  <div class="start-screen" id="startScreen">
    <div class="start-btn" id="startBtn">
      INITIATE
    </div>
  </div>
  
  <div class="evolution-space" id="evolutionSpace">
    <div class="orb" id="orb"></div>
    
    <div class="instruction" id="instruction">Neural Sync Activating</div>
    
    <div class="ui-corner top-left">
      <div class="stage-name" id="stageName">Dormant</div>
      <div class="metric">State: <span id="currentState">Awaiting</span></div>
      <div class="metric">Pattern: <span id="behaviorPattern">None</span></div>
      <div class="metric">Ambient Vibe: <span id="ambientVibe">Silent</span></div>
      <div class="metric">Heart Rate: <span id="heartRateDisplay">--</span></div> <!-- New UI for heart rate -->
    </div>
    
    <div class="ui-corner bottom-left">
      <div class="metric">Motion Flow</div>
      <div class="bar">
        <div class="bar-fill" id="motionBar"></div>
      </div>
      <div class="metric">Neural Sync</div>
      <div class="bar">
        <div class="bar-fill" id="neuralBar"></div>
      </div>
      <div class="metric">Emotion Level</div>
      <div class="bar">
        <div class="bar-fill" id="emotionBar"></div>
      </div>
      <div class="metric">Ambient Energy</div>
      <div class="bar">
        <div class="bar-fill" id="ambientBar"></div>
      </div>
      <div class="metric">Pulse Sync</div> <!-- New bar for heart rate sync -->
      <div class="bar">
        <div class="bar-fill" id="pulseBar"></div>
      </div>
    </div>
    
    <div class="ui-corner top-right">
      <div class="metric">Tempo: <span id="bpmDisplay">--</span></div>
      <div class="metric">Key: <span id="keyDisplay">--</span></div>
      <div class="metric">Voices: <span id="voiceCount">0</span></div>
      <div class="metric">Complexity: <span id="complexityLevel">0</span></div>
    </div>

    <div class="ui-corner bottom-right">
      <div class="mood-ring" id="moodRing"></div>
      <div class="behavioral-indicator" id="behaviorIndicator">Listening</div>
      <div class="metric">Flow State: <span id="flowState">0%</span></div>
    </div>
    
    <div class="spectrum-viz" id="spectrumViz"></div>
    <div class="neural-patterns" id="neuralPatterns"></div>
    <video id="heartVideo" playsinline autoplay muted style="display: none;"></video>
    <canvas id="heartCanvas" class="heart-rate-canvas"></canvas> <!-- New canvas for webcam preview -->
  </div>

  <div class="cinematic-overlay" id="cinematicOverlay"></div>
  <div class="theme-text" id="themeText"></div>

  <script>
    class EnhancedVoidEngine {
      constructor() {
        this.ctx = null;
        this.active = false;
        this.analyser = null;
        this.dataArray = null;
        
        // Enhanced Musical Intelligence
        this.musicalBrain = {
          bpm: 72,
          key: 'D',
          mode: 'dorian',
          tension: 0,
          release: 0,
          complexity: 0,
          emotionalState: 'neutral',
          flowState: 0
        };
        
        // Behavioral Pattern Recognition
        this.behaviorAnalyzer = {
          patterns: [],
          currentPattern: 'exploring',
          confidence: 0,
          gestureMemory: [],
          rhythmicPrediction: [],
          emotionalTrajectory: [],
          flowMoments: []
        };
        
        // Advanced Motion Analysis
        this.motionSystem = {
          raw: 0,
          smoothed: 0,
          velocity: { x: 0, y: 0, z: 0 },
          acceleration: { x: 0, y: 0, z: 0 },
          jerk: { x: 0, y: 0, z: 0 },
          history: [],
          patterns: {
            walking: 0,
            dancing: 0,
            working: 0,
            resting: 0,
            exercising: 0
          }
        };
        
        // Procedural Composition Engine
        this.composer = {
          phrases: [],
          currentPhrase: null,
          melodicContour: [],
          harmonicProgression: [],
          rhythmicComplexity: 1,
          orchestrationDensity: 0,
          adaptiveArrangement: true
        };
        
        // Neural Network Simulation for Music AI
        this.neuralNetwork = {
          inputLayer: new Array(12).fill(0),
          hiddenLayers: [new Array(24).fill(0), new Array(16).fill(0)],
          outputLayer: new Array(8).fill(0),
          weights: this.initializeWeights(),
          learningRate: 0.001
        };
        
        // Spatial Audio Engine
        this.spatialEngine = {
          listener: null,
          sources: new Map(),
          hrtf: true,
          roomAcoustics: 'cathedral',
          binaural: false
        };
        
        // Cinematic Storytelling
        this.narrative = {
          arc: 'exposition',
          intensity: 0,
          themes: {
            awakening: { active: false, weight: 0 },
            journey: { active: false, weight: 0 },
            conflict: { active: false, weight: 0 },
            resolution: { active: false, weight: 0 },
            transcendence: { active: false, weight: 0 }
          },
          currentMood: 'mysterious'
        };
        
        // Enhanced Voice Management
        this.voiceManager = {
          pools: {
            percussion: { voices: [], max: 6 },
            bass: { voices: [], max: 4 },
            harmony: { voices: [], max: 12 },
            melody: { voices: [], max: 8 },
            atmosphere: { voices: [], max: 10 },
            neural: { voices: [], max: 16 }
          },
          allocation: new Map(),
          priority: new Map()
        };
        
        // Real-time Audio Effects
        this.effects = {
          master: { compressor: null, limiter: null, reverb: null },
          adaptive: { 
            filter: null, 
            delay: null, 
            chorus: null, 
            granular: null,
            spectral: null 
          },
          neural: { 
            morph: null, 
            predict: null 
          }
        };
        
        this.elements = {};
        this.spectrumBars = [];
        this.neuralNodes = [];
        this.isInitialized = false;
        
        // Time and rhythm
        this.timeSignature = [4, 4];
        this.subdivision = 16;
        this.stepCount = 0;
        this.measures = 0;
        
        // Ambient Environment Analyzer
        this.ambientAnalyzer = {
          micStream: null,
          micAnalyser: null,
          micData: new Uint8Array(128),
          energy: 0,
          spectralCentroid: 0,
          lowEnergy: 0,
          midEnergy: 0,
          highEnergy: 0,
          vibe: 'silent',
          history: []
        };

        // New: Webcam Heart Rate Analyzer (rPPG - remote Photoplethysmography)
        this.heartRateAnalyzer = {
          video: null,
          canvas: null,
          context: null,
          bpm: 0,
          samples: [], // Array of green channel averages over time
          timestamps: [], // Corresponding timestamps
          lastTime: 0,
          sampleInterval: 33, // ~30 fps
          windowSize: 300, // Number of samples for BPM calculation (10 seconds at 30fps)
          confidence: 0
        };
        
        this.init();
      }

      init() {
        // Cache DOM elements
        const elementIds = [
          'startScreen', 'startBtn', 'evolutionSpace', 'orb', 'instruction',
          'stageName', 'currentState', 'behaviorPattern', 'motionBar', 
          'neuralBar', 'emotionBar', 'bpmDisplay', 'keyDisplay', 'voiceCount',
          'complexityLevel', 'moodRing', 'behaviorIndicator', 'flowState',
          'cinematicOverlay', 'themeText', 'spectrumViz', 'neuralPatterns',
          'ambientVibe', 'ambientBar',
          'heartRateDisplay', 'pulseBar', // New elements
          'heartVideo', 'heartCanvas'
        ];
        
        elementIds.forEach(id => {
          this.elements[id] = document.getElementById(id);
        });
        
        this.elements.startBtn.onclick = () => this.initializeEngine();
        this.setupAdvancedMotionDetection();
        this.setupBehavioralAnalysis();
        this.setupNeuralVisualization();
        this.setupSpectrumAnalyzer();
      }

      initializeWeights() {
        // Initialize neural network weights with Xavier initialization
        const weights = {
          inputToHidden1: this.createMatrix(12, 24),
          hidden1ToHidden2: this.createMatrix(24, 16),
          hidden2ToOutput: this.createMatrix(16, 8)
        };
        
        // Initialize with small random values
        Object.values(weights).forEach(matrix => {
          matrix.forEach(row => {
            for (let i = 0; i < row.length; i++) {
              row[i] = (Math.random() - 0.5) * 0.1;
            }
          });
        });
        
        return weights;
      }

      createMatrix(rows, cols) {
        return Array(rows).fill().map(() => Array(cols).fill(0));
      }

      setupAdvancedMotionDetection() {
        // Enhanced motion detection with gesture recognition
        let lastMotionData = { x: 0, y: 0, z: 0, timestamp: 0 };
        
        window.addEventListener('devicemotion', (event) => {
          if (!this.active) return;
          
          const acc = event.accelerationIncludingGravity;
          if (!acc || acc.x === null) return;
          
          const now = performance.now();
          const dt = (now - lastMotionData.timestamp) / 1000;
          
          if (dt > 0) {
            // Calculate velocity and acceleration
            this.motionSystem.velocity.x = (acc.x - lastMotionData.x) / dt;
            this.motionSystem.velocity.y = (acc.y - lastMotionData.y) / dt;
            this.motionSystem.velocity.z = (acc.z - lastMotionData.z) / dt;
            
            // Calculate jerk (rate of change of acceleration)
            this.motionSystem.jerk.x = (acc.x - this.motionSystem.acceleration.x) / dt;
            this.motionSystem.jerk.y = (acc.y - this.motionSystem.acceleration.y) / dt;
            this.motionSystem.jerk.z = (acc.z - this.motionSystem.acceleration.z) / dt;
            
            this.motionSystem.acceleration = { x: acc.x, y: acc.y, z: acc.z };
          }
          
          // Calculate motion magnitude with sophisticated smoothing
          const magnitude = Math.sqrt(acc.x*acc.x + acc.y*acc.y + acc.z*acc.z);
          this.motionSystem.raw = magnitude;
          this.motionSystem.smoothed = this.motionSystem.smoothed * 0.85 + magnitude * 0.15;
          
          // Store motion history
          this.motionSystem.history.push({
            magnitude,
            velocity: { ...this.motionSystem.velocity },
            acceleration: { ...this.motionSystem.acceleration },
            jerk: { ...this.motionSystem.jerk },
            timestamp: now
          });
          
          if (this.motionSystem.history.length > 300) {
            this.motionSystem.history.shift();
          }
          
          this.analyzeMotionPatterns();
          this.updateNeuralInputs();
          
          lastMotionData = { x: acc.x, y: acc.y, z: acc.z, timestamp: now };
        });

        // Enhanced mouse/touch motion with gesture recognition
        let gestureBuffer = [];
        let lastPointer = { x: 0, y: 0, time: 0 };
        
        const handlePointerMove = (e) => {
          if (!this.active) return;
          
          const now = performance.now();
          const x = e.clientX / window.innerWidth;
          const y = e.clientY / window.innerHeight;
          
          const dt = now - lastPointer.time;
          if (dt > 0) {
            const vx = (x - lastPointer.x) / dt * 1000;
            const vy = (y - lastPointer.y) / dt * 1000;
            
            gestureBuffer.push({ x, y, vx, vy, time: now });
            if (gestureBuffer.length > 50) gestureBuffer.shift();
            
            this.analyzeGestures(gestureBuffer);
          }
          
          lastPointer = { x, y, time: now };
        };
        
        window.addEventListener('mousemove', handlePointerMove);
        window.addEventListener('touchmove', (e) => {
          if (e.touches.length > 0) {
            handlePointerMove(e.touches[0]);
          }
        });
      }

      analyzeMotionPatterns() {
        if (this.motionSystem.history.length < 50) return;
        
        const recent = this.motionSystem.history.slice(-50);
        
        // Analyze for different motion patterns
        const avgMagnitude = recent.reduce((sum, m) => sum + m.magnitude, 0) / recent.length;
        const variance = recent.reduce((sum, m) => sum + Math.pow(m.magnitude - avgMagnitude, 2), 0) / recent.length;
        const rhythmicity = this.calculateRhythmicity(recent);
        
        // Pattern recognition
        this.motionSystem.patterns.walking = this.detectWalking(recent);
        this.motionSystem.patterns.dancing = this.detectDancing(recent, rhythmicity);
        this.motionSystem.patterns.working = this.detectWorking(recent);
        this.motionSystem.patterns.resting = avgMagnitude < 0.5 ? 1 : 0;
        this.motionSystem.patterns.exercising = this.detectExercising(recent);
        
        // Update behavioral pattern
        this.updateBehavioralPattern();
      }

      calculateRhythmicity(motionData) {
        // FFT-based rhythm detection would be ideal, but let's use autocorrelation
        const magnitudes = motionData.map(m => m.magnitude);
        let maxCorrelation = 0;
        
        for (let lag = 5; lag < 25; lag++) {
          let correlation = 0;
          let count = 0;
          
          for (let i = 0; i < magnitudes.length - lag; i++) {
            correlation += magnitudes[i] * magnitudes[i + lag];
            count++;
          }
          
          if (count > 0) {
            correlation /= count;
            maxCorrelation = Math.max(maxCorrelation, correlation);
          }
        }
        
        return Math.min(maxCorrelation / 10, 1); // Normalize
      }

      detectWalking(motionData) {
        const avgMag = motionData.reduce((sum, m) => sum + m.magnitude, 0) / motionData.length;
        const regularity = this.calculateRhythmicity(motionData);
        
        return (avgMag > 1 && avgMag < 4 && regularity > 0.3) ? regularity : 0;
      }

      detectDancing(motionData, rhythmicity) {
        const avgMag = motionData.reduce((sum, m) => sum + m.magnitude, 0) / motionData.length;
        const variance = motionData.reduce((sum, m) => sum + Math.pow(m.magnitude - avgMag, 2), 0) / motionData.length;
        
        return (avgMag > 2 && variance > 2 && rhythmicity > 0.4) ? Math.min(rhythmicity * variance * 0.1, 1) : 0;
      }

      detectWorking(motionData) {
        const recent = motionData.slice(-20);
        const avgMag = recent.reduce((sum, m) => sum + m.magnitude, 0) / recent.length;
        
        // Small, focused movements
        return (avgMag > 0.5 && avgMag < 2) ? Math.min(avgMag * 0.5, 1) : 0;
      }

      detectExercising(motionData) {
        const avgMag = motionData.reduce((sum, m) => sum + m.magnitude, 0) / motionData.length;
        const variance = motionData.reduce((sum, m) => sum + Math.pow(m.magnitude - avgMag, 2), 0) / motionData.length;
        
        // High intensity, high variance movements
        return (avgMag > 4 && variance > 5) ? Math.min(avgMag * variance * 0.02, 1) : 0;
      }

      analyzeGestures(gestureBuffer) {
        if (gestureBuffer.length < 10) return;
        
        // Detect gesture patterns: circles, lines, curves
        const path = gestureBuffer.map(g => ({ x: g.x, y: g.y }));
        const velocities = gestureBuffer.map(g => Math.sqrt(g.vx*g.vx + g.vy*g.vy));
        
        // Store in behavior analyzer
        this.behaviorAnalyzer.gestureMemory.push({
          path,
          velocities,
          timestamp: performance.now(),
          type: this.classifyGesture(path, velocities)
        });
        
        if (this.behaviorAnalyzer.gestureMemory.length > 20) {
          this.behaviorAnalyzer.gestureMemory.shift();
        }
      }

      classifyGesture(path, velocities) {
        if (path.length < 5) return 'tap';
        
        const avgVelocity = velocities.reduce((a, b) => a + b, 0) / velocities.length;
        const pathLength = this.calculatePathLength(path);
        const boundingBox = this.getBoundingBox(path);
        const aspectRatio = boundingBox.width / boundingBox.height;
        
        if (avgVelocity > 0.5 && pathLength > 0.2) {
          if (this.isCircular(path)) return 'circle';
          if (aspectRatio > 3 || aspectRatio < 0.33) return 'line';
          return 'curve';
        }
        
        return avgVelocity > 0.1 ? 'gentle' : 'still';
      }

      calculatePathLength(path) {
        let length = 0;
        for (let i = 1; i < path.length; i++) {
          const dx = path[i].x - path[i-1].x;
          const dy = path[i].y - path[i-1].y;
          length += Math.sqrt(dx*dx + dy*dy);
        }
        return length;
      }

      getBoundingBox(path) {
        const xs = path.map(p => p.x);
        const ys = path.map(p => p.y);
        return {
          width: Math.max(...xs) - Math.min(...xs),
          height: Math.max(...ys) - Math.min(...ys)
        };
      }

      isCircular(path) {
        if (path.length < 8) return false;
        
        const center = path.reduce((acc, p) => ({ 
          x: acc.x + p.x, 
          y: acc.y + p.y 
        }), { x: 0, y: 0 });
        center.x /= path.length;
        center.y /= path.length;
        
        const distances = path.map(p => 
          Math.sqrt((p.x - center.x)**2 + (p.y - center.y)**2)
        );
        
        const avgDistance = distances.reduce((a, b) => a + b, 0) / distances.length;
        const variance = distances.reduce((sum, d) => 
          sum + Math.pow(d - avgDistance, 2), 0) / distances.length;
        
        return variance < 0.01; // Low variance indicates circular motion
      }

      updateBehavioralPattern() {
        const patterns = this.motionSystem.patterns;
        const dominant = Object.keys(patterns).reduce((a, b) => 
          patterns[a] > patterns[b] ? a : b
        );
        
        if (patterns[dominant] > 0.3) {
          this.behaviorAnalyzer.currentPattern = dominant;
          this.behaviorAnalyzer.confidence = patterns[dominant];
        } else {
          this.behaviorAnalyzer.currentPattern = 'exploring';
          this.behaviorAnalyzer.confidence = 0.5;
        }
        
        // Update flow state based on pattern consistency
        this.updateFlowState();
      }

      updateFlowState() {
        const recentPatterns = this.behaviorAnalyzer.patterns.slice(-10);
        if (recentPatterns.length < 5) return;
        
        const consistency = recentPatterns.filter(p => 
          p === this.behaviorAnalyzer.currentPattern
        ).length / recentPatterns.length;
        
        const intensity = this.motionSystem.smoothed;
        const engagement = Math.min(intensity * consistency, 1);
        
        this.musicalBrain.flowState = this.musicalBrain.flowState * 0.9 + engagement * 0.1;
      }

      setupBehavioralAnalysis() {
        // Analyze user behavior patterns every few seconds
        setInterval(() => {
          if (!this.active) return;
          
          this.analyzeBehavioralTrends();
          this.updateEmotionalTrajectory();
          this.adaptMusicalResponse();
        }, 2000);
      }

      analyzeBehavioralTrends() {
        const now = performance.now();
        const recentMotion = this.motionSystem.history.filter(m => 
          now - m.timestamp < 10000 // Last 10 seconds
        );
        
        if (recentMotion.length < 10) return;
        
        // Calculate trend metrics
        const intensityTrend = this.calculateTrend(recentMotion.map(m => m.magnitude));
        const complexityTrend = this.calculateTrend(recentMotion.map(m => 
          Math.sqrt(m.velocity.x**2 + m.velocity.y**2 + m.velocity.z**2)
        ));
        
        // Update musical brain
        this.musicalBrain.tension = Math.max(0, Math.min(1, intensityTrend + 0.5));
        this.musicalBrain.complexity = Math.max(0, Math.min(1, complexityTrend + 0.5));
        
        // Store pattern for learning
        this.behaviorAnalyzer.patterns.push({
          pattern: this.behaviorAnalyzer.currentPattern,
          confidence: this.behaviorAnalyzer.confidence,
          intensity: this.motionSystem.smoothed,
          complexity: this.musicalBrain.complexity,
          timestamp: now
        });
        
        if (this.behaviorAnalyzer.patterns.length > 100) {
          this.behaviorAnalyzer.patterns.shift();
        }
      }

      calculateTrend(data) {
        if (data.length < 2) return 0;
        
        // Simple linear regression slope
        const n = data.length;
        const sumX = n * (n - 1) / 2;
        const sumY = data.reduce((a, b) => a + b, 0);
        const sumXY = data.reduce((sum, y, x) => sum + x * y, 0);
        const sumX2 = n * (n - 1) * (2 * n - 1) / 6;
        
        return (n * sumXY - sumX * sumY) / (n * sumX2 - sumX * sumX);
      }

      updateEmotionalTrajectory() {
        // Map motion patterns to emotional states
        const patterns = this.motionSystem.patterns;
        let emotionalVector = { valence: 0, arousal: 0 };
        
        if (patterns.dancing > 0.5) {
          emotionalVector = { valence: 0.8, arousal: 0.9 };
          this.musicalBrain.emotionalState = 'joyful';
        } else if (patterns.exercising > 0.5) {
          emotionalVector = { valence: 0.6, arousal: 0.8 };
          this.musicalBrain.emotionalState = 'energetic';
        } else if (patterns.walking > 0.5) {
          emotionalVector = { valence: 0.4, arousal: 0.5 };
          this.musicalBrain.emotionalState = 'contemplative';
        } else if (patterns.working > 0.5) {
          emotionalVector = { valence: 0.3, arousal: 0.6 };
          this.musicalBrain.emotionalState = 'focused';
        } else if (patterns.resting > 0.5) {
          emotionalVector = { valence: 0.2, arousal: 0.2 };
          this.musicalBrain.emotionalState = 'peaceful';
        } else {
          emotionalVector = { valence: 0.5, arousal: 0.3 };
          this.musicalBrain.emotionalState = 'neutral';
        }
        
        // Store emotional trajectory
        this.behaviorAnalyzer.emotionalTrajectory.push({
          ...emotionalVector,
          state: this.musicalBrain.emotionalState,
          timestamp: performance.now()
        });
        
        if (this.behaviorAnalyzer.emotionalTrajectory.length > 50) {
          this.behaviorAnalyzer.emotionalTrajectory.shift();
        }
      }

      updateNeuralInputs() {
        // Prepare inputs for neural network
        const inputs = [
          this.motionSystem.smoothed / 10, // Normalized motion
          this.musicalBrain.tension,
          this.musicalBrain.complexity,
          this.musicalBrain.flowState,
          this.behaviorAnalyzer.confidence,
          Math.sin(performance.now() * 0.001), // Time component
          Math.cos(performance.now() * 0.0005), // Slower time component
          this.motionSystem.patterns.dancing,
          this.motionSystem.patterns.walking,
          this.motionSystem.patterns.working,
          this.motionSystem.patterns.resting,
          this.motionSystem.patterns.exercising
        ];
        
        this.neuralNetwork.inputLayer = inputs;
        this.runNeuralForward();
      }

      runNeuralForward() {
        // Simple feedforward neural network
        const { inputLayer, hiddenLayers, outputLayer, weights } = this.neuralNetwork;
        
        // Input to first hidden layer
        for (let i = 0; i < hiddenLayers[0].length; i++) {
          let sum = 0;
          for (let j = 0; j < inputLayer.length; j++) {
            sum += inputLayer[j] * weights.inputToHidden1[j][i];
          }
          hiddenLayers[0][i] = this.sigmoid(sum);
        }
        
        // First to second hidden layer
        for (let i = 0; i < hiddenLayers[1].length; i++) {
          let sum = 0;
          for (let j = 0; j < hiddenLayers[0].length; j++) {
            sum += hiddenLayers[0][j] * weights.hidden1ToHidden2[j][i];
          }
          hiddenLayers[1][i] = this.sigmoid(sum);
        }
        
        // Second hidden to output
        for (let i = 0; i < outputLayer.length; i++) {
          let sum = 0;
          for (let j = 0; j < hiddenLayers[1].length; j++) {
            sum += hiddenLayers[1][j] * weights.hidden2ToOutput[j][i];
          }
          outputLayer[i] = this.sigmoid(sum);
        }
        
        // Map outputs to musical parameters
        this.applyNeuralOutputs();
      }

      sigmoid(x) {
        return 1 / (1 + Math.exp(-x));
      }

      applyNeuralOutputs() {
        const outputs = this.neuralNetwork.outputLayer;
        
        // Map neural outputs to musical parameters
        this.musicalBrain.bpm = 60 + outputs[0] * 120; // 60-180 BPM
        this.composer.rhythmicComplexity = outputs[1];
        this.composer.orchestrationDensity = outputs[2];
        this.musicalBrain.tension = outputs[3];
        this.musicalBrain.release = outputs[4];
        
        // Update harmonic and melodic parameters
        this.updateMusicalStructure();
      }

      updateMusicalStructure() {
        // Adaptive key changes based on emotional trajectory
        const recentEmotions = this.behaviorAnalyzer.emotionalTrajectory.slice(-5);
        if (recentEmotions.length > 0) {
          const avgValence = recentEmotions.reduce((sum, e) => sum + e.valence, 0) / recentEmotions.length;
          const avgArousal = recentEmotions.reduce((sum, e) => sum + e.arousal, 0) / recentEmotions.length;
          
          // Map to musical modes
          if (avgValence > 0.7 && avgArousal > 0.7) {
            this.musicalBrain.mode = 'lydian'; // Bright, uplifting
          } else if (avgValence > 0.5 && avgArousal > 0.5) {
            this.musicalBrain.mode = 'ionian'; // Major, happy
          } else if (avgValence < 0.3 && avgArousal < 0.4) {
            this.musicalBrain.mode = 'aeolian'; // Natural minor, sad
          } else if (avgValence < 0.4 && avgArousal > 0.6) {
            this.musicalBrain.mode = 'phrygian'; // Dark, intense
          } else {
            this.musicalBrain.mode = 'dorian'; // Balanced, contemplative
          }
        }
        
        // Update scale based on mode
        this.updateScale();
        this.generateHarmonicProgression();
      }

      updateScale() {
        const modes = {
          ionian: [0, 2, 4, 5, 7, 9, 11],
          dorian: [0, 2, 3, 5, 7, 9, 10],
          phrygian: [0, 1, 3, 5, 7, 8, 10],
          lydian: [0, 2, 4, 6, 7, 9, 11],
          mixolydian: [0, 2, 4, 5, 7, 9, 10],
          aeolian: [0, 2, 3, 5, 7, 8, 10],
          locrian: [0, 1, 3, 5, 6, 8, 10]
        };
        
        this.composer.scale = modes[this.musicalBrain.mode] || modes.dorian;
      }

      generateHarmonicProgression() {
        // Generate chord progressions based on current mode and emotional state
        const progressions = {
          joyful: [[0, 2, 4], [3, 5, 0], [1, 3, 5], [4, 6, 1]],
          energetic: [[0, 2, 4], [5, 0, 2], [3, 5, 0], [1, 3, 5]],
          contemplative: [[0, 2, 4], [1, 3, 5], [4, 6, 1], [0, 2, 4]],
          focused: [[0, 2, 4], [4, 6, 1], [1, 3, 5], [0, 2, 4]],
          peaceful: [[0, 2, 4], [3, 5, 0], [6, 1, 3], [0, 2, 4]],
          neutral: [[0, 2, 4], [1, 3, 5], [3, 5, 0], [0, 2, 4]]
        };
        
        this.composer.harmonicProgression = progressions[this.musicalBrain.emotionalState] || progressions.neutral;
      }

      adaptMusicalResponse() {
        // This is where the magic happens - adapt the entire musical arrangement
        // based on analyzed behavior patterns
        
        const intensity = this.motionSystem.smoothed;
        const complexity = this.musicalBrain.complexity;
        const flowState = this.musicalBrain.flowState;
        
        // Dynamic layer activation
        this.updateLayerActivation(intensity, complexity, flowState);
        
        // Adaptive tempo
        this.adaptTempo();
        
        // Dynamic orchestration
        this.adaptOrchestration();
        
        // Narrative progression
        this.updateNarrativeArc();
      }

      updateLayerActivation(intensity, complexity, flowState) {
        // More sophisticated layer management based on multiple factors
        const layers = {
          percussion: intensity > 0.2,
          bass: intensity > 0.3 && this.behaviorAnalyzer.currentPattern !== 'resting',
          harmony: complexity > 0.4 || flowState > 0.5,
          melody: intensity > 0.5 || this.musicalBrain.emotionalState === 'joyful',
          atmosphere: intensity < 0.3 || this.musicalBrain.emotionalState === 'peaceful',
          neural: flowState > 0.7 // AI-generated parts when in flow state
        };
        
        this.voiceManager.layerStates = layers;
      }

      adaptTempo() {
        const baseTempos = {
          resting: 60,
          working: 80,
          walking: 100,
          dancing: 120,
          exercising: 140
        };
        
        const baseTempo = baseTempos[this.behaviorAnalyzer.currentPattern] || 80;
        const intensityModifier = this.motionSystem.smoothed * 20;
        const flowModifier = this.musicalBrain.flowState * 10;
        
        let targetTempo = baseTempo + intensityModifier + flowModifier;
        
        // New: Integrate heart rate if available
        if (this.heartRateAnalyzer.bpm > 40 && this.heartRateAnalyzer.bpm < 200 && this.heartRateAnalyzer.confidence > 0.5) {
          targetTempo = targetTempo * 0.7 + this.heartRateAnalyzer.bpm * 0.3; // Blend with heart rate for bio-sync
        }
        
        // Smooth tempo transitions
        this.musicalBrain.bpm = this.musicalBrain.bpm * 0.95 + targetTempo * 0.05;
        this.musicalBrain.bpm = Math.max(40, Math.min(180, this.musicalBrain.bpm));
      }

      adaptOrchestration() {
        // Dynamic orchestration based on complexity and emotional state
        const density = this.composer.orchestrationDensity;
        const emotion = this.musicalBrain.emotionalState;
        
        if (emotion === 'joyful' && density > 0.7) {
          this.composer.arrangement = 'full_orchestra';
        } else if (emotion === 'energetic' && density > 0.5) {
          this.composer.arrangement = 'rock_ensemble';
        } else if (emotion === 'contemplative') {
          this.composer.arrangement = 'chamber_group';
        } else if (emotion === 'peaceful') {
          this.composer.arrangement = 'ambient_pad';
        } else {
          this.composer.arrangement = 'minimal';
        }
      }

      updateNarrativeArc() {
        // Cinematic storytelling progression
        const totalMotion = this.motionSystem.history.reduce((sum, m) => sum + m.magnitude, 0);
        const sessionLength = performance.now() / 1000; // seconds
        
        if (sessionLength < 30) {
          this.narrative.arc = 'exposition';
        } else if (sessionLength < 120 || totalMotion < 100) {
          this.narrative.arc = 'rising_action';
        } else if (this.musicalBrain.tension > 0.7) {
          this.narrative.arc = 'climax';
        } else if (this.musicalBrain.release > 0.5) {
          this.narrative.arc = 'falling_action';
        } else {
          this.narrative.arc = 'resolution';
        }
        
        this.updateThemeWeights();
      }

      updateThemeWeights() {
        const arc = this.narrative.arc;
        const emotion = this.musicalBrain.emotionalState;
        
        // Reset theme weights
        Object.keys(this.narrative.themes).forEach(theme => {
          this.narrative.themes[theme].weight *= 0.95; // Gradual decay
        });
        
        // Boost relevant themes based on current state
        switch (arc) {
          case 'exposition':
            this.narrative.themes.awakening.weight = Math.min(1, this.narrative.themes.awakening.weight + 0.1);
            break;
          case 'rising_action':
            this.narrative.themes.journey.weight = Math.min(1, this.narrative.themes.journey.weight + 0.1);
            break;
          case 'climax':
            this.narrative.themes.conflict.weight = Math.min(1, this.narrative.themes.conflict.weight + 0.15);
            break;
          case 'falling_action':
            this.narrative.themes.resolution.weight = Math.min(1, this.narrative.themes.resolution.weight + 0.1);
            break;
          case 'resolution':
            this.narrative.themes.transcendence.weight = Math.min(1, this.narrative.themes.transcendence.weight + 0.05);
            break;
        }
        
        // Activate themes above threshold
        Object.keys(this.narrative.themes).forEach(theme => {
          this.narrative.themes[theme].active = this.narrative.themes[theme].weight > 0.3;
        });
      }

      setupNeuralVisualization() {
        // Create neural network visualization nodes
        for (let i = 0; i < 24; i++) {
          const node = document.createElement('div');
          node.className = 'neural-node';
          node.style.left = Math.random() * 100 + '%';
          node.style.top = Math.random() * 100 + '%';
          node.style.animationDelay = Math.random() * 4 + 's';
          this.elements.neuralPatterns.appendChild(node);
          this.neuralNodes.push(node);
        }
      }

      setupSpectrumAnalyzer() {
        // Enhanced spectrum analyzer with more bars and better responsiveness
        for (let i = 0; i < 80; i++) {
          const bar = document.createElement('div');
          bar.className = 'spectrum-bar';
          bar.style.left = (i * 8) + 'px';
          bar.style.height = '0px';
          this.elements.spectrumViz.appendChild(bar);
          this.spectrumBars.push(bar);
        }
      }

      async initializeEngine() {
        try {
          // Request permissions for advanced motion detection
          if (typeof DeviceMotionEvent?.requestPermission === 'function') {
            const motionPermission = await DeviceMotionEvent.requestPermission();
            if (motionPermission !== 'granted') {
              alert('Motion permission required for neural synchronization');
              return;
            }
          }

          if (typeof DeviceOrientationEvent?.requestPermission === 'function') {
            const orientationPermission = await DeviceOrientationEvent.requestPermission();
            if (orientationPermission !== 'granted') {
              alert('Orientation permission required for spatial immersion');
              return;
            }
          }

          // Initialize Web Audio API with advanced features
          this.ctx = new (window.AudioContext || window.webkitAudioContext)();
          await this.ctx.resume();
          
          this.setupAdvancedAudioChain();
          this.setupSpatialAudio();
          this.initializeVoiceManager();

          // UI transitions
          this.elements.startScreen.classList.add('hidden');
          this.evolutionSpace.classList.add('active');
          
          setTimeout(() => {
            this.elements.instruction.classList.add('show');
            setTimeout(() => this.elements.instruction.classList.remove('show'), 5000);
          }, 1000);

          this.active = true;
          this.isInitialized = true;
          this.startAdvancedSequencer();
          this.startAdvancedAnimation();
          
          // New: Setup ambient and heart rate analyzers
          this.setupAmbientAnalyzer();
          this.setupHeartRateAnalyzer();
        } catch (error) {
          console.error('Failed to initialize enhanced engine:', error);
          alert('Failed to initialize. Please ensure your browser supports Web Audio API.');
        }
      }

      setupAdvancedAudioChain() {
        // Create advanced audio analysis
        this.analyser = this.ctx.createAnalyser();
        this.analyser.fftSize = 256;
        this.analyser.smoothingTimeConstant = 0.8;
        this.dataArray = new Uint8Array(this.analyser.frequencyBinCount);
        
        // Master effects chain
        this.effects.master.compressor = this.ctx.createDynamicsCompressor();
        this.effects.master.compressor.threshold.value = -12;
        this.effects.master.compressor.knee.value = 20;
        this.effects.master.compressor.ratio.value = 12;
        this.effects.master.compressor.attack.value = 0.003;
        this.effects.master.compressor.release.value = 0.25;
        
        this.effects.master.limiter = this.ctx.createDynamicsCompressor();
        this.effects.master.limiter.threshold.value = -3;
        this.effects.master.limiter.knee.value = 0;
        this.effects.master.limiter.ratio.value = 20;
        this.effects.master.limiter.attack.value = 0.001;
        this.effects.master.limiter.release.value = 0.01;
        
        // Advanced reverb
        this.setupConvolutionReverb();
        
        // Adaptive effects
        this.setupAdaptiveEffects();
        
        // Master gain
        this.masterGain = this.ctx.createGain();
        this.masterGain.gain.value = 0.5;
        
        // Connect effects chain
        this.effects.master.compressor.connect(this.effects.master.reverb);
        this.effects.master.reverb.connect(this.effects.master.limiter);
        this.effects.master.limiter.connect(this.analyser);
        this.analyser.connect(this.masterGain);
        this.masterGain.connect(this.ctx.destination);
      }

      setupConvolutionReverb() {
        this.effects.master.reverb = this.ctx.createConvolver();
        
        // Generate impulse response for different room types
        const roomTypes = {
          cathedral: { length: 8, decay: 5, brightness: 0.3 },
          hall: { length: 4, decay: 3, brightness: 0.5 },
          chamber: { length: 2, decay: 2, brightness: 0.7 },
          ambient: { length: 12, decay: 8, brightness: 0.2 }
        };
        
        const room = roomTypes[this.spatialEngine.roomAcoustics] || roomTypes.cathedral;
        const buffer = this.ctx.createBuffer(2, this.ctx.sampleRate * room.length, this.ctx.sampleRate);
        
        for (let channel = 0; channel < 2; channel++) {
          const data = buffer.getChannelData(channel);
          for (let i = 0; i < data.length; i++) {
            const decay = Math.pow(1 - i / data.length, room.decay);
            const noise = (Math.random() * 2 - 1) * decay;
            data[i] = noise * (room.brightness + (1 - room.brightness) * Math.random());
          }
        }
        
        this.effects.master.reverb.buffer = buffer;
      }

      setupAdaptiveEffects() {
        // Adaptive filter for dynamic tone shaping
        this.effects.adaptive.filter = this.ctx.createBiquadFilter();
        this.effects.adaptive.filter.type = 'lowpass';
        this.effects.adaptive.filter.frequency.value = 1000;
        this.effects.adaptive.filter.Q.value = 1;
        
        // Adaptive delay for rhythmic enhancement
        this.effects.adaptive.delay = this.ctx.createDelay(1);
        this.effects.adaptive.delay.delayTime.value = 0.25;
        
        const delayFeedback = this.ctx.createGain();
        delayFeedback.gain.value = 0.3;
        const delayWet = this.ctx.createGain();
        delayWet.gain.value = 0.2;
        
        this.effects.adaptive.delay.connect(delayFeedback);
        delayFeedback.connect(this.effects.adaptive.delay);
        this.effects.adaptive.delay.connect(delayWet);
        delayWet.connect(this.effects.master.compressor);
        
        // Chorus for richness
        this.setupChorus();
        
        // Granular synthesis for textures
        this.setupGranularSynthesis();
      }

      setupChorus() {
        this.effects.adaptive.chorus = {
          delays: [],
          lfos: [],
          gains: []
        };
        
        const chorusVoices = 4;
        for (let i = 0; i < chorusVoices; i++) {
          const delay = this.ctx.createDelay(0.05);
          const lfo = this.ctx.createOscillator();
          const lfoGain = this.ctx.createGain();
          const voiceGain = this.ctx.createGain();
          
          lfo.frequency.value = 0.5 + i * 0.3;
          lfoGain.gain.value = 0.005;
          voiceGain.gain.value = 0.15;
          
          lfo.connect(lfoGain);
          lfoGain.connect(delay.delayTime);
          delay.connect(voiceGain);
          voiceGain.connect(this.effects.master.compressor);
          
          lfo.start();
          
          this.effects.adaptive.chorus.delays.push(delay);
          this.effects.adaptive.chorus.lfos.push(lfo);
          this.effects.adaptive.chorus.gains.push(voiceGain);
        }
      }

      setupGranularSynthesis() {
        // Granular synthesis for atmospheric textures
        this.effects.adaptive.granular = {
          grains: [],
          buffer: null
        };
        
        // Create a source buffer for granular synthesis
        const bufferLength = this.ctx.sampleRate * 2; // 2 seconds
        const buffer = this.ctx.createBuffer(1, bufferLength, this.ctx.sampleRate);
        const data = buffer.getChannelData(0);
        
        // Fill with harmonic content
        for (let i = 0; i < bufferLength; i++) {
          let sample = 0;
          for (let harmonic = 1; harmonic <= 8; harmonic++) {
            const freq = 110 * harmonic; // A2 and harmonics
            const phase = 2 * Math.PI * freq * i / this.ctx.sampleRate;
            sample += Math.sin(phase) / harmonic; // Sawtooth-like spectrum
          }
          data[i] = sample * 0.1;
        }
        
        this.effects.adaptive.granular.buffer = buffer;
      }

      setupSpatialAudio() {
        // Enhanced spatial audio setup
        this.spatialEngine.listener = this.ctx.listener;
        
        // Set listener in center of space
        this.spatialEngine.listener.positionX.value = 0;
        this.spatialEngine.listener.positionY.value = 0;
        this.spatialEngine.listener.positionZ.value = 0;
        
        // Initial orientation (looking forward)
        this.spatialEngine.listener.forwardX.value = 0;
        this.spatialEngine.listener.forwardY.value = 0;
        this.spatialEngine.listener.forwardZ.value = -1;
        this.spatialEngine.listener.upX.value = 0;
        this.spatialEngine.listener.upY.value = 1;
        this.spatialEngine.listener.upZ.value = 0;
      }

      initializeVoiceManager() {
        // Initialize voice pools with enhanced management
        Object.keys(this.voiceManager.pools).forEach(poolName => {
          this.voiceManager.pools[poolName].voices = [];
          this.voiceManager.allocation.set(poolName, 0);
          this.voiceManager.priority.set(poolName, this.getPriorityLevel(poolName));
        });
      }

      getPriorityLevel(poolName) {
        const priorities = {
          percussion: 10,
          bass: 9,
          melody: 8,
          harmony: 7,
          atmosphere: 6,
          neural: 5
        };
        return priorities[poolName] || 5;
      }

      startAdvancedSequencer() {
        let lastTime = performance.now();
        
        const tick = () => {
          if (!this.active) return;
          
          const now = performance.now();
          const deltaTime = now - lastTime;
          
          // Calculate timing based on current BPM
          const beatInterval = (60 / this.musicalBrain.bpm) * 1000; // milliseconds per beat
          const subdivisionInterval = beatInterval / 4; // 16th notes
          
          if (deltaTime >= subdivisionInterval) {
            this.playAdvancedStep();
            this.stepCount++;
            
            // Update measures
            if (this.stepCount % (this.subdivision * this.timeSignature[0]) === 0) {
              this.measures++;
              this.updateMusicalStructure();
            }
            
            lastTime = now;
          }
          
          // Update effects in real-time
          this.updateAdaptiveEffects();
          
          requestAnimationFrame(tick);
        };
        
        requestAnimationFrame(tick);
      }

      playAdvancedStep() {
        const beat = (this.stepCount % this.subdivision) / 4; // Current beat position
        const measure = Math.floor(this.stepCount / this.subdivision) % 4; // Current measure
        
        // Enhanced rhythm patterns based on behavioral analysis
        this.playAdaptivePercussion(beat, measure);
        this.playAdaptiveBass(beat, measure);
        this.playAdaptiveHarmony(beat, measure);
        this.playAdaptiveMelody(beat, measure);
        this.playAdaptiveAtmosphere(beat, measure);
        
        // Neural AI-generated parts when in flow state
        if (this.musicalBrain.flowState > 0.7) {
          this.playNeuralGeneration(beat, measure);
        }
        
        // Visual feedback
        if (beat === 0) {
          this.triggerBeatVisualization();
        }
      }

      playAdaptivePercussion(beat, measure) {
        if (!this.voiceManager.layerStates.percussion) return;
        
        const pattern = this.behaviorAnalyzer.currentPattern;
        const intensity = this.motionSystem.smoothed;
        
        // Kick drum pattern adaptation
        if (this.shouldPlayKick(beat, pattern)) {
          this.playAdvancedKick(intensity);
        }
        
        // Snare/clap pattern
        if (this.shouldPlaySnare(beat, pattern)) {
          this.playAdvancedSnare(intensity);
        }
        
        // Hi-hat patterns
        if (this.shouldPlayHihat(beat, pattern, intensity)) {
          this.playAdvancedHihat(intensity);
        }
      }

      shouldPlayKick(beat, pattern) {
        switch (pattern) {
          case 'dancing': return beat === 0 || beat === 2;
          case 'exercising': return beat === 0 || (beat === 1.5 && Math.random() < 0.7);
          case 'walking': return beat === 0 || beat === 2;
          case 'working': return beat === 0;
          default: return beat === 0;
        }
      }

      shouldPlaySnare(beat, pattern) {
        switch (pattern) {
          case 'dancing': return beat === 1 || beat === 3;
          case 'exercising': return beat === 1 || beat === 3 || (beat === 2.5 && Math.random() < 0.5);
          case 'working': return beat === 2 && Math.random() < 0.3;
          default: return beat === 1 || beat === 3;
        }
      }

      shouldPlayHihat(beat, pattern, intensity) {
        const probability = intensity * 0.5 + 0.2;
        switch (pattern) {
          case 'dancing': return Math.random() < probability;
          case 'exercising': return beat % 0.5 === 0 && Math.random() < probability;
          case 'working': return beat % 1 === 0.5 && Math.random() < probability * 0.5;
          default: return beat % 0.5 === 0 && Math.random() < probability * 0.7;
        }
      }

      playAdvancedKick(intensity) {
        const voice = this.allocateVoice('percussion', 0.8);
        if (!voice) return;
        
        const { osc, env, filter, panner } = voice;
        
        // Adaptive kick synthesis
        osc.type = 'sine';
        const baseFreq = 50 + intensity * 20;
        osc.frequency.setValueAtTime(baseFreq, this.ctx.currentTime);
        osc.frequency.exponentialRampToValueAtTime(25, this.ctx.currentTime + 0.5);
        
        // Intensity-based envelope
        const attackTime = 0.01;
        const releaseTime = 0.4 + intensity * 0.3;
        
        env.gain.setValueAtTime(0, this.ctx.currentTime);
        env.gain.linearRampToValueAtTime(1, this.ctx.currentTime + attackTime);
        env.gain.exponentialRampToValueAtTime(0.001, this.ctx.currentTime + releaseTime);
        
        // Dynamic filtering
        filter.type = 'lowpass';
        filter.frequency.value = 120 + intensity * 80;
        filter.Q.value = 2 + intensity;
        
        // Spatial positioning based on motion
        const position = this.calculateSpatialPosition('kick');
        panner.setPosition(position.x, position.y, position.z);
        
        this.connectVoiceChain(voice);
        osc.start();
        osc.stop(this.ctx.currentTime + releaseTime);
        
        this.scheduleVoiceRelease(voice, releaseTime);
      }

      playAdvancedSnare(intensity) {
        const voice = this.allocateVoice('percussion', 0.4);
        if (!voice) return;
        
        // Create noise component
        const noiseBuffer = this.createNoiseBuffer(0.1);
        const noiseSource = this.ctx.createBufferSource();
        noiseSource.buffer = noiseBuffer;
        
        const { osc, env, filter, panner } = voice;
        const noiseGain = this.ctx.createGain();
        
        // Tonal component
        osc.type = 'triangle';
        osc.frequency.value = 200 + intensity * 100;
        
        // Noise component for snare character
        noiseGain.gain.value = 0.7;
        noiseSource.connect(noiseGain);
        
        // Mix tonal and noise
        const mixer = this.ctx.createGain();
        mixer.gain.value = 0.8;
        
        osc.connect(mixer);
        noiseGain.connect(mixer);
        mixer.connect(filter);
        
        // Snare-specific envelope
        env.gain.setValueAtTime(0, this.ctx.currentTime);
        env.gain.linearRampToValueAtTime(1, this.ctx.currentTime + 0.005);
        env.gain.exponentialRampToValueAtTime(0.3, this.ctx.currentTime + 0.05);
        env.gain.exponentialRampToValueAtTime(0.001, this.ctx.currentTime + 0.25);
        
        filter.type = 'bandpass';
        filter.frequency.value = 1000 + intensity * 500;
        filter.Q.value = 3;
        
        const position = this.calculateSpatialPosition('snare');
        panner.setPosition(position.x, position.y, position.z);
        
        filter.connect(env);
        env.connect(panner);
        panner.connect(this.effects.adaptive.delay);
        
        osc.start();
        noiseSource.start();
        
        const duration = 0.25;
        osc.stop(this.ctx.currentTime + duration);
        noiseSource.stop(this.ctx.currentTime + duration);
        
        this.scheduleVoiceRelease(voice, duration);
      }

      playAdvancedHihat(intensity) {
        const voice = this.allocateVoice('percussion', 0.15);
        if (!voice) return;
        
        const noiseBuffer = this.createNoiseBuffer(0.05);
        const noiseSource = this.ctx.createBufferSource();
        noiseSource.buffer = noiseBuffer;
        
        const { env, filter, panner } = voice;
        
        // Hi-hat envelope (very quick)
        env.gain.setValueAtTime(0, this.ctx.currentTime);
        env.gain.linearRampToValueAtTime(1, this.ctx.currentTime + 0.001);
        env.gain.exponentialRampToValueAtTime(0.001, this.ctx.currentTime + 0.08);
        
        // High-frequency filtering
        filter.type = 'highpass';
        filter.frequency.value = 8000 + intensity * 2000;
        filter.Q.value = 5;
        
        const position = this.calculateSpatialPosition('hihat');
        panner.setPosition(position.x, position.y, position.z);
        
        noiseSource.connect(filter);
        filter.connect(env);
        env.connect(panner);
        panner.connect(this.effects.adaptive.chorus.delays[0]);
        
        noiseSource.start();
        noiseSource.stop(this.ctx.currentTime + 0.08);
        
        this.scheduleVoiceRelease(voice, 0.08);
      }

      playAdaptiveBass(beat, measure) {
        if (!this.voiceManager.layerStates.bass) return;
        
        // Play bass on strong beats with behavioral adaptation
        if (beat === 0 || (beat === 2 && this.behaviorAnalyzer.currentPattern === 'dancing')) {
          this.playAdvancedBass();
        }
      }

      playAdvancedBass() {
        const voice = this.allocateVoice('bass', 2.0);
        if (!voice) return;
        
        const { osc, env, filter, panner } = voice;
        
        // Get current harmonic context
        const chordIndex = this.measures % this.composer.harmonicProgression.length;
        const chord = this.composer.harmonicProgression[chordIndex];
        const rootNote = chord[0];
        
        // Convert to frequency
        const baseFreq = this.noteToFreq(rootNote, 2); // Bass octave
        
        // Adaptive bass synthesis
        osc.type = 'sawtooth';
        osc.frequency.value = baseFreq;
        osc.detune.value = Math.random() * 6 - 3; // Slight detuning for richness
        
        // Bass-specific filtering
        filter.type = 'lowpass';
        filter.frequency.value = 120 + this.motionSystem.smoothed * 80;
        filter.Q.value = 4 + this.musicalBrain.tension * 2;
        
        // Envelope with punch
        env.gain.setValueAtTime(0, this.ctx.currentTime);
        env.gain.linearRampToValueAtTime(1, this.ctx.currentTime + 0.02);
        env.gain.exponentialRampToValueAtTime(0.4, this.ctx.currentTime + 0.1);
        env.gain.exponentialRampToValueAtTime(0.001, this.ctx.currentTime + 2.0);
        
        const position = this.calculateSpatialPosition('bass');
        panner.setPosition(position.x, position.y, position.z);
        
        this.connectVoiceChain(voice);
        osc.start();
        osc.stop(this.ctx.currentTime + 2.0);
        
        this.scheduleVoiceRelease(voice, 2.0);
      }

      playAdaptiveHarmony(beat, measure) {
        if (!this.voiceManager.layerStates.harmony) return;
        
        // Play chords on downbeats and adapt to emotional state
        if (beat === 0 && measure % 2 === 0) {
          this.playAdvancedHarmony();
        }
      }

      playAdvancedHarmony() {
        const chordIndex = this.measures % this.composer.harmonicProgression.length;
        const chord = this.composer.harmonicProgression[chordIndex];
        
        chord.forEach((noteIndex, voiceIndex) => {
          const voice = this.allocateVoice('harmony', 8.0);
          if (!voice) return;
          
          const { osc, env, filter, panner } = voice;
          
          const freq = this.noteToFreq(noteIndex, 4 + Math.floor(voiceIndex / 3));
          
          // Harmonic synthesis with emotional coloring
          const emotionMap = {
            joyful: 'triangle',
            energetic: 'square',
            contemplative: 'sine',
            focused: 'sawtooth',
            peaceful: 'sine',
            neutral: 'triangle'
          };
          
          osc.type = emotionMap[this.musicalBrain.emotionalState] || 'triangle';
          osc.frequency.value = freq;
          osc.detune.value = Math.random() * 8 - 4;
          
          // Emotional filtering
          filter.type = 'lowpass';
          const brightness = {
            joyful: 2000,
            energetic: 1500,
            contemplative: 800,
            focused: 1200,
            peaceful: 600,
            neutral: 1000
          };
          
          filter.frequency.value = brightness[this.musicalBrain.emotionalState] || 1000;
          filter.Q.value = 1.5 + this.musicalBrain.tension;
          
          // Emotional envelope
          const attack = this.musicalBrain.emotionalState === 'peaceful' ? 1.0 : 0.2;
          const sustain = this.musicalBrain.emotionalState === 'energetic' ? 0.6 : 0.8;
          
          env.gain.setValueAtTime(0, this.ctx.currentTime);
          env.gain.linearRampToValueAtTime(0.3, this.ctx.currentTime + attack);
          env.gain.linearRampToValueAtTime(sustain * 0.3, this.ctx.currentTime + attack + 1);
          env.gain.exponentialRampToValueAtTime(0.001, this.ctx.currentTime + 8.0);
          
          // Spread harmony in space
          const angle = (voiceIndex / chord.length) * 2 * Math.PI;
          const radius = 3;
          panner.setPosition(
            Math.cos(angle) * radius,
            Math.sin(angle) * radius * 0.5,
            -2 - voiceIndex
          );
          
          this.connectVoiceChain(voice);
          
          // Connect to chorus for richness
          panner.connect(this.effects.adaptive.chorus.delays[voiceIndex % this.effects.adaptive.chorus.delays.length]);
          
          osc.start();
          osc.stop(this.ctx.currentTime + 8.0);
          
          this.scheduleVoiceRelease(voice, 8.0);
        });
      }

      playAdaptiveMelody(beat, measure) {
        if (!this.voiceManager.layerStates.melody) return;
        
        // Generate melodic phrases based on motion patterns and emotional state
        if (beat % 1 === 0 && Math.random() < this.composer.rhythmicComplexity * 0.6) {
          this.playAdvancedMelody();
        }
      }

      playAdvancedMelody() {
        const voice = this.allocateVoice('melody', 2.0);
        if (!voice) return;
        
        const { osc, env, filter, panner } = voice;
        
        // Generate melodic note based on current scale and emotional trajectory
        const scale = this.composer.scale;
        const scaleIndex = Math.floor(Math.random() * scale.length);
        const noteIndex = scale[scaleIndex];
        
        // Emotional octave selection
        const octaveMap = {
          joyful: 5,
          energetic: 4,
          contemplative: 4,
          focused: 4,
          peaceful: 5,
          neutral: 4
        };
        
        const octave = octaveMap[this.musicalBrain.emotionalState] || 4;
        const freq = this.noteToFreq(noteIndex, octave);
        
        // Melodic synthesis with motion influence
        osc.type = 'triangle';
        osc.frequency.setValueAtTime(freq, this.ctx.currentTime);
        
        // Add vibrato based on motion smoothness
        const vibratoDepth = this.motionSystem.smoothed * 10;
        const vibratoRate = 4 + this.musicalBrain.tension * 2;
        osc.frequency.setValueAtTime(freq, this.ctx.currentTime);
        osc.frequency.linearRampToValueAtTime(freq + vibratoDepth, this.ctx.currentTime + 1/vibratoRate);
        osc.frequency.linearRampToValueAtTime(freq - vibratoDepth, this.ctx.currentTime + 2/vibratoRate);
        osc.frequency.linearRampToValueAtTime(freq, this.ctx.currentTime + 3/vibratoRate);
        
        // Motion-influenced filtering
        filter.type = 'lowpass';
        filter.frequency.value = 2000 + this.motionSystem.smoothed * 1000;
        filter.Q.value = 1 + this.musicalBrain.complexity * 2;
        
        // Expressive envelope
        const duration = 1.5 + Math.random() * 0.5;
        env.gain.setValueAtTime(0, this.ctx.currentTime);
        env.gain.linearRampToValueAtTime(0.4, this.ctx.currentTime + 0.1);
        env.gain.linearRampToValueAtTime(0.3, this.ctx.currentTime + duration * 0.7);
        env.gain.exponentialRampToValueAtTime(0.001, this.ctx.currentTime + duration);
        
        // Position melody in space based on pitch
        const normalizedPitch = (freq - 200) / 1000; // Normalize frequency
        panner.setPosition(
          normalizedPitch * 4 - 2, // Left-right based on pitch
          2, // Above listener
          -1 // In front
        );
        
        this.connectVoiceChain(voice);
        panner.connect(this.effects.adaptive.delay);
        
        osc.start();
        osc.stop(this.ctx.currentTime + duration);
        
        this.scheduleVoiceRelease(voice, duration);
      }

      playAdaptiveAtmosphere(beat, measure) {
        if (!this.voiceManager.layerStates.atmosphere) return;
        
        // Atmospheric textures based on flow state and emotional trajectory
        if (Math.random() < 0.1 * this.musicalBrain.flowState) {
          this.playAtmosphericTexture();
        }
      }

      playAtmosphericTexture() {
        // Use granular synthesis for rich atmospheric textures
        const grainDuration = 0.1 + Math.random() * 0.2;
        const grainPitch = 0.5 + Math.random() * 1.5;
        const grainPan = Math.random() * 2 - 1;
        
        const grain = this.ctx.createBufferSource();
        grain.buffer = this.effects.adaptive.granular.buffer;
        grain.playbackRate.value = grainPitch;
        
        const grainGain = this.ctx.createGain();
        grainGain.gain.setValueAtTime(0, this.ctx.currentTime);
        grainGain.gain.linearRampToValueAtTime(0.1, this.ctx.currentTime + grainDuration * 0.1);
        grainGain.gain.exponentialRampToValueAtTime(0.001, this.ctx.currentTime + grainDuration);
        
        const grainPanner = this.ctx.createPanner();
        grainPanner.setPosition(grainPan * 5, Math.random() * 4 + 2, Math.random() * 6 + 2);
        
        grain.connect(grainGain);
        grainGain.connect(grainPanner);
        grainPanner.connect(this.effects.master.reverb);
        
        const startOffset = Math.random() * (this.effects.adaptive.granular.buffer.duration - grainDuration);
        grain.start(this.ctx.currentTime, startOffset, grainDuration);
      }

      playNeuralGeneration(beat, measure) {
        // AI-generated musical content when in flow state
        if (beat === 0 && Math.random() < this.musicalBrain.flowState) {
          this.generateNeuralPhrase();
        }
      }

      generateNeuralPhrase() {
        // Use neural network outputs to generate musical phrases
        const outputs = this.neuralNetwork.outputLayer;
        
        const phraseLength = Math.floor(outputs[0] * 8) + 4; // 4-12 notes
        const rhythmDensity = outputs[1];
        const pitchRange = outputs[2] * 24; // Up to 2 octaves
        const harmonyComplexity = outputs[3];
        
        for (let i = 0; i < phraseLength; i++) {
          if (Math.random() < rhythmDensity) {
            setTimeout(() => {
              this.playNeuralNote(pitchRange, harmonyComplexity);
            }, i * 200 + Math.random() * 100);
          }
        }
      }

      playNeuralNote(pitchRange, complexity) {
        const voice = this.allocateVoice('neural', 1.5);
        if (!voice) return;
        
        const { osc, env, filter, panner } = voice;
        
        // Neural-influenced pitch selection
        const baseNote = this.composer.scale[Math.floor(Math.random() * this.composer.scale.length)];
        const octaveOffset = Math.floor((Math.random() - 0.5) * pitchRange / 12);
        const freq = this.noteToFreq(baseNote, 4 + octaveOffset);
        
        // Complex waveform based on neural complexity
        if (complexity > 0.7) {
          // Create complex waveform by layering
          const osc2 = this.ctx.createOscillator();
          osc2.type = 'square';
          osc2.frequency.value = freq * 1.01;
          osc2.connect(filter);
          
          osc.type = 'sawtooth';
          osc2.start();
          osc2.stop(this.ctx.currentTime + 1.5);
        } else {
          osc.type = 'sine';
        }
        
        osc.frequency.value = freq;
        
        // Neural-influenced filtering
        filter.type = complexity > 0.5 ? 'bandpass' : 'lowpass';
        filter.frequency.value = 500 + complexity * 2000;
        filter.Q.value = 1 + complexity * 5;
        
        // Adaptive envelope
        const attack = complexity * 0.3;
        const release = 1.5 - complexity * 0.5;
        
        env.gain.setValueAtTime(0, this.ctx.currentTime);
        env.gain.linearRampToValueAtTime(0.3, this.ctx.currentTime + attack);
        env.gain.exponentialRampToValueAtTime(0.001, this.ctx.currentTime + release);
        
        // Position based on neural activity
        const neuralX = (Math.random() - 0.5) * 8;
        const neuralY = complexity * 4;
        const neuralZ = -2 - complexity * 3;
        panner.setPosition(neuralX, neuralY, neuralZ);
        
        this.connectVoiceChain(voice);
        
        osc.start();
        osc.stop(this.ctx.currentTime + release);
        
        this.scheduleVoiceRelease(voice, release);
      }

      // Utility functions
      
      allocateVoice(poolName, duration) {
        const pool = this.voiceManager.pools[poolName];
        if (!pool) return null;
        
        // Clean up finished voices
        pool.voices = pool.voices.filter(voice => voice.active);
        
        // Check if we can allocate a new voice
        if (pool.voices.length >= pool.max) {
          // Remove oldest voice if at capacity
          const oldest = pool.voices.shift();
          if (oldest && oldest.cleanup) oldest.cleanup();
        }
        
        // Create new voice
        const voice = this.createVoice();
        voice.active = true;
        voice.poolName = poolName;
        voice.startTime = this.ctx.currentTime;
        voice.duration = duration;
        
        pool.voices.push(voice);
        
        return voice;
      }

      createVoice() {
        return {
          osc: this.ctx.createOscillator(),
          env: this.ctx.createGain(),
          filter: this.ctx.createBiquadFilter(),
          panner: this.ctx.createPanner(),
          active: false,
          cleanup: null
        };
      }

      connectVoiceChain(voice) {
        voice.osc.connect(voice.filter);
        voice.filter.connect(voice.env);
        voice.env.connect(voice.panner);
        voice.panner.connect(this.effects.adaptive.filter);
        this.effects.adaptive.filter.connect(this.effects.master.compressor);
      }

      scheduleVoiceRelease(voice, duration) {
        voice.cleanup = () => {
          voice.active = false;
        };
        
        setTimeout(() => {
          if (voice.cleanup) voice.cleanup();
        }, duration * 1000 + 100);
      }

      calculateSpatialPosition(instrumentType) {
        // Calculate spatial positions based on motion and musical arrangement
        const motion = this.motionSystem.smoothed;
        const basePositions = {
          kick: { x: 0, y: -1, z: -2 },
          snare: { x: 0.5, y: 0, z: -1.5 },
          hihat: { x: -0.5, y: 1, z: -3 },
          bass: { x: 0, y: -2, z: -3 },
          melody: { x: 2, y: 1, z: -1 },
          harmony: { x: -2, y: 1, z: -2 },
          atmosphere: { x: 0, y: 3, z: 5 },
          neural: { x: 0, y: 2, z: 0 }
        };
        
        const base = basePositions[instrumentType] || { x: 0, y: 0, z: 0 };
        
        // Add motion-based variation
        return {
          x: base.x + (Math.random() - 0.5) * motion * 0.5,
          y: base.y + (Math.random() - 0.5) * motion * 0.3,
          z: base.z + (Math.random() - 0.5) * motion * 0.2
        };
      }

      createNoiseBuffer(duration) {
        const buffer = this.ctx.createBuffer(1, this.ctx.sampleRate * duration, this.ctx.sampleRate);
        const data = buffer.getChannelData(0);
        
        for (let i = 0; i < data.length; i++) {
          data[i] = Math.random() * 2 - 1;
        }
        
        return buffer;
      }

      noteToFreq(semitone, octave = 4) {
        // Convert semitone offset and octave to frequency
        return 440 * Math.pow(2, (semitone - 9 + (octave - 4) * 12) / 12);
      }

      updateAdaptiveEffects() {
        // Real-time effect parameter updates based on musical brain state
        const motion = this.motionSystem.smoothed;
        const tension = this.musicalBrain.tension;
        const complexity = this.musicalBrain.complexity;
        const flow = this.musicalBrain.flowState;
        
        // Adaptive filter
        this.effects.adaptive.filter.frequency.value = 500 + motion * 1000 + complexity * 500;
        this.effects.adaptive.filter.Q.value = 1 + tension * 3;
        
        // Adaptive delay timing
        const bpmSync = 60 / this.musicalBrain.bpm;
        this.effects.adaptive.delay.delayTime.value = bpmSync * 0.25 * (1 + flow * 0.5);
        
        // Chorus modulation based on emotional state
        this.effects.adaptive.chorus.lfos.forEach((lfo, i) => {
          lfo.frequency.value = 0.3 + motion * 0.4 + i * 0.2;
        });
        
        // Master reverb wet/dry based on atmosphere
        const reverbWet = this.ctx.createGain();
        reverbWet.gain.value = 0.2 + flow * 0.3 + (this.musicalBrain.emotionalState === 'peaceful' ? 0.2 : 0);
      }

      triggerBeatVisualization() {
        // Enhanced beat visualization
        this.elements.orb.classList.add('pulse');
        setTimeout(() => this.elements.orb.classList.remove('pulse'), 200);
        
        // Update neural nodes based on current activity
        this.neuralNodes.forEach((node, i) => {
          const activity = this.neuralNetwork.hiddenLayers[0][i % this.neuralNetwork.hiddenLayers[0].length];
          node.style.opacity = 0.3 + activity * 0.7;
          node.style.transform = `scale(${1 + activity * 0.5})`;
        });
      }

      startAdvancedAnimation() {
        const animate = () => {
          if (!this.active) return;
          
          this.updateAdvancedUI();
          this.updateSpatialVisualization();
          this.updateNeuralVisualization();
          this.updateCinematicElements();
          
          requestAnimationFrame(animate);
        };
        
        requestAnimationFrame(animate);
      }

      updateAdvancedUI() {
        // Update all UI elements with smooth animations
        this.elements.stageName.textContent = this.narrative.arc.replace('_', ' ').toUpperCase();
        this.elements.currentState.textContent = this.musicalBrain.emotionalState.toUpperCase();
        this.elements.behaviorPattern.textContent = this.behaviorAnalyzer.currentPattern.toUpperCase();
        
        // Smooth bar animations
        const motionPercent = Math.min(this.motionSystem.smoothed * 20, 100);
        this.elements.motionBar.style.width = motionPercent + '%';
        
        const neuralPercent = this.musicalBrain.flowState * 100;
        this.elements.neuralBar.style.width = neuralPercent + '%';
        
        const emotionPercent = this.calculateEmotionalIntensity() * 100;
        this.elements.emotionBar.style.width = emotionPercent + '%';
        
        // Musical information
        this.elements.bpmDisplay.textContent = Math.round(this.musicalBrain.bpm);
        this.elements.keyDisplay.textContent = `${this.musicalBrain.key} ${this.musicalBrain.mode.toUpperCase()}`;
        
        const totalVoices = Object.values(this.voiceManager.pools).reduce((sum, pool) => sum + pool.voices.length, 0);
        this.elements.voiceCount.textContent = totalVoices;
        this.elements.complexityLevel.textContent = Math.round(this.musicalBrain.complexity * 10);
        
        // Flow state and behavioral indicators
        this.elements.flowState.textContent = Math.round(this.musicalBrain.flowState * 100) + '%';
        this.elements.behaviorIndicator.textContent = this.getBehaviorDescription();
        
        // Update mood ring color
        this.updateMoodRing();
        
        // Spectrum visualization
        if (this.analyser && this.dataArray) {
          this.analyser.getByteFrequencyData(this.dataArray);
          this.spectrumBars.forEach((bar, i) => {
            if (i < this.dataArray.length) {
              const height = (this.dataArray[i] / 255) * 100;
              bar.style.height = height + 'px';
              
              // Color based on frequency range
              const hue = (i / this.dataArray.length) * 240; // Blue to red spectrum
              bar.style.background = `linear-gradient(0deg, hsl(${hue}, 70%, 60%), hsl(${hue}, 50%, 40%))`;
            }
          });
        }
      }

      calculateEmotionalIntensity() {
        const emotionIntensities = {
          joyful: 0.9,
          energetic: 0.8,
          contemplative: 0.4,
          focused: 0.6,
          peaceful: 0.3,
          neutral: 0.5
        };
        
        return emotionIntensities[this.musicalBrain.emotionalState] || 0.5;
      }

      getBehaviorDescription() {
        const descriptions = {
          dancing: 'Rhythmic Flow',
          exercising: 'High Energy',
          walking: 'Steady Motion',
          working: 'Focused Activity',
          resting: 'Calm State',
          exploring: 'Discovering'
        };
        
        return descriptions[this.behaviorAnalyzer.currentPattern] || 'Listening';
      }

      updateMoodRing() {
        const emotion = this.musicalBrain.emotionalState;
        const intensity = this.calculateEmotionalIntensity();
        
        const colors = {
          joyful: '#f39c12',
          energetic: '#e74c3c',
          contemplative: '#3498db',
          focused: '#9b59b6',
          peaceful: '#2ecc71',
          neutral: '#95a5a6'
        };
        
        const color = colors[emotion] || '#95a5a6';
        this.elements.moodRing.style.borderColor = color;
        this.elements.moodRing.style.boxShadow = `0 0 ${20 + intensity * 20}px ${color}`;
        
        // Animate the ring based on flow state
        const scale = 1 + this.musicalBrain.flowState * 0.2;
        this.elements.moodRing.style.transform = `scale(${scale})`;
      }

      updateSpatialVisualization() {
        // Update orb position and appearance based on motion and emotion
        const emotion = this.musicalBrain.emotionalState;
        const motion = this.motionSystem.smoothed;
        const flow = this.musicalBrain.flowState;
        
        // Orb size based on activity
        const scale = 1 + motion * 0.3 + flow * 0.2;
        this.elements.orb.style.transform = `translate(-50%, -50%) scale(${scale})`;
        
        // Orb color based on emotion and activity
        const colorMaps = {
          joyful: `radial-gradient(circle, #f39c12 0%, rgba(243,156,18,0.5) 40%, transparent 80%)`,
          energetic: `radial-gradient(circle, #e74c3c 0%, rgba(231,76,60,0.5) 40%, transparent 80%)`,
          contemplative: `radial-gradient(circle, #3498db 0%, rgba(52,152,219,0.5) 40%, transparent 80%)`,
          focused: `radial-gradient(circle, #9b59b6 0%, rgba(155,89,182,0.5) 40%, transparent 80%)`,
          peaceful: `radial-gradient(circle, #2ecc71 0%, rgba(46,204,113,0.5) 40%, transparent 80%)`,
          neutral: `radial-gradient(circle, #fff 0%, rgba(255,255,255,0.4) 40%, transparent 80%)`
        };
        
        this.elements.orb.style.background = colorMaps[emotion] || colorMaps.neutral;
        
        // Enhanced glow based on flow state
        const glowIntensity = 60 + flow * 90;
        const glowColor = colorMaps[emotion] ? emotion === 'joyful' ? '#f39c12' : 
                         emotion === 'energetic' ? '#e74c3c' :
                         emotion === 'contemplative' ? '#3498db' :
                         emotion === 'focused' ? '#9b59b6' :
                         emotion === 'peaceful' ? '#2ecc71' : '#fff' : '#fff';
        
        this.elements.orb.style.boxShadow = `0 0 ${glowIntensity}px ${glowColor}`;
      }

      updateNeuralVisualization() {
        // Update neural network visualization
        this.neuralNodes.forEach((node, i) => {
          const layerIndex = i % 2; // Alternate between hidden layers
          const nodeIndex = Math.floor(i / 2) % this.neuralNetwork.hiddenLayers[layerIndex].length;
          const activity = this.neuralNetwork.hiddenLayers[layerIndex][nodeIndex];
          
          // Update node appearance based on neural activity
          node.style.opacity = 0.2 + activity * 0.8;
          const size = 3 + activity * 4;
          node.style.width = size + 'px';
          node.style.height = size + 'px';
          
          // Color based on activity level
          const hue = activity * 240; // Blue to red
          node.style.background = `hsl(${hue}, 70%, 60%)`;
          
          // Dynamic positioning based on neural state
          const x = 10 + (i % 8) * 10 + activity * 5;
          const y = 10 + Math.floor(i / 8) * 15 + Math.sin(performance.now() * 0.001 + i) * 3;
          node.style.left = x + '%';
          node.style.top = y + '%';
        });
      }

      updateCinematicElements() {
        // Update cinematic overlay and theme text
        const shouldShowOverlay = this.musicalBrain.tension > 0.6 || 
                                 this.narrative.arc === 'climax' ||
                                 this.musicalBrain.flowState > 0.8;
        
        this.elements.cinematicOverlay.classList.toggle('active', shouldShowOverlay);
        
        // Dynamic background based on emotional trajectory and motion
        const motion = this.motionSystem.smoothed;
        const tension = this.musicalBrain.tension;
        const flow = this.musicalBrain.flowState;
        
        // Create dynamic background gradient
        const emotion = this.musicalBrain.emotionalState;
        const colorSchemes = {
          joyful: ['#f39c12', '#e67e22', '#d35400'],
          energetic: ['#e74c3c', '#c0392b', '#a93226'],
          contemplative: ['#3498db', '#2980b9', '#1f4e79'],
          focused: ['#9b59b6', '#8e44ad', '#6c3483'],
          peaceful: ['#2ecc71', '#27ae60', '#1e8449'],
          neutral: ['#34495e', '#2c3e50', '#1b2631']
        };
        
        const colors = colorSchemes[emotion] || colorSchemes.neutral;
        const intensityFactor = motion * 0.3 + tension * 0.4 + flow * 0.3;
        
        const gradient = `radial-gradient(ellipse at center,
          ${colors[0]}${Math.floor(intensityFactor * 255).toString(16).padStart(2, '0')} 0%,
          ${colors[1]}${Math.floor(intensityFactor * 0.7 * 255).toString(16).padStart(2, '0')} 30%,
          ${colors[2]}${Math.floor(intensityFactor * 0.4 * 255).toString(16).padStart(2, '0')} 60%,
          #0a0a0a 100%)`;
        
        document.body.style.background = gradient;
        
        // Update theme text based on narrative arc
        const themeTexts = {
          exposition: 'The Journey Begins...',
          rising_action: 'Story Unfolds',
          climax: 'Peak Experience',
          falling_action: 'Resolution Approaching',
          resolution: 'Harmony Achieved'
        };
        
        const currentTheme = themeTexts[this.narrative.arc] || 'Neural Symphony';
        if (this.elements.themeText.textContent !== currentTheme) {
          this.elements.themeText.textContent = currentTheme;
          this.elements.themeText.classList.add('visible');
          setTimeout(() => this.elements.themeText.classList.remove('visible'), 3000);
        }
      }

      // Public methods for external control (if needed)
      
      setEmotionalState(state) {
        if (['joyful', 'energetic', 'contemplative', 'focused', 'peaceful', 'neutral'].includes(state)) {
          this.musicalBrain.emotionalState = state;
          this.updateMusicalStructure();
        }
      }

      setBehaviorPattern(pattern) {
        if (['dancing', 'exercising', 'walking', 'working', 'resting', 'exploring'].includes(pattern)) {
          this.behaviorAnalyzer.currentPattern = pattern;
          this.behaviorAnalyzer.confidence = 1.0;
        }
      }

      getSystemState() {
        return {
          active: this.active,
          motion: this.motionSystem.smoothed,
          emotion: this.musicalBrain.emotionalState,
          pattern: this.behaviorAnalyzer.currentPattern,
          flowState: this.musicalBrain.flowState,
          bpm: Math.round(this.musicalBrain.bpm),
          key: this.musicalBrain.key,
          mode: this.musicalBrain.mode,
          narrativeArc: this.narrative.arc,
          activeVoices: Object.values(this.voiceManager.pools).reduce((sum, pool) => sum + pool.voices.length, 0)
        };
      }

      // Advanced debugging and monitoring
      
      logNeuralState() {
        console.log('Neural Network State:', {
          inputs: this.neuralNetwork.inputLayer,
          hidden1: this.neuralNetwork.hiddenLayers[0].slice(0, 5), // First 5 nodes
          hidden2: this.neuralNetwork.hiddenLayers[1].slice(0, 5),
          outputs: this.neuralNetwork.outputLayer
        });
      }

      logMusicalState() {
        console.log('Musical Brain State:', {
          bpm: this.musicalBrain.bpm,
          key: this.musicalBrain.key,
          mode: this.musicalBrain.mode,
          emotion: this.musicalBrain.emotionalState,
          tension: this.musicalBrain.tension,
          complexity: this.musicalBrain.complexity,
          flowState: this.musicalBrain.flowState,
          scale: this.composer.scale,
          progression: this.composer.harmonicProgression
        });
      }

      logBehaviorState() {
        console.log('Behavior Analysis:', {
          currentPattern: this.behaviorAnalyzer.currentPattern,
          confidence: this.behaviorAnalyzer.confidence,
          motionPatterns: this.motionSystem.patterns,
          recentGestures: this.behaviorAnalyzer.gestureMemory.slice(-3),
          emotionalTrajectory: this.behaviorAnalyzer.emotionalTrajectory.slice(-5)
        });
      }

      // New: Setup heart rate analyzer
      async setupHeartRateAnalyzer() {
        try {
          const stream = await navigator.mediaDevices.getUserMedia({ video: true });
          this.heartRateAnalyzer.video = this.elements.heartVideo;
          this.heartRateAnalyzer.video.srcObject = stream;
          this.heartRateAnalyzer.video.onloadedmetadata = () => {
            this.heartRateAnalyzer.video.play();
            this.heartRateAnalyzer.canvas = this.elements.heartCanvas;
            this.heartRateAnalyzer.context = this.heartRateAnalyzer.canvas.getContext('2d');
            this.startHeartRateAnalysis();
          };
        } catch (error) {
          console.warn('Webcam access denied for heart rate sync. Proceeding without.', error);
        }
      }

      startHeartRateAnalysis() {
        const analyze = () => {
          if (!this.active || !this.heartRateAnalyzer.video.videoWidth) return;

          const now = performance.now();
          if (now - this.heartRateAnalyzer.lastTime < this.heartRateAnalyzer.sampleInterval) {
            requestAnimationFrame(analyze);
            return;
          }

          this.heartRateAnalyzer.lastTime = now;

          // Draw video to canvas
          this.heartRateAnalyzer.context.drawImage(this.heartRateAnalyzer.video, 0, 0, this.heartRateAnalyzer.canvas.width, this.heartRateAnalyzer.canvas.height);

          // Get image data
          const imageData = this.heartRateAnalyzer.context.getImageData(0, 0, this.heartRateAnalyzer.canvas.width, this.heartRateAnalyzer.canvas.height);
          const data = imageData.data;

          // Calculate average green channel (for PPG signal)
          let greenSum = 0;
          const pixelCount = data.length / 4;
          for (let i = 0; i < data.length; i += 4) {
            greenSum += data[i + 1]; // Green channel
          }
          const avgGreen = greenSum / pixelCount;

          // Push to samples
          this.heartRateAnalyzer.samples.push(avgGreen);
          this.heartRateAnalyzer.timestamps.push(now);

          // Keep window size
          if (this.heartRateAnalyzer.samples.length > this.heartRateAnalyzer.windowSize) {
            this.heartRateAnalyzer.samples.shift();
            this.heartRateAnalyzer.timestamps.shift();
          }

          // Calculate BPM if enough samples
          if (this.heartRateAnalyzer.samples.length >= 60) { // Min 2 seconds at 30fps
            this.calculateHeartRateBPM();
          }

          // Influence music (e.g., tempo blend in adaptTempo)

          // Update UI
          this.elements.heartRateDisplay.textContent = this.heartRateAnalyzer.bpm > 0 ? Math.round(this.heartRateAnalyzer.bpm) : '--';
          const pulsePercent = (this.heartRateAnalyzer.bpm / 200) * 100; // Normalize to 200 max BPM
          this.elements.pulseBar.style.width = pulsePercent + '%';

          requestAnimationFrame(analyze);
        };

        requestAnimationFrame(analyze);
      }

      calculateHeartRateBPM() {
        const samples = this.heartRateAnalyzer.samples;
        const timestamps = this.heartRateAnalyzer.timestamps;

        // Simple peak detection on detrended signal
        // First, detrend (subtract moving average)
        const window = 30; // Moving average window
        const detrended = [];
        for (let i = 0; i < samples.length; i++) {
          let sum = 0;
          let count = 0;
          for (let j = Math.max(0, i - window / 2); j < Math.min(samples.length, i + window / 2); j++) {
            sum += samples[j];
            count++;
          }
          detrended[i] = samples[i] - (sum / count);
        }

        // Find peaks (local maxima)
        const peaks = [];
        for (let i = 1; i < detrended.length - 1; i++) {
          if (detrended[i] > detrended[i - 1] && detrended[i] > detrended[i + 1] && detrended[i] > 0.1) { // Threshold for peak
            peaks.push(timestamps[i]);
          }
        }

        if (peaks.length < 2) {
          this.heartRateAnalyzer.bpm = 0;
          this.heartRateAnalyzer.confidence = 0;
          return;
        }

        // Calculate average interval
        let intervals = [];
        for (let i = 1; i < peaks.length; i++) {
          intervals.push(peaks[i] - peaks[i - 1]);
        }

        const avgInterval = intervals.reduce((a, b) => a + b, 0) / intervals.length / 1000; // seconds
        this.heartRateAnalyzer.bpm = 60 / avgInterval;

        // Confidence based on variance of intervals
        const variance = intervals.reduce((sum, int) => sum + Math.pow(int - avgInterval * 1000, 2), 0) / intervals.length;
        this.heartRateAnalyzer.confidence = Math.max(0, 1 - variance / (avgInterval * 1000 * 0.2)); // Arbitrary normalization
      }
    }

    // Initialize the Enhanced Void Engine
    window.addEventListener('load', () => {
      const engine = new EnhancedVoidEngine();
      
      // Expose engine to global scope for debugging
      window.voidEngine = engine;
      
      // Add keyboard shortcuts for debugging (optional)
      window.addEventListener('keydown', (e) => {
        if (!engine.active) return;
        
        switch(e.key) {
          case 'n':
            engine.logNeuralState();
            break;
          case 'm':
            engine.logMusicalState();
            break;
          case 'b':
            engine.logBehaviorState();
            break;
          case 's':
            console.log('System State:', engine.getSystemState());
            break;
        }
      });
      
      console.log(' Enhanced Void Engine Loaded');
      console.log('Debug commands: N (neural), M (musical), B (behavior), S (system)');
    });

  </script>
</body>
</html>
