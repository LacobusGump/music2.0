<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="mobile-web-app-status-bar-style" content="black-translucent">
<title>NEUROMANCER - Environmental Music AI</title>
<style>
* {
  margin: 0;
  padding: 0;
  box-sizing: border-box;
  -webkit-tap-highlight-color: transparent;
  -webkit-user-select: none;
  user-select: none;
  touch-action: none;
}

:root {
  --quantum-blue: #00ffff;
  --neural-purple: #ff00ff;
  --plasma-green: #00ff00;
  --void-black: #000000;
  --ghost-white: rgba(255,255,255,0.03);
  --electric-red: #ff0040;
  --safe-area-top: env(safe-area-inset-top);
  --safe-area-bottom: env(safe-area-inset-bottom);
}

body {
  background: var(--void-black);
  color: #fff;
  overflow: hidden;
  height: 100vh;
  height: 100dvh;
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
  position: relative;
  overscroll-behavior: none;
}

/* Quantum Field Background */
#quantumField {
  position: fixed;
  inset: 0;
  background: radial-gradient(ellipse at center,
    transparent 0%,
    rgba(0, 255, 255, 0.03) 40%,
    rgba(255, 0, 255, 0.02) 70%,
    transparent 100%);
  pointer-events: none;
  animation: quantum-pulse 8s ease-in-out infinite;
  transition: all 2s ease;
}

#quantumField.elevated {
  background: radial-gradient(ellipse at center,
    rgba(255, 0, 255, 0.1) 0%,
    rgba(0, 255, 255, 0.2) 40%,
    rgba(255, 0, 0, 0.1) 70%,
    transparent 100%);
  animation-duration: 2s;
}

@keyframes quantum-pulse {
  0%, 100% { opacity: 0.3; transform: scale(1) rotate(0deg); }
  50% { opacity: 0.6; transform: scale(1.1) rotate(90deg); }
}

/* 3D Spatial Visualizer */
#spatialCanvas {
  position: fixed;
  inset: 0;
  pointer-events: none;
  opacity: 0.6;
}

/* Motion Indicator */
.motion-indicator {
  position: fixed;
  top: calc(var(--safe-area-top) + 20px);
  left: 50%;
  transform: translateX(-50%);
  width: 200px;
  height: 4px;
  background: rgba(255, 255, 255, 0.1);
  border-radius: 2px;
  overflow: hidden;
}

.motion-level {
  height: 100%;
  width: 0%;
  background: linear-gradient(90deg, var(--plasma-green), var(--quantum-blue));
  transition: width 0.1s ease;
}

/* Environmental State Display */
.env-state {
  position: fixed;
  top: calc(var(--safe-area-top) + 40px);
  left: 50%;
  transform: translateX(-50%);
  font-size: 10px;
  letter-spacing: 3px;
  opacity: 0.5;
  text-transform: uppercase;
}

/* Sample Orbs Container */
.sample-grid {
  position: fixed;
  top: 50%;
  left: 50%;
  transform: translate(-50%, -50%);
  display: grid;
  grid-template-columns: repeat(2, 1fr);
  grid-template-rows: repeat(2, 1fr);
  gap: 30px;
  width: 200px;
  height: 200px;
}

.sample-orb {
  width: 80px;
  height: 80px;
  border-radius: 50%;
  border: 2px solid var(--ghost-white);
  display: flex;
  align-items: center;
  justify-content: center;
  position: relative;
  transition: all 0.3s ease;
  background: radial-gradient(circle at 30% 30%,
    rgba(0, 255, 255, 0.05),
    transparent);
}

.sample-orb.recording {
  animation: orb-record 1s ease-in-out infinite;
  border-color: var(--electric-red);
  box-shadow: 0 0 30px var(--electric-red);
}

.sample-orb.loaded {
  border-color: var(--plasma-green);
  background: radial-gradient(circle at center,
    rgba(0, 255, 0, 0.1),
    transparent);
}

.sample-orb.playing {
  animation: orb-play 0.5s ease-in-out;
  border-color: var(--quantum-blue);
  box-shadow: 0 0 40px var(--quantum-blue);
}

@keyframes orb-record {
  0%, 100% { transform: scale(1); }
  50% { transform: scale(1.1); }
}

@keyframes orb-play {
  0% { transform: scale(1); }
  50% { transform: scale(1.2); }
  100% { transform: scale(1); }
}

/* Journey Timeline */
.journey-timeline {
  position: fixed;
  bottom: calc(var(--safe-area-bottom) + 100px);
  left: 20px;
  right: 20px;
  height: 2px;
  background: rgba(255, 255, 255, 0.1);
  border-radius: 1px;
}

.journey-progress {
  height: 100%;
  width: 0%;
  background: linear-gradient(90deg,
    var(--plasma-green),
    var(--quantum-blue),
    var(--neural-purple));
  transition: width 1s linear;
}

/* Control Zone */
.control-zone {
  position: fixed;
  bottom: var(--safe-area-bottom);
  left: 0;
  right: 0;
  height: 80px;
  background: linear-gradient(to top,
    rgba(0, 0, 0, 0.8),
    transparent);
  display: flex;
  justify-content: space-around;
  align-items: center;
  padding: 0 20px;
}

.control-btn {
  width: 50px;
  height: 50px;
  border-radius: 50%;
  border: 1px solid var(--ghost-white);
  background: rgba(0, 0, 0, 0.5);
  display: flex;
  align-items: center;
  justify-content: center;
  font-size: 9px;
  letter-spacing: 1px;
  transition: all 0.3s ease;
}

.control-btn.active {
  border-color: var(--quantum-blue);
  background: rgba(0, 255, 255, 0.1);
  box-shadow: 0 0 20px var(--quantum-blue);
}

/* Permission Request */
.permission-overlay {
  position: fixed;
  inset: 0;
  display: flex;
  align-items: center;
  justify-content: center;
  background: var(--void-black);
  z-index: 10000;
  flex-direction: column;
  gap: 30px;
  padding: 40px;
  text-align: center;
}

.permission-overlay.hidden {
  display: none;
}

.permission-title {
  font-size: 18px;
  letter-spacing: 4px;
  opacity: 0.8;
  font-weight: 100;
}

.permission-text {
  font-size: 12px;
  opacity: 0.5;
  line-height: 1.6;
  max-width: 300px;
}

.permission-btn {
  padding: 15px 40px;
  border: 1px solid var(--quantum-blue);
  background: transparent;
  color: var(--quantum-blue);
  border-radius: 30px;
  font-size: 12px;
  letter-spacing: 3px;
  cursor: pointer;
  transition: all 0.3s ease;
}

.permission-btn:active {
  background: rgba(0, 255, 255, 0.1);
  transform: scale(0.98);
}

/* BPM Display */
.bpm-display {
  position: fixed;
  top: calc(var(--safe-area-top) + 70px);
  left: 20px;
  font-size: 24px;
  font-weight: 100;
  opacity: 0.3;
  font-family: monospace;
}

/* Spatial Position Indicator */
.spatial-indicator {
  position: fixed;
  top: 50%;
  left: 50%;
  transform: translate(-50%, -50%);
  width: 300px;
  height: 300px;
  pointer-events: none;
  z-index: 10;
}

.spatial-dot {
  position: absolute;
  width: 8px;
  height: 8px;
  background: var(--quantum-blue);
  border-radius: 50%;
  left: 50%;
  top: 50%;
  transform: translate(-50%, -50%);
  box-shadow: 0 0 20px var(--quantum-blue);
  transition: all 0.1s ease;
}

/* Loading State */
.loading-overlay {
  position: fixed;
  inset: 0;
  display: none;
  align-items: center;
  justify-content: center;
  background: rgba(0, 0, 0, 0.9);
  z-index: 9999;
}

.loading-overlay.active {
  display: flex;
}

.loading-text {
  font-size: 12px;
  letter-spacing: 5px;
  opacity: 0.5;
  animation: pulse 2s ease-in-out infinite;
}

@keyframes pulse {
  0%, 100% { opacity: 0.3; }
  50% { opacity: 0.8; }
}

/* Debug Info */
.debug-info {
  position: fixed;
  top: calc(var(--safe-area-top) + 10px);
  right: 10px;
  font-size: 8px;
  font-family: monospace;
  opacity: 0.3;
  text-align: right;
}
</style>
</head>
<body>
<div id="quantumField"></div>
<canvas id="spatialCanvas"></canvas>

<div class="motion-indicator">
  <div class="motion-level" id="motionLevel"></div>
</div>

<div class="env-state" id="envState">VOID</div>

<div class="bpm-display" id="bpmDisplay">120 BPM</div>

<div class="sample-grid" id="sampleGrid">
  <div class="sample-orb" data-slot="0"></div>
  <div class="sample-orb" data-slot="1"></div>
  <div class="sample-orb" data-slot="2"></div>
  <div class="sample-orb" data-slot="3"></div>
</div>

<div class="spatial-indicator">
  <div class="spatial-dot" id="spatialDot"></div>
</div>

<div class="journey-timeline">
  <div class="journey-progress" id="journeyProgress"></div>
</div>

<div class="control-zone">
  <div class="control-btn" id="btnMotion">MOTION</div>
  <div class="control-btn" id="btnAI">AI DJ</div>
  <div class="control-btn" id="btnSpatial">3D</div>
</div>

<div class="debug-info" id="debug">
  <div>STATE: <span id="debugState">INIT</span></div>
  <div>MOTION: <span id="debugMotion">0</span></div>
  <div>SAMPLES: <span id="debugSamples">0</span></div>
</div>

<div class="permission-overlay" id="permissionOverlay">
  <div class="permission-title">NEUROMANCER</div>
  <div class="permission-text">
    This experience needs access to your microphone and motion sensors to transform your environment into music.
    A 25-minute journey awaits.
  </div>
  <button class="permission-btn" id="startBtn">ENTER THE VOID</button>
</div>

<div class="loading-overlay" id="loadingOverlay">
  <div class="loading-text">AWAKENING</div>
</div>

<script>
'use strict';

class NeuromancerEngine {
  constructor() {
    this.config = {
      sampleRate: 48000,
      bpm: 120,
      sampleDuration: 4000, // 4 seconds
      journeyDuration: 25 * 60 * 1000, // 25 minutes
      motionThreshold: 0.5,
      spatialRadius: 5, // meters
      autoSampleInterval: 8000 // Auto-sample every 8 seconds
    };
    
    this.state = {
      currentState: 'void', // void, ambient, rhythmic, elevated, chaos
      motionLevel: 0,
      spatialPosition: { x: 0, y: 0, z: 0 },
      isRecording: false,
      journeyStartTime: null,
      bpm: 120,
      samples: new Map(),
      nextSampleSlot: 0,
      aiDjActive: true
    };
    
    this.audioNodes = {};
    this.scheduler = null;
    this.motionData = [];
    
    this.init();
  }
  
  async init() {
    this.setupUI();
    this.setupEventListeners();
  }
  
  setupUI() {
    this.ui = {
      permissionOverlay: document.getElementById('permissionOverlay'),
      loadingOverlay: document.getElementById('loadingOverlay'),
      startBtn: document.getElementById('startBtn'),
      
      quantumField: document.getElementById('quantumField'),
      spatialCanvas: document.getElementById('spatialCanvas'),
      motionLevel: document.getElementById('motionLevel'),
      envState: document.getElementById('envState'),
      bpmDisplay: document.getElementById('bpmDisplay'),
      sampleOrbs: document.querySelectorAll('.sample-orb'),
      spatialDot: document.getElementById('spatialDot'),
      journeyProgress: document.getElementById('journeyProgress'),
      
      btnMotion: document.getElementById('btnMotion'),
      btnAI: document.getElementById('btnAI'),
      btnSpatial: document.getElementById('btnSpatial'),
      
      debug: {
        state: document.getElementById('debugState'),
        motion: document.getElementById('debugMotion'),
        samples: document.getElementById('debugSamples')
      }
    };
    
    // Setup canvas
    this.spatialCtx = this.ui.spatialCanvas.getContext('2d');
    this.resizeCanvas();
    window.addEventListener('resize', () => this.resizeCanvas());
  }
  
  resizeCanvas() {
    this.ui.spatialCanvas.width = window.innerWidth;
    this.ui.spatialCanvas.height = window.innerHeight;
  }
  
  setupEventListeners() {
    this.ui.startBtn.addEventListener('click', () => this.requestPermissions());
    
    this.ui.btnMotion.addEventListener('click', () => this.toggleMotion());
    this.ui.btnAI.addEventListener('click', () => this.toggleAIDJ());
    this.ui.btnSpatial.addEventListener('click', () => this.toggle3D());
    
    // Prevent default gestures
    document.addEventListener('touchmove', e => e.preventDefault(), { passive: false });
  }
  
  async requestPermissions() {
    this.ui.loadingOverlay.classList.add('active');
    
    try {
      // Request microphone
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: false,
          noiseSuppression: false,
          autoGainControl: false
        }
      });
      
      // Request motion sensors
      if (typeof DeviceMotionEvent !== 'undefined' && 
          typeof DeviceMotionEvent.requestPermission === 'function') {
        await DeviceMotionEvent.requestPermission();
      }
      
      if (typeof DeviceOrientationEvent !== 'undefined' && 
          typeof DeviceOrientationEvent.requestPermission === 'function') {
        await DeviceOrientationEvent.requestPermission();
      }
      
      // Initialize audio system
      await this.initAudioSystem(stream);
      
      // Start the journey
      this.startJourney();
      
    } catch (error) {
      console.error('Permission denied:', error);
      alert('This experience requires microphone and motion access');
    } finally {
      this.ui.loadingOverlay.classList.remove('active');
    }
  }
  
  async initAudioSystem(stream) {
    // Create audio context
    this.audioContext = new (window.AudioContext || window.webkitAudioContext)({
      sampleRate: this.config.sampleRate,
      latencyHint: 'interactive'
    });
    
    // Setup audio nodes
    this.setupAudioGraph(stream);
    
    // Initialize spatial audio
    this.setupSpatialAudio();
    
    // Setup beat scheduler
    this.setupScheduler();
    
    await this.audioContext.resume();
  }
  
  setupAudioGraph(stream) {
    // Microphone input
    this.audioNodes.micInput = this.audioContext.createMediaStreamSource(stream);
    
    // Analyser for visualization
    this.audioNodes.analyser = this.audioContext.createAnalyser();
    this.audioNodes.analyser.fftSize = 2048;
    
    // Master gain
    this.audioNodes.masterGain = this.audioContext.createGain();
    this.audioNodes.masterGain.gain.value = 0.7;
    
    // Compressor for dynamics
    this.audioNodes.compressor = this.audioContext.createDynamicsCompressor();
    this.audioNodes.compressor.threshold.value = -24;
    this.audioNodes.compressor.knee.value = 30;
    this.audioNodes.compressor.ratio.value = 12;
    this.audioNodes.compressor.attack.value = 0.003;
    this.audioNodes.compressor.release.value = 0.25;
    
    // Create effect sends
    this.setupEffects();
    
    // Connect main signal path
    this.audioNodes.micInput.connect(this.audioNodes.analyser);
    this.audioNodes.compressor.connect(this.audioNodes.masterGain);
    this.audioNodes.masterGain.connect(this.audioContext.destination);
  }
  
  setupEffects() {
    // Reverb
    this.audioNodes.reverb = this.audioContext.createConvolver();
    this.audioNodes.reverbGain = this.audioContext.createGain();
    this.audioNodes.reverbGain.gain.value = 0.3;
    
    // Create reverb impulse
    const length = this.audioContext.sampleRate * 3;
    const impulse = this.audioContext.createBuffer(2, length, this.audioContext.sampleRate);
    
    for (let channel = 0; channel < 2; channel++) {
      const channelData = impulse.getChannelData(channel);
      for (let i = 0; i < length; i++) {
        channelData[i] = (Math.random() * 2 - 1) * Math.pow(1 - i / length, 2);
      }
    }
    
    this.audioNodes.reverb.buffer = impulse;
    this.audioNodes.reverb.connect(this.audioNodes.reverbGain);
    this.audioNodes.reverbGain.connect(this.audioNodes.compressor);
    
    // Delay
    this.audioNodes.delay = this.audioContext.createDelay(2);
    this.audioNodes.delayGain = this.audioContext.createGain();
    this.audioNodes.delayFeedback = this.audioContext.createGain();
    
    this.audioNodes.delay.delayTime.value = 60 / this.state.bpm / 4; // 16th note delay
    this.audioNodes.delayGain.gain.value = 0.4;
    this.audioNodes.delayFeedback.gain.value = 0.5;
    
    this.audioNodes.delay.connect(this.audioNodes.delayFeedback);
    this.audioNodes.delayFeedback.connect(this.audioNodes.delay);
    this.audioNodes.delay.connect(this.audioNodes.delayGain);
    this.audioNodes.delayGain.connect(this.audioNodes.compressor);
    
    // Filter for motion control
    this.audioNodes.filter = this.audioContext.createBiquadFilter();
    this.audioNodes.filter.type = 'lowpass';
    this.audioNodes.filter.frequency.value = 2000;
    this.audioNodes.filter.Q.value = 5;
    this.audioNodes.filter.connect(this.audioNodes.compressor);
  }
  
  setupSpatialAudio() {
    // Create 3D panner nodes for spatial sound
    this.audioNodes.spatialPanners = [];
    
    for (let i = 0; i < 4; i++) {
      const panner = this.audioContext.createPanner();
      panner.panningModel = 'HRTF';
      panner.distanceModel = 'inverse';
      panner.refDistance = 1;
      panner.maxDistance = 10;
      panner.rolloffFactor = 1;
      panner.coneInnerAngle = 360;
      
      // Position in 3D space
      const angle = (i / 4) * Math.PI * 2;
      panner.positionX.value = Math.cos(angle) * 2;
      panner.positionY.value = 0;
      panner.positionZ.value = Math.sin(angle) * 2;
      
      panner.connect(this.audioNodes.compressor);
      this.audioNodes.spatialPanners.push(panner);
    }
    
    // Listener position (user)
    const listener = this.audioContext.listener;
    listener.positionX.value = 0;
    listener.positionY.value = 0;
    listener.positionZ.value = 0;
  }
  
  setupScheduler() {
    const scheduleAheadTime = 0.1; // Schedule 100ms ahead
    const tempo = this.state.bpm;
    const secondsPerBeat = 60.0 / tempo;
    
    let currentNote = 0;
    let nextNoteTime = this.audioContext.currentTime;
    
    this.scheduler = () => {
      while (nextNoteTime < this.audioContext.currentTime + scheduleAheadTime) {
        this.scheduleNote(currentNote, nextNoteTime);
        
        // Advance to next 16th note
        nextNoteTime += secondsPerBeat / 4;
        currentNote++;
        
        if (currentNote === 16) {
          currentNote = 0;
          this.onBarComplete();
        }
      }
      
      this.schedulerTimer = setTimeout(this.scheduler, 25);
    };
  }
  
  scheduleNote(noteNumber, time) {
    // Metronome/kick pattern based on state
    if (this.state.currentState !== 'void') {
      if (noteNumber % 4 === 0) { // Quarter notes
        this.playKick(time);
      }
      
      if (this.state.currentState === 'rhythmic' || this.state.currentState === 'elevated') {
        if (noteNumber % 4 === 2) { // Off-beats
          this.playSnare(time);
        }
      }
      
      if (this.state.currentState === 'elevated' || this.state.currentState === 'chaos') {
        if (noteNumber % 2 === 1) { // 8th note hi-hats
          this.playHiHat(time);
        }
      }
    }
    
    // Trigger sample playback based on pattern
    this.triggerSamplePattern(noteNumber, time);
  }
  
  playKick(time) {
    const osc = this.audioContext.createOscillator();
    const gain = this.audioContext.createGain();
    
    osc.frequency.setValueAtTime(60, time);
    osc.frequency.exponentialRampToValueAtTime(0.01, time + 0.5);
    
    gain.gain.setValueAtTime(0.7, time);
    gain.gain.exponentialRampToValueAtTime(0.01, time + 0.5);
    
    osc.connect(gain);
    gain.connect(this.audioNodes.compressor);
    
    osc.start(time);
    osc.stop(time + 0.5);
  }
  
  playSnare(time) {
    const noise = this.audioContext.createBufferSource();
    const noiseBuffer = this.audioContext.createBuffer(1, 0.1 * this.audioContext.sampleRate, this.audioContext.sampleRate);
    const noiseData = noiseBuffer.getChannelData(0);
    
    for (let i = 0; i < noiseData.length; i++) {
      noiseData[i] = Math.random() * 2 - 1;
    }
    
    noise.buffer = noiseBuffer;
    
    const noiseGain = this.audioContext.createGain();
    const noiseFilter = this.audioContext.createBiquadFilter();
    
    noiseFilter.type = 'highpass';
    noiseFilter.frequency.value = 1000;
    
    noiseGain.gain.setValueAtTime(0.2, time);
    noiseGain.gain.exponentialRampToValueAtTime(0.01, time + 0.2);
    
    noise.connect(noiseFilter);
    noiseFilter.connect(noiseGain);
    noiseGain.connect(this.audioNodes.compressor);
    
    noise.start(time);
  }
  
  playHiHat(time) {
    const noise = this.audioContext.createBufferSource();
    const noiseBuffer = this.audioContext.createBuffer(1, 0.05 * this.audioContext.sampleRate, this.audioContext.sampleRate);
    const noiseData = noiseBuffer.getChannelData(0);
    
    for (let i = 0; i < noiseData.length; i++) {
      noiseData[i] = Math.random() * 2 - 1;
    }
    
    noise.buffer = noiseBuffer;
    
    const noiseGain = this.audioContext.createGain();
    const noiseFilter = this.audioContext.createBiquadFilter();
    
    noiseFilter.type = 'highpass';
    noiseFilter.frequency.value = 8000;
    
    noiseGain.gain.setValueAtTime(0.05, time);
    noiseGain.gain.exponentialRampToValueAtTime(0.01, time + 0.05);
    
    noise.connect(noiseFilter);
    noiseFilter.connect(noiseGain);
    noiseGain.connect(this.audioNodes.compressor);
    
    noise.start(time);
  }
  
  triggerSamplePattern(noteNumber, time) {
    // Play samples based on current state and pattern
    if (this.state.samples.size > 0) {
      const samples = Array.from(this.state.samples.values());
      
      // Different patterns for different states
      switch(this.state.currentState) {
        case 'ambient':
          if (noteNumber === 0) {
            this.playSampleAt(samples[0], time, 0);
          }
          break;
          
        case 'rhythmic':
          if (noteNumber % 8 === 0 && samples[0]) {
            this.playSampleAt(samples[0], time, 0);
          }
          if (noteNumber % 8 === 4 && samples[1]) {
            this.playSampleAt(samples[1], time, 1);
          }
          break;
          
        case 'elevated':
          samples.forEach((sample, index) => {
            if (noteNumber % (4 + index) === 0) {
              this.playSampleAt(sample, time, index);
            }
          });
          break;
          
        case 'chaos':
          // Random triggering
          if (Math.random() > 0.7) {
            const randomSample = samples[Math.floor(Math.random() * samples.length)];
            const randomPanner = Math.floor(Math.random() * 4);
            this.playSampleAt(randomSample, time, randomPanner);
          }
          break;
      }
    }
  }
  
  playSampleAt(sample, time, pannerIndex) {
    if (!sample || !sample.buffer) return;
    
    const source = this.audioContext.createBufferSource();
    source.buffer = sample.buffer;
    
    // Apply pitch variation based on motion
    source.playbackRate.value = 1 + (this.state.motionLevel - 0.5) * 0.2;
    
    // Route through spatial panner
    const panner = this.audioNodes.spatialPanners[pannerIndex % 4];
    source.connect(panner);
    
    // Also send to effects
    const effectSend = this.audioContext.createGain();
    effectSend.gain.value = 0.3;
    source.connect(effectSend);
    effectSend.connect(this.audioNodes.reverb);
    effectSend.connect(this.audioNodes.delay);
    
    source.start(time);
    
    // Visual feedback
    const orbIndex = Array.from(this.state.samples.keys()).indexOf(pannerIndex);
    if (orbIndex >= 0) {
      this.flashOrb(orbIndex);
    }
  }
  
  flashOrb(index) {
    const orb = this.ui.sampleOrbs[index];
    if (!orb) return;
    
    orb.classList.add('playing');
    setTimeout(() => orb.classList.remove('playing'), 200);
  }
  
  onBarComplete() {
    // Auto-adjust BPM based on motion
    if (this.state.motionLevel > 0.7) {
      this.state.bpm = Math.min(140, this.state.bpm + 1);
    } else if (this.state.motionLevel < 0.3) {
      this.state.bpm = Math.max(100, this.state.bpm - 1);
    }
    
    this.ui.bpmDisplay.textContent = `${Math.round(this.state.bpm)} BPM`;
    
    // Update delay time to match tempo
    this.audioNodes.delay.delayTime.value = 60 / this.state.bpm / 4;
  }
  
  startJourney() {
    console.log('ðŸš€ Journey started');
    
    // Hide permission overlay
    this.ui.permissionOverlay.classList.add('hidden');
    
    // Initialize journey
    this.state.journeyStartTime = Date.now();
    
    // Setup motion detection
    this.setupMotionDetection();
    
    // Start beat scheduler
    this.scheduler();
    
    // Start AI DJ auto-sampling
    this.startAIDJ();
    
    // Start visualization
    this.startVisualization();
    
    // Start journey progression
    this.startJourneyProgression();
    
    // Initial state check
    this.checkInitialMotion();
  }
  
  setupMotionDetection() {
    let lastX = 0, lastY = 0, lastZ = 0;
    
    window.addEventListener('devicemotion', (event) => {
      const acc = event.accelerationIncludingGravity;
      if (!acc) return;
      
      const deltaX = Math.abs(acc.x - lastX);
      const deltaY = Math.abs(acc.y - lastY);
      const deltaZ = Math.abs(acc.z - lastZ);
      
      const totalMotion = (deltaX + deltaY + deltaZ) / 30;
      this.state.motionLevel = Math.min(1, totalMotion);
      
      // Update UI
      this.ui.motionLevel.style.width = (this.state.motionLevel * 100) + '%';
      this.ui.debug.motion.textContent = this.state.motionLevel.toFixed(2);
      
      // Update filter based on motion
      const filterFreq = 200 + this.state.motionLevel * 5000;
      this.audioNodes.filter.frequency.setTargetAtTime(filterFreq, this.audioContext.currentTime, 0.1);
      
      lastX = acc.x || 0;
      lastY = acc.y || 0;
      lastZ = acc.z || 0;
      
      // Store motion data for analysis
      this.motionData.push({
        level: this.state.motionLevel,
        time: Date.now()
      });
      
      // Keep only last 100 samples
      if (this.motionData.length > 100) {
        this.motionData.shift();
      }
    });
    
    // Device orientation for spatial positioning
    window.addEventListener('deviceorientation', (event) => {
      if (!event.alpha) return;
      
      const alpha = event.alpha * Math.PI / 180;
      const beta = event.beta * Math.PI / 180;
      const gamma = event.gamma * Math.PI / 180;
      
      // Update spatial position
      this.state.spatialPosition = {
        x: Math.sin(gamma) * Math.cos(alpha),
        y: Math.sin(beta),
        z: Math.cos(gamma) * Math.cos(alpha)
      };
      
      // Update listener position
      const listener = this.audioContext.listener;
      listener.positionX.setValueAtTime(this.state.spatialPosition.x * 2, this.audioContext.currentTime);
      listener.positionY.setValueAtTime(this.state.spatialPosition.y * 2, this.audioContext.currentTime);
      listener.positionZ.setValueAtTime(this.state.spatialPosition.z * 2, this.audioContext.currentTime);
      
      // Update visual indicator
      this.updateSpatialIndicator();
    });
  }
  
  updateSpatialIndicator() {
    const dot = this.ui.spatialDot;
    const x = 150 + this.state.spatialPosition.x * 100;
    const y = 150 + this.state.spatialPosition.z * 100;
    
    dot.style.left = x + 'px';
    dot.style.top = y + 'px';
  }
  
  checkInitialMotion() {
    // Wait 2 seconds to analyze initial motion
    setTimeout(() => {
      const avgMotion = this.motionData.reduce((sum, d) => sum + d.level, 0) / Math.max(1, this.motionData.length);
      
      if (avgMotion > 0.5) {
        // Lots of motion - start elevated
        this.transitionToState('elevated');
        console.log('ðŸŽ‰ Starting elevated - high motion detected!');
      } else {
        // Still - start with ethereal void
        this.transitionToState('void');
        console.log('ðŸŒŒ Starting in the void - minimal motion');
        
        // Start first auto-sample after 2 seconds
        setTimeout(() => this.autoSample(), 2000);
      }
    }, 2000);
  }
  
  transitionToState(newState) {
    console.log(`ðŸŽ­ State transition: ${this.state.currentState} -> ${newState}`);
    
    this.state.currentState = newState;
    this.ui.envState.textContent = newState.toUpperCase();
    this.ui.debug.state.textContent = newState.toUpperCase();
    
    // Update visual atmosphere
    switch(newState) {
      case 'void':
        this.ui.quantumField.className = '';
        this.audioNodes.reverbGain.gain.setTargetAtTime(0.8, this.audioContext.currentTime, 1);
        this.audioNodes.delayGain.gain.setTargetAtTime(0.6, this.audioContext.currentTime, 1);
        break;
        
      case 'ambient':
        this.ui.quantumField.className = '';
        this.audioNodes.reverbGain.gain.setTargetAtTime(0.5, this.audioContext.currentTime, 1);
        this.audioNodes.delayGain.gain.setTargetAtTime(0.4, this.audioContext.currentTime, 1);
        break;
        
      case 'rhythmic':
        this.ui.quantumField.className = '';
        this.audioNodes.reverbGain.gain.setTargetAtTime(0.3, this.audioContext.currentTime, 1);
        this.audioNodes.delayGain.gain.setTargetAtTime(0.3, this.audioContext.currentTime, 1);
        break;
        
      case 'elevated':
        this.ui.quantumField.className = 'elevated';
        this.audioNodes.reverbGain.gain.setTargetAtTime(0.2, this.audioContext.currentTime, 1);
        this.audioNodes.delayGain.gain.setTargetAtTime(0.5, this.audioContext.currentTime, 1);
        break;
        
      case 'chaos':
        this.ui.quantumField.className = 'elevated';
        this.audioNodes.reverbGain.gain.setTargetAtTime(0.4, this.audioContext.currentTime, 1);
        this.audioNodes.delayGain.gain.setTargetAtTime(0.7, this.audioContext.currentTime, 1);
        break;
    }
  }
  
  startAIDJ() {
    if (!this.state.aiDjActive) return;
    
    // Auto-sample at regular intervals
    this.aiDjInterval = setInterval(() => {
      if (this.state.samples.size < 4 && !this.state.isRecording) {
        this.autoSample();
      }
    }, this.config.autoSampleInterval);
  }
  
  autoSample() {
    if (this.state.isRecording) return;
    
    console.log('ðŸŽ™ï¸ AI DJ: Auto-sampling environment...');
    
    const slot = this.state.nextSampleSlot;
    this.state.nextSampleSlot = (this.state.nextSampleSlot + 1) % 4;
    
    this.startRecording(slot);
    
    // Record for 4 seconds
    setTimeout(() => {
      this.stopRecording(slot);
    }, this.config.sampleDuration);
  }
  
  startRecording(slot) {
    if (this.state.isRecording) return;
    
    this.state.isRecording = true;
    this.recordBuffer = [];
    
    // Visual feedback
    this.ui.sampleOrbs[slot].classList.add('recording');
    
    // Create recorder
    const recorder = this.audioContext.createScriptProcessor(4096, 1, 1);
    
    recorder.onaudioprocess = (e) => {
      const input = e.inputBuffer.getChannelData(0);
      this.recordBuffer.push(...input);
    };
    
    this.audioNodes.micInput.connect(recorder);
    recorder.connect(this.audioContext.destination);
    
    this.currentRecorder = recorder;
  }
  
  stopRecording(slot) {
    if (!this.state.isRecording) return;
    
    this.state.isRecording = false;
    
    // Disconnect recorder
    if (this.currentRecorder) {
      this.currentRecorder.disconnect();
      this.audioNodes.micInput.disconnect(this.currentRecorder);
      this.currentRecorder = null;
    }
    
    // Process sample
    if (this.recordBuffer && this.recordBuffer.length > 0) {
      this.processSample(slot, new Float32Array(this.recordBuffer));
    }
    
    // Update UI
    this.ui.sampleOrbs[slot].classList.remove('recording');
    this.ui.sampleOrbs[slot].classList.add('loaded');
  }
  
  processSample(slot, audioData) {
    // Apply auto-tune and processing
    const processedData = this.applyAutoTune(audioData);
    
    // Create buffer
    const buffer = this.audioContext.createBuffer(1, processedData.length, this.audioContext.sampleRate);
    buffer.getChannelData(0).set(processedData);
    
    // Store sample
    this.state.samples.set(slot, {
      buffer: buffer,
      originalData: audioData,
      timestamp: Date.now()
    });
    
    console.log(`âœ… Sample ${slot} processed and stored`);
    this.ui.debug.samples.textContent = this.state.samples.size;
    
    // Transition state if first sample
    if (this.state.samples.size === 1 && this.state.currentState === 'void') {
      this.transitionToState('ambient');
    }
  }
  
  applyAutoTune(audioData) {
    // Simple pitch correction and beat alignment
    // This is a simplified version - real autotune would need pitch detection
    
    const processed = new Float32Array(audioData.length);
    const fadeLength = Math.min(1000, audioData.length / 10);
    
    for (let i = 0; i < audioData.length; i++) {
      let sample = audioData[i];
      
      // Apply fade in/out
      if (i < fadeLength) {
        sample *= i / fadeLength;
      } else if (i > audioData.length - fadeLength) {
        sample *= (audioData.length - i) / fadeLength;
      }
      
      // Simple compression
      sample = Math.tanh(sample * 2) * 0.5;
      
      processed[i] = sample;
    }
    
    return processed;
  }
  
  startJourneyProgression() {
    // Update journey timeline
    this.journeyInterval = setInterval(() => {
      const elapsed = Date.now() - this.state.journeyStartTime;
      const progress = Math.min(100, (elapsed / this.config.journeyDuration) * 100);
      
      this.ui.journeyProgress.style.width = progress + '%';
      
      // State transitions based on journey time and motion
      const journeyPhase = Math.floor(elapsed / (this.config.journeyDuration / 5));
      const avgMotion = this.getAverageMotion();
      
      switch(journeyPhase) {
        case 0: // 0-5 minutes: Introduction
          if (avgMotion > 0.6 && this.state.currentState === 'void') {
            this.transitionToState('ambient');
          }
          break;
          
        case 1: // 5-10 minutes: Building
          if (this.state.currentState === 'void' || this.state.currentState === 'ambient') {
            this.transitionToState('rhythmic');
          }
          break;
          
        case 2: // 10-15 minutes: Peak
          if (avgMotion > 0.5) {
            this.transitionToState('elevated');
          }
          break;
          
        case 3: // 15-20 minutes: Exploration
          if (avgMotion > 0.7) {
            this.transitionToState('chaos');
          } else {
            this.transitionToState('elevated');
          }
          break;
          
        case 4: // 20-25 minutes: Resolution
          if (this.state.currentState === 'chaos' || this.state.currentState === 'elevated') {
            this.transitionToState('ambient');
          }
          break;
      }
      
      // End journey after 25 minutes
      if (elapsed >= this.config.journeyDuration) {
        this.endJourney();
      }
      
    }, 1000);
  }
  
  getAverageMotion() {
    if (this.motionData.length === 0) return 0;
    return this.motionData.reduce((sum, d) => sum + d.level, 0) / this.motionData.length;
  }
  
  startVisualization() {
    const draw = () => {
      this.drawSpatialField();
      requestAnimationFrame(draw);
    };
    requestAnimationFrame(draw);
  }
  
  drawSpatialField() {
    const ctx = this.spatialCtx;
    const width = this.ui.spatialCanvas.width;
    const height = this.ui.spatialCanvas.height;
    
    // Fade effect
    ctx.fillStyle = 'rgba(0, 0, 0, 0.05)';
    ctx.fillRect(0, 0, width, height);
    
    // Draw spatial sound sources
    this.audioNodes.spatialPanners.forEach((panner, i) => {
      const x = width/2 + panner.positionX.value * 50;
      const y = height/2 + panner.positionZ.value * 50;
      
      ctx.beginPath();
      ctx.arc(x, y, 5 + this.state.motionLevel * 10, 0, Math.PI * 2);
      ctx.fillStyle = `rgba(0, 255, 255, ${0.3 + this.state.motionLevel * 0.5})`;
      ctx.fill();
    });
    
    // Draw motion trails
    if (this.state.motionLevel > 0.1) {
      ctx.strokeStyle = `rgba(255, 0, 255, ${this.state.motionLevel * 0.5})`;
      ctx.lineWidth = 2;
      ctx.beginPath();
      
      for (let i = 0; i < 5; i++) {
        const angle = (Date.now() / 1000 + i) * this.state.motionLevel;
        const radius = 100 + i * 20;
        const x = width/2 + Math.cos(angle) * radius;
        const y = height/2 + Math.sin(angle) * radius;
        
        if (i === 0) {
          ctx.moveTo(x, y);
        } else {
          ctx.lineTo(x, y);
        }
      }
      
      ctx.stroke();
    }
  }
  
  toggleMotion() {
    this.ui.btnMotion.classList.toggle('active');
    // Motion is always active, this just shows/hides debug info
  }
  
  toggleAIDJ() {
    this.state.aiDjActive = !this.state.aiDjActive;
    this.ui.btnAI.classList.toggle('active');
    
    if (this.state.aiDjActive) {
      this.startAIDJ();
    } else {
      clearInterval(this.aiDjInterval);
    }
  }
  
  toggle3D() {
    this.ui.btnSpatial.classList.toggle('active');
    // 3D is always active, this could toggle visualization
  }
  
  endJourney() {
    console.log('ðŸŒ… Journey complete');
    
    clearInterval(this.journeyInterval);
    clearTimeout(this.schedulerTimer);
    clearInterval(this.aiDjInterval);
    
    // Fade out
    this.audioNodes.masterGain.gain.exponentialRampToValueAtTime(0.01, this.audioContext.currentTime + 5);
    
    // Show completion
    this.ui.envState.textContent = 'JOURNEY COMPLETE';
  }
}

// Initialize on load
const neuromancer = new NeuromancerEngine();

console.log('ðŸŽµ NEUROMANCER READY');
console.log('ðŸ“± Grant permissions to begin your 25-minute journey');
console.log('ðŸŽ­ Your movement and environment will shape the music');
</script>
</body>
</html>
