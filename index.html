<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>GUMP - Jazz Orchestra</title>
    <!-- Puter.js for free Kimi K2 AI -->
    <script src="https://js.puter.com/v2/"></script>
    <style>
        :root{--phi:1.618}
        *{margin:0;padding:0;box-sizing:border-box}
        body{background:#050508;overflow:hidden;touch-action:none;height:100vh;font-family:system-ui,-apple-system,sans-serif}
        canvas{position:fixed;inset:0}

        #enter{position:fixed;inset:0;display:flex;align-items:center;justify-content:center;z-index:100;cursor:pointer;background:#050508}
        #enter.off{display:none}
        #enter i{width:89px;height:89px;border-radius:50%;border:1px solid rgba(200,180,255,0.1);display:flex;align-items:center;justify-content:center}
        #enter i::after{content:'';width:34px;height:34px;border-radius:50%;border:1px solid rgba(200,180,255,0.2)}

        #loading{position:fixed;inset:0;display:flex;align-items:center;justify-content:center;z-index:99;background:#050508;color:rgba(200,180,255,0.25);font-size:8px;letter-spacing:3px}
        #loading.off{display:none}

        #dials{position:fixed;bottom:0;left:0;right:0;z-index:50;padding:13px 21px 34px;touch-action:pan-x}
        .dial{display:flex;align-items:center;justify-content:center;gap:21px;margin-bottom:13px}
        .dial-opt{font-size:11px;color:rgba(200,180,255,0.15);cursor:pointer;padding:8px 13px;transition:all 0.3s;letter-spacing:1px;-webkit-tap-highlight-color:transparent}
        .dial-opt.on{color:rgba(200,180,255,0.8)}
        .dial-line{width:1px;height:13px;background:rgba(200,180,255,0.06)}

        #band-status{position:fixed;top:13px;left:13px;z-index:50;font-size:9px;color:rgba(200,180,255,0.35);letter-spacing:1px;line-height:1.6}
        #band-status .agent{opacity:0.4;transition:opacity 0.5s}
        #band-status .agent.active{opacity:1;color:rgba(200,180,255,0.7)}
        #band-status .direction{position:absolute;top:0;right:13px;color:rgba(200,180,255,0.25)}
    </style>
</head>
<body>
<div id="enter"><i></i></div>
<div id="loading" class="off">...</div>
<div id="band-status" style="display:none">
    <div class="agent" id="st-drums">drums: steady</div>
    <div class="agent" id="st-bass">bass: root</div>
    <div class="agent" id="st-pad">pad: close</div>
    <div class="agent" id="st-lead">lead: rest</div>
    <div class="direction" id="st-direction">~</div>
</div>

<div id="dials" style="display:none">
    <div class="dial" data-dial="pulse">
        <span class="dial-opt" data-v="0">—</span>
        <span class="dial-line"></span>
        <span class="dial-opt on" data-v="dust">dust</span>
        <span class="dial-line"></span>
        <span class="dial-opt" data-v="gold">gold</span>
        <span class="dial-line"></span>
        <span class="dial-opt" data-v="drive">drive</span>
    </div>
    <div class="dial" data-dial="depth">
        <span class="dial-opt" data-v="0">—</span>
        <span class="dial-line"></span>
        <span class="dial-opt on" data-v="sub">sub</span>
        <span class="dial-line"></span>
        <span class="dial-opt" data-v="thick">thick</span>
        <span class="dial-line"></span>
        <span class="dial-opt" data-v="warm">warm</span>
    </div>
    <div class="dial" data-dial="haze">
        <span class="dial-opt" data-v="clear">clear</span>
        <span class="dial-line"></span>
        <span class="dial-opt on" data-v="fog">fog</span>
        <span class="dial-line"></span>
        <span class="dial-opt" data-v="glass">glass</span>
        <span class="dial-line"></span>
        <span class="dial-opt" data-v="heat">heat</span>
    </div>
</div>

<canvas id="c"></canvas>

<script>
// GUMP - THE CORE MAGIC
// Generative + Motion → Music + Layers + Lo-fi + Evolution

const TAU = Math.PI * 2;
const PHI = 1.618033988749;

let ctx, master, canvas, vc;
let running = false;

// State
let dial = { pulse: 'dust', depth: 'sub', haze: 'fog' };
let field = { x: 0.5, y: 0.5, energy: 0, time: 0, peak: 0 };

// Musical state - THE HEART
let music = {
    intensity: 0.4,
    bar: 0,
    phrase: 0,
    density: 0.5
};

// ============ SAMPLES ============

const URLS = {
    kick_a: 'https://cdn.freesound.org/previews/171/171104_2394245-lq.mp3',
    kick_b: 'https://cdn.freesound.org/previews/568/568573_12517458-lq.mp3',
    snare_a: 'https://cdn.freesound.org/previews/387/387186_7255534-lq.mp3',
    snare_b: 'https://cdn.freesound.org/previews/398/398712_183766-lq.mp3',
    hat_a: 'https://cdn.freesound.org/previews/250/250540_4486188-lq.mp3',
    hat_b: 'https://cdn.freesound.org/previews/353/353774_5121236-lq.mp3',
    perc: 'https://cdn.freesound.org/previews/250/250537_4486188-lq.mp3',
};

let samples = {};

async function loadSamples() {
    for (const [k, url] of Object.entries(URLS)) {
        try {
            const r = await fetch(url);
            samples[k] = await ctx.decodeAudioData(await r.arrayBuffer());
        } catch (e) {
            samples[k] = makeFallback(k);
        }
    }
}

function makeFallback(k) {
    const sr = ctx.sampleRate, len = sr * 0.4;
    const buf = ctx.createBuffer(2, len, sr);
    for (let ch = 0; ch < 2; ch++) {
        const d = buf.getChannelData(ch);
        if (k.includes('kick')) {
            for (let i = 0; i < len; i++) {
                const t = i / sr;
                d[i] = Math.sin(TAU * (140 * Math.exp(-t * 25) + 45) * t) * Math.exp(-t * 10) * 0.8;
            }
        } else if (k.includes('snare')) {
            for (let i = 0; i < len; i++) {
                const t = i / sr;
                d[i] = ((Math.random() * 2 - 1) * 0.7 + Math.sin(TAU * 180 * t) * 0.3) * Math.exp(-t * 15) * 0.6;
            }
        } else {
            for (let i = 0; i < len * 0.15; i++) {
                const t = i / sr;
                d[i] = (Math.random() * 2 - 1) * Math.exp(-t * 40) * 0.35;
            }
        }
    }
    return buf;
}

// ============ FX CHAIN ============

let drumBus, bassBus, padBus, masterBus;
let lofiFilter, verb, verbWet, dly, dlyWet, sat, comp, lim;

function initFX() {
    drumBus = ctx.createGain(); drumBus.gain.value = 0.75;
    bassBus = ctx.createGain(); bassBus.gain.value = 0.6;
    padBus = ctx.createGain(); padBus.gain.value = 0.4;
    masterBus = ctx.createGain();

    sat = ctx.createWaveShaper();
    const curve = new Float32Array(65536);
    for (let i = 0; i < 65536; i++) curve[i] = Math.tanh((i / 32768 - 1) * 1.5) * 0.95;
    sat.curve = curve;
    sat.oversample = '4x';

    lofiFilter = ctx.createBiquadFilter();
    lofiFilter.type = 'lowpass';
    lofiFilter.frequency.value = 18000;

    comp = ctx.createDynamicsCompressor();
    comp.threshold.value = -14;
    comp.ratio.value = 4;
    comp.attack.value = 0.003;
    comp.release.value = 0.12;

    lim = ctx.createDynamicsCompressor();
    lim.threshold.value = -2;
    lim.ratio.value = 20;
    lim.attack.value = 0.001;

    // Lush reverb
    verb = ctx.createConvolver();
    const vLen = ctx.sampleRate * 2.8;
    const vBuf = ctx.createBuffer(2, vLen, ctx.sampleRate);
    for (let ch = 0; ch < 2; ch++) {
        const d = vBuf.getChannelData(ch);
        for (let i = 0; i < vLen; i++) d[i] = (Math.random() * 2 - 1) * Math.exp(-i / ctx.sampleRate / 1.4) * 0.45;
    }
    verb.buffer = vBuf;
    verbWet = ctx.createGain();
    verbWet.gain.value = 0.22;

    // Tape delay
    dly = ctx.createDelay(1);
    dly.delayTime.value = 0.375;
    const dlyFb = ctx.createGain();
    dlyFb.gain.value = 0.35;
    const dlyFilt = ctx.createBiquadFilter();
    dlyFilt.type = 'lowpass';
    dlyFilt.frequency.value = 2400;
    dlyWet = ctx.createGain();
    dlyWet.gain.value = 0.16;
    dly.connect(dlyFilt).connect(dlyFb).connect(dly);
    dlyFilt.connect(dlyWet);

    master = ctx.createGain();
    master.gain.value = 0.85;

    // Routing
    [drumBus, bassBus, padBus].forEach(b => b.connect(masterBus));
    masterBus.connect(sat).connect(lofiFilter).connect(comp);
    masterBus.connect(verb); verb.connect(verbWet);
    masterBus.connect(dly);
    [comp, verbWet, dlyWet].forEach(n => n.connect(lim));
    lim.connect(master).connect(ctx.destination);
}

// ============ EUCLIDEAN PATTERN ENGINE ============

function euclidean(steps, pulses, rot = 0) {
    const p = [];
    let b = 0;
    for (let i = 0; i < steps; i++) {
        b += pulses;
        p.push(b >= steps ? (b -= steps, 1) : 0);
    }
    for (let i = 0; i < rot; i++) p.push(p.shift());
    return p;
}

const GENES = {
    dust: { bpm: 72, kickP: 3, swing: 0.12, ghost: 0.28, hatP: 0.4, kit: 'a' },
    gold: { bpm: 88, kickP: 5, swing: 0.16, ghost: 0.22, hatP: 0.55, kit: 'b' },
    drive: { bpm: 122, kickP: 4, swing: 0, ghost: 0.12, hatP: 0.7, kit: 'b' }
};

let pattern = null;
let step = 0;
let lastStep = 0;

function genPattern(gene, bar) {
    const g = GENES[gene];

    // AI INFLUENCE: Use bandState.drums to shape pattern
    const aiDensity = bandState.drums.density;
    const aiEnergy = bandState.drums.energy;
    const aiPattern = bandState.drums.pattern;

    const evolution = Math.sin(bar * 0.3 + field.x * 2) * 0.6;
    let kickPulses = Math.round(g.kickP + evolution);

    // AI adjusts kick density
    if (aiPattern === 'pushing') kickPulses = Math.min(7, kickPulses + 1);
    if (aiPattern === 'sparse' || aiPattern === 'minimal') kickPulses = Math.max(2, kickPulses - 2);

    const kicks = euclidean(16, kickPulses, bar % 5);

    const snares = new Array(16).fill(0);
    snares[4] = 0.9; snares[12] = 1;
    // Variation based on phrase
    if (music.phrase === 3) snares[10] = 0.5;
    if (music.phrase === 7) snares[14] = 0.6;

    // AI FILL: Add extra hits when AI calls for fill
    if (aiPattern === 'fill' && bandState.drums.lastFill === bar) {
        // Jazz fill - toms and snare flurry in last 4 steps
        snares[13] = 0.6;
        snares[14] = 0.7;
        snares[15] = 0.5;
    }

    // AI ACCENT: Strong hit on downbeat
    if (aiPattern === 'accenting') {
        kicks[0] = 1;
        snares[4] = 1;
    }

    // Hats driven by intensity AND AI density
    const hats = [];
    const hatDensity = g.hatP * (0.4 + aiDensity * 0.4 + music.intensity * 0.3);
    for (let i = 0; i < 16; i++) {
        if (aiPattern === 'minimal' && i % 4 !== 0) {
            hats.push(0); // Minimal = only quarter notes
        } else {
            hats.push(Math.random() < hatDensity ? 0.2 + Math.random() * 0.35 : 0);
        }
    }

    // Ghost notes - AI sparse pattern reduces these
    const ghostProb = aiPattern === 'sparse' ? g.ghost * 0.3 : g.ghost;
    const ghosts = kicks.map((k, i) =>
        !k && !snares[i] && Math.random() < ghostProb * music.intensity * aiDensity ? 0.12 + Math.random() * 0.1 : 0
    );

    // Perc accents - more when pushing
    const percs = [];
    const percProb = aiPattern === 'pushing' ? 0.35 : 0.2;
    for (let i = 0; i < 16; i++) {
        percs.push(i % 4 === 2 && Math.random() < percProb * music.intensity ? 0.15 : 0);
    }

    return { kicks, snares, hats, ghosts, percs, swing: g.swing, kit: g.kit, bpm: g.bpm };
}

function play(buf, opts = {}) {
    if (!buf) return;
    const src = ctx.createBufferSource();
    src.buffer = buf;
    if (opts.pitch) src.playbackRate.value = Math.pow(2, opts.pitch / 12);

    const g = ctx.createGain();
    g.gain.value = opts.vol || 1;

    let node = src;
    if (opts.filter) {
        const f = ctx.createBiquadFilter();
        f.type = 'lowpass';
        f.frequency.value = opts.filter;
        src.connect(f);
        node = f;
    }

    if (opts.pan) {
        const p = ctx.createStereoPanner();
        p.pan.value = opts.pan;
        node.connect(p).connect(g);
    } else {
        node.connect(g);
    }

    g.connect(opts.bus || drumBus);
    // Humanize timing
    src.start(ctx.currentTime + (opts.delay || 0) + (Math.random() - 0.5) * 0.006);
}

function updateBeats() {
    if (dial.pulse === '0') return;

    const gene = GENES[dial.pulse];
    if (!gene) return;

    const stepDur = 60 / gene.bpm / 4;
    const now = ctx.currentTime;

    if (now - lastStep >= stepDur) {
        lastStep = now;

        // New pattern each bar
        if (step % 16 === 0) {
            music.bar++;
            music.phrase = music.bar % 8;
            pattern = genPattern(dial.pulse, music.bar);

            // CORE MAGIC: Motion → Intensity
            music.intensity = music.intensity * 0.85 + field.peak * 0.15;
            music.intensity = Math.max(0.25, Math.min(1, music.intensity));
            music.density = 0.4 + music.intensity * 0.4;
        }

        if (!pattern) return;

        const s = step % 16;
        const sw = s % 2 === 1 ? stepDur * pattern.swing : 0;
        const k = pattern.kit;

        // DRUMS - the groove
        if (pattern.kicks[s]) {
            const vel = 0.8 + music.intensity * 0.2;
            play(samples['kick_' + k], { vol: vel, delay: sw });
        }

        if (pattern.snares[s]) {
            const vel = pattern.snares[s] * (0.7 + music.intensity * 0.25);
            play(samples['snare_' + k], { vol: vel, delay: sw, pan: (Math.random() - 0.5) * 0.12 });
        }

        if (pattern.hats[s]) {
            const vel = pattern.hats[s] * (0.5 + music.density * 0.4);
            const filt = dial.haze === 'fog' ? 5500 : dial.haze === 'heat' ? 7000 : 11000;
            play(samples['hat_' + k], { vol: vel, delay: sw, pan: (Math.random() - 0.5) * 0.4, filter: filt });
        }

        if (pattern.ghosts[s]) {
            play(samples['kick_' + k], { vol: pattern.ghosts[s], delay: sw, filter: 700, pitch: -3 });
        }

        if (pattern.percs[s]) {
            play(samples['perc'], { vol: pattern.percs[s], delay: sw, pan: (Math.random() - 0.5) * 0.6, pitch: 5 });
        }

        step++;
    }
}

// ============ BASS - EVOLVING ============

let bassO1, bassO2, bassF, bassG, bassLFO, bassLFOG;

function initBass() {
    bassO1 = ctx.createOscillator();
    bassO2 = ctx.createOscillator();
    bassO1.type = bassO2.type = 'sine';
    bassO1.frequency.value = bassO2.frequency.value = 55;
    bassO2.detune.value = 7;

    bassF = ctx.createBiquadFilter();
    bassF.type = 'lowpass';
    bassF.frequency.value = 350;
    bassF.Q.value = 1.8;

    bassLFO = ctx.createOscillator();
    bassLFO.frequency.value = 0.35;
    bassLFOG = ctx.createGain();
    bassLFOG.gain.value = 0;
    bassLFO.connect(bassLFOG).connect(bassF.frequency);
    bassLFO.start();

    bassG = ctx.createGain();
    bassG.gain.value = 0;

    const mix = ctx.createGain();
    mix.gain.value = 0.5;
    bassO1.connect(mix);
    bassO2.connect(mix);
    mix.connect(bassF).connect(bassG).connect(bassBus);
    bassO1.start();
    bassO2.start();
}

// Bass sequence evolves
let bassSeq = [0, 0, 5, 3];
let lastBassShift = 0;
let walkingBassStep = 0;

// Walking bass patterns - jazz movement
const WALKING_PATTERNS = [
    [0, 2, 4, 5],   // Ascending scale
    [0, -2, -4, -5], // Descending
    [0, 5, 3, 7],   // Arpeggiated
    [0, 7, 5, 3],   // Descending arp
    [0, 0, 5, 7],   // Pedal then move
    [0, 3, 5, 6],   // Chromatic approach
];

function updateBass() {
    if (dial.depth === '0') {
        bassG.gain.linearRampToValueAtTime(0, ctx.currentTime + 0.1);
        return;
    }

    const cfg = {
        sub: { t1: 'sine', t2: 'sine', base: 32.7, filt: 200, lfo: 0, vol: 0.55, det: 5 },
        thick: { t1: 'sawtooth', t2: 'sawtooth', base: 55, filt: 550, lfo: 100, vol: 0.38, det: 18 },
        warm: { t1: 'triangle', t2: 'sine', base: 55, filt: 650, lfo: 35, vol: 0.42, det: 8 }
    }[dial.depth];

    if (!cfg) return;

    // AI INFLUENCE: Bass behavior from bandState
    const aiWalking = bandState.bass.walking;
    const aiRegister = bandState.bass.register;
    const aiActivity = bandState.bass.activity;

    // Register affects base frequency
    const registerMult = { low: 0.5, mid: 1, high: 2 }[aiRegister] || 1;

    // When AI says walk, use walking patterns
    if (aiWalking) {
        // Pick a walking pattern based on bar
        const walkPattern = WALKING_PATTERNS[music.bar % WALKING_PATTERNS.length];
        walkingBassStep = (walkingBassStep + 1) % 4;
        bassSeq = walkPattern;
    } else {
        // Standard evolution
        if (field.time - lastBassShift > 4 && Math.random() < 0.06 * aiActivity) {
            lastBassShift = field.time;
            bassSeq[Math.floor(Math.random() * 4)] = [0, 3, 5, 7, -5, -7][Math.floor(Math.random() * 6)];
        }
    }

    // AI climbing/descending affects sequence
    if (aiRegister === 'high' && music.bar % 4 === 0) {
        bassSeq = bassSeq.map(n => n + 5); // Shift up
    } else if (aiRegister === 'low' && music.bar % 4 === 0) {
        bassSeq = bassSeq.map(n => Math.max(-12, n - 3)); // Shift down
    }

    const note = bassSeq[music.bar % 4];
    let freq = cfg.base * registerMult * Math.pow(2, note / 12) * Math.pow(2, (1 - field.y) * 0.45);

    bassO1.type = cfg.t1;
    bassO2.type = cfg.t2;
    bassO1.frequency.linearRampToValueAtTime(freq, ctx.currentTime + 0.04);
    bassO2.frequency.linearRampToValueAtTime(freq, ctx.currentTime + 0.04);
    bassO2.detune.value = cfg.det;

    // Filter opens with energy AND activity
    const filtMod = 1 + field.energy * 1.8 + music.intensity * 0.6 + aiActivity * 0.4;
    bassF.frequency.linearRampToValueAtTime(cfg.filt * filtMod, ctx.currentTime + 0.05);
    bassLFOG.gain.value = cfg.lfo * music.intensity * aiActivity;
    bassLFO.frequency.value = 0.25 + field.energy * 1.5 + (aiWalking ? 0.5 : 0);

    // Volume affected by AI activity level
    const vol = cfg.vol * (0.5 + aiActivity * 0.5);
    bassG.gain.linearRampToValueAtTime(vol, ctx.currentTime + 0.1);
}

// ============ PAD LAYER ============

let padOscs = [], padG, padF;

const CHORDS = {
    dust: [[0, 3, 7, 10], [5, 8, 12, 15], [3, 7, 10, 14], [7, 10, 14, 17]],
    gold: [[0, 4, 7, 11], [5, 9, 12, 16], [7, 11, 14, 17], [0, 4, 7, 11]],
    drive: [[0, 3, 7, 12], [5, 8, 12, 17], [7, 10, 14, 19], [0, 3, 7, 12]]
};

function initPad() {
    padG = ctx.createGain();
    padG.gain.value = 0;
    padF = ctx.createBiquadFilter();
    padF.type = 'lowpass';
    padF.frequency.value = 1600;

    for (let i = 0; i < 4; i++) {
        const o = ctx.createOscillator();
        o.type = 'sine';
        o.frequency.value = 220;
        const g = ctx.createGain();
        g.gain.value = 0.1 / (i + 1);
        o.connect(g).connect(padF);
        o.start();
        padOscs.push({ o, g });
    }
    padF.connect(padG).connect(padBus);
}

// AI voicing variations - jazz piano voicings
const VOICINGS = {
    close: [0, 3, 7, 10],      // Standard close voicing
    spread: [0, 7, 10, 15],    // Open voicing, more space
    shell: [0, 10, 14, 0],     // Shell voicing (root, 7th, 3rd)
    rich: [0, 4, 7, 11],       // Major 7 lush
    sparse: [0, 7, 0, 0],      // Just root and 5th - minimal
    out: [0, 6, 11, 16]        // Tritone sub - outside harmony
};

function updatePad() {
    const genre = dial.pulse === '0' ? 'dust' : dial.pulse;
    const chords = CHORDS[genre] || CHORDS.dust;
    const baseChord = chords[music.bar % 4];
    const base = 110 * Math.pow(2, (1 - field.y) * 0.35);

    // AI INFLUENCE: Voicing from bandState
    const aiVoicing = bandState.pad.voicing;
    const aiVolume = bandState.pad.volume;
    const voicing = VOICINGS[aiVoicing] || VOICINGS.close;

    // Blend base chord with AI voicing
    padOscs.forEach((p, i) => {
        // Use voicing offsets, but transpose based on base chord root
        const chordRoot = baseChord[0] || 0;
        const voicingNote = voicing[i] || 0;
        const finalNote = chordRoot + voicingNote;
        const freq = base * Math.pow(2, finalNote / 12);
        p.o.frequency.linearRampToValueAtTime(freq, ctx.currentTime + 0.3);

        // Sparse voicing = some oscillators silent
        if (aiVoicing === 'sparse' && i > 1) {
            p.g.gain.linearRampToValueAtTime(0, ctx.currentTime + 0.2);
        } else if (aiVoicing === 'shell' && i === 3) {
            p.g.gain.linearRampToValueAtTime(0, ctx.currentTime + 0.2);
        } else {
            p.g.gain.linearRampToValueAtTime(0.1 / (i + 1), ctx.currentTime + 0.2);
        }
    });

    // CORE MAGIC: Stillness = pad swells, modified by AI volume
    const still = 1 - Math.min(1, field.energy * 5);
    const padVol = still * aiVolume * music.intensity;
    padG.gain.linearRampToValueAtTime(padVol, ctx.currentTime + 0.2);

    // Filter affected by voicing type
    let filtBase = 1000 + still * 1800 + field.energy * 600;
    if (aiVoicing === 'rich') filtBase *= 1.3; // Brighter for rich voicing
    if (aiVoicing === 'sparse') filtBase *= 0.7; // Darker for sparse
    if (aiVoicing === 'out') filtBase *= 1.1; // Slightly brighter for tension
    padF.frequency.linearRampToValueAtTime(filtBase, ctx.currentTime + 0.1);
}

// ============ TEXTURE ============

let textureSrc, textureG;

function initTexture() {
    const len = ctx.sampleRate * 6;
    const buf = ctx.createBuffer(2, len, ctx.sampleRate);
    for (let ch = 0; ch < 2; ch++) {
        const d = buf.getChannelData(ch);
        for (let i = 0; i < len; i++) {
            const crackle = Math.random() < 0.0006 ? (Math.random() - 0.5) * 0.35 : 0;
            d[i] = crackle + (Math.random() * 2 - 1) * 0.012;
        }
    }
    textureSrc = ctx.createBufferSource();
    textureSrc.buffer = buf;
    textureSrc.loop = true;

    const f = ctx.createBiquadFilter();
    f.type = 'bandpass';
    f.frequency.value = 2800;
    f.Q.value = 0.35;

    textureG = ctx.createGain();
    textureG.gain.value = 0;

    textureSrc.connect(f).connect(textureG).connect(masterBus);
    textureSrc.start();
}

// ============ MELODY LAYERS - DISCOVERY ============

let melodies = [];

// Store last melody note for development
let lastMelodyNote = 0;
let melodyMotif = [0, 3, 5]; // Current motif being developed

function createMelody() {
    if (melodies.length >= 4) {
        const old = melodies.shift();
        old.o.stop();
    }

    const genre = dial.pulse === '0' ? 'dust' : dial.pulse;
    const chord = (CHORDS[genre] || CHORDS.dust)[music.bar % 4];

    // AI INFLUENCE: Lead behavior from bandState
    const aiActive = bandState.lead.active;
    const aiDeveloping = bandState.lead.developing;
    const aiRegister = bandState.lead.register;

    // If not active, don't create melody
    if (!aiActive && Math.random() > 0.3) return;

    let note;
    if (aiDeveloping && melodyMotif.length > 0) {
        // JAZZ DEVELOPMENT: Transform the motif
        const motifIndex = melodies.length % melodyMotif.length;
        const motifNote = melodyMotif[motifIndex];

        // Transformation options: transpose, invert, retrograde
        const transforms = [
            motifNote,                    // Original
            motifNote + 2,                // Step up
            motifNote - 2,                // Step down
            12 - motifNote,               // Invert
            lastMelodyNote + (motifNote - lastMelodyNote) // Sequence
        ];
        note = transforms[Math.floor(Math.random() * transforms.length)];

        // Sometimes introduce new motif element
        if (Math.random() < 0.2) {
            melodyMotif.push(note % 12);
            if (melodyMotif.length > 5) melodyMotif.shift();
        }
    } else {
        // Standard chord tone selection
        note = chord[Math.floor(Math.random() * chord.length)];

        // Sometimes start a new motif
        if (Math.random() < 0.15) {
            melodyMotif = [note, note + 2, note + 4].map(n => n % 12);
            logMusicalEvent('lead', 'new motif');
        }
    }

    // AI register affects octave
    let base = 220 * Math.pow(2, (1 - field.y) * 0.7);
    if (aiRegister === 'high') base *= 2;
    if (aiRegister === 'low') base *= 0.5;

    const freq = base * Math.pow(2, note / 12);
    lastMelodyNote = note;

    const o = ctx.createOscillator();
    const g = ctx.createGain();
    const f = ctx.createBiquadFilter();

    // More variety in timbre
    const timbres = ['sine', 'triangle', 'sine', 'triangle'];
    o.type = timbres[melodies.length % timbres.length];
    o.frequency.value = freq;
    f.type = 'lowpass';

    // Filter brighter when developing, softer when spacing
    f.frequency.value = aiDeveloping ? 2200 : 1400;

    // Volume louder when AI is active
    const baseVol = aiActive ? 0.06 : 0.04;
    const vol = baseVol * Math.pow(0.65, melodies.length);
    g.gain.value = vol;

    o.connect(f).connect(g).connect(padBus);
    o.start();

    // Longer notes when spacing, shorter when developing
    const len = aiDeveloping ? 1.2 + Math.random() * 1.0 : 2.0 + Math.random() * 2.0;
    melodies.push({ o, g, f, freq, vol, phase: 0, len });
}

function updateMelodies(dt) {
    for (const m of melodies) {
        m.phase += dt / m.len;
        if (m.phase >= 1) m.phase -= 1;
        const env = 0.5 + 0.5 * Math.cos(m.phase * TAU);
        m.g.gain.value = m.vol * env;
    }
}

// ORB - motion creates melody
let orb = { on: false, x: 0.5, y: 0.5 };

function updateOrb(dt) {
    if (!orb.on && field.energy > 0.035) {
        orb.on = true;
        orb.x = field.x;
        orb.y = field.y;
    }
    if (orb.on) {
        const dx = 0.5 - orb.x, dy = 0.5 - orb.y;
        const d = Math.sqrt(dx * dx + dy * dy);
        if (d > 0.025) {
            const speed = 0.4 + field.energy * 0.3;
            orb.x += (dx / d) * speed * dt;
            orb.y += (dy / d) * speed * dt;
        } else {
            createMelody();
            orb.on = false;
        }
        if (field.energy < 0.008) orb.on = false;
    }
}

// ============ HAZE ============

const HAZE = {
    clear: { filt: 20000, verb: 0.1, dly: 0.06, tex: 0 },
    fog: { filt: 3200, verb: 0.28, dly: 0.18, tex: 0.1 },
    glass: { filt: 15000, verb: 0.18, dly: 0.1, tex: 0.02 },
    heat: { filt: 7500, verb: 0.14, dly: 0.22, tex: 0.05 }
};

function updateHaze() {
    const h = HAZE[dial.haze] || HAZE.fog;
    lofiFilter.frequency.linearRampToValueAtTime(h.filt, ctx.currentTime + 0.15);
    verbWet.gain.linearRampToValueAtTime(h.verb, ctx.currentTime + 0.15);
    dlyWet.gain.linearRampToValueAtTime(h.dly, ctx.currentTime + 0.15);
    textureG.gain.linearRampToValueAtTime(h.tex, ctx.currentTime + 0.15);
}

// ============ INPUT ============

function onMove(nx, ny) {
    const dx = nx - field.x, dy = ny - field.y;
    field.x += dx * 0.2;
    field.y += dy * 0.2;
    field.energy = field.energy * 0.85 + Math.sqrt(dx * dx + dy * dy) * 2.5;
    field.peak = Math.max(field.peak * 0.98, field.energy);
}

function onMotion(e) {
    const a = e.accelerationIncludingGravity;
    if (!a) return;
    const ax = (a.x || 0) / 9, ay = (a.y || 0) / 9;
    field.x = Math.max(0, Math.min(1, field.x + ax * 0.06));
    field.y = Math.max(0, Math.min(1, field.y - ay * 0.06));
    field.energy = field.energy * 0.85 + Math.sqrt(ax * ax + ay * ay) * 0.6;
    field.peak = Math.max(field.peak * 0.98, field.energy);
}

function onOrientation(e) {
    const gx = (e.gamma || 0) / 40, gy = (e.beta || 0) / 40 - 0.5;
    onMove((gx + 1) / 2, (1 - gy) / 2);
}

// ============ DIALS ============

function initDials() {
    document.querySelectorAll('.dial').forEach(d => {
        const name = d.dataset.dial;
        d.querySelectorAll('.dial-opt').forEach(opt => {
            opt.addEventListener('click', e => {
                e.stopPropagation();
                d.querySelectorAll('.dial-opt').forEach(o => o.classList.remove('on'));
                opt.classList.add('on');
                dial[name] = opt.dataset.v;
                if (name === 'pulse') { step = 0; lastStep = ctx.currentTime; pattern = null; }
                if (name === 'haze') updateHaze();
            });
            opt.addEventListener('touchend', e => e.stopPropagation());
        });
    });
}

// ============ VISUALS ============

function resize() {
    const dpr = devicePixelRatio || 1;
    canvas.width = innerWidth * dpr;
    canvas.height = innerHeight * dpr;
    canvas.style.width = innerWidth + 'px';
    canvas.style.height = innerHeight + 'px';
    vc.setTransform(dpr, 0, 0, dpr, 0, 0);
}

function draw() {
    const w = innerWidth, h = innerHeight;

    // Subtle magenta-tinted fade
    vc.fillStyle = `rgba(5,5,8,${0.08 + music.intensity * 0.03})`;
    vc.fillRect(0, 0, w, h);

    // Center pulse - phi proportions
    const r = 21 + music.intensity * 13;
    vc.strokeStyle = `rgba(200,180,255,${0.03 + music.intensity * 0.04})`;
    vc.lineWidth = 1;
    vc.beginPath();
    vc.arc(w / 2, h / 2, r, 0, TAU);
    vc.stroke();

    // Melody rings
    melodies.forEach((m, i) => {
        const mr = 34 + i * 21;
        const a = 0.05 + (0.5 + 0.5 * Math.cos(m.phase * TAU)) * 0.1;
        vc.strokeStyle = `rgba(180,160,220,${a})`;
        vc.beginPath();
        vc.arc(w / 2, h / 2, mr, 0, TAU);
        vc.stroke();
    });

    // Orb
    if (orb.on) {
        vc.fillStyle = 'rgba(220,200,255,0.5)';
        vc.beginPath();
        vc.arc(orb.x * w, orb.y * h, 4, 0, TAU);
        vc.fill();
    }

    // Cursor
    vc.fillStyle = `rgba(200,180,255,${0.1 + field.energy * 0.4})`;
    vc.beginPath();
    vc.arc(field.x * w, field.y * h, 3 + field.energy * 10, 0, TAU);
    vc.fill();
}

// ============ JAZZ ORCHESTRA - AI MINDS ============

// Shared state - what all musicians can "hear"
const bandState = {
    // What's happening right now
    drums: { density: 0.5, lastFill: 0, energy: 0.5, pattern: 'steady' },
    bass: { register: 'mid', activity: 0.5, lastChange: 0, walking: false },
    pad: { voicing: 'close', volume: 0.4, moving: false },
    lead: { active: false, register: 'mid', motif: null, developing: false },

    // Conversation state
    lastSolo: null,
    tension: 0.5,
    direction: 'building', // building, releasing, floating
    barsInDirection: 0,

    // Recent events for context
    recentEvents: []
};

// Jazz conversation - when someone plays, others might respond
function logMusicalEvent(who, what) {
    bandState.recentEvents.push({ who, what, bar: music.bar, time: Date.now() });
    if (bandState.recentEvents.length > 12) bandState.recentEvents.shift();
}

// Agent personalities - different musical tendencies
const agentPersonality = {
    drums: { responsive: 0.7, leadTendency: 0.3, spaceLove: 0.4 },
    bass: { responsive: 0.8, leadTendency: 0.2, spaceLove: 0.3 },
    pad: { responsive: 0.5, leadTendency: 0.1, spaceLove: 0.7 },
    lead: { responsive: 0.6, leadTendency: 0.8, spaceLove: 0.5 }
};

// AI decision state
let aiEnabled = true;
let lastAICall = 0;
let aiCooldown = 4000; // ms between AI decisions
let pendingDecisions = {};

// Build context for AI decision
function buildMusicalContext() {
    const recent = bandState.recentEvents.slice(-6).map(e => `${e.who}: ${e.what}`).join('; ');
    return {
        energy: Math.round(music.intensity * 100),
        motion: Math.round(field.energy * 100),
        tension: Math.round(bandState.tension * 100),
        direction: bandState.direction,
        barsInDirection: bandState.barsInDirection,
        drums: bandState.drums.pattern,
        bass: bandState.bass.walking ? 'walking' : 'holding',
        pad: bandState.pad.voicing,
        lead: bandState.lead.active ? 'playing' : 'resting',
        recentActivity: recent || 'quiet start',
        bar: music.bar,
        phrase: music.phrase
    };
}

// THE JAZZ BRAIN - asks Kimi for musical decisions
async function askJazzMind(agent, context) {
    if (!window.puter?.ai) return null;

    const prompts = {
        drums: `You are a jazz drummer. Energy:${context.energy}%, tension:${context.tension}%, direction:${context.direction}.
Bass is ${context.bass}. Lead is ${context.lead}. Recent: ${context.recentActivity}.
What's your next move? Reply with ONLY one word from: steady, push, pull-back, fill, drop, accent`,

        bass: `You are a jazz bassist. Energy:${context.energy}%, tension:${context.tension}%, bar ${context.bar}.
Drums are ${context.drums}. Lead is ${context.lead}. Recent: ${context.recentActivity}.
What's your next move? Reply with ONLY one word from: root, walk, climb, descend, pedal, rest`,

        pad: `You are a jazz pianist comping. Energy:${context.energy}%, tension:${context.tension}%.
Drums: ${context.drums}. Bass: ${context.bass}. Recent: ${context.recentActivity}.
What voicing? Reply with ONLY one word from: close, spread, shell, rich, sparse, out`,

        lead: `You are a jazz soloist. Energy:${context.energy}%, motion:${context.motion}%, tension:${context.tension}%.
Direction: ${context.direction} for ${context.barsInDirection} bars. Recent: ${context.recentActivity}.
What's your move? Reply with ONLY one word from: develop, contrast, space, peak, echo, rest`
    };

    try {
        const response = await puter.ai.chat(prompts[agent], {
            model: 'moonshotai/kimi-k2.5',
            max_tokens: 10
        });
        const decision = (response?.toString() || '').trim().toLowerCase().split(/\s/)[0];
        console.log(`[${agent}] AI: ${decision}`);
        return decision;
    } catch (e) {
        console.log(`[${agent}] AI error:`, e.message);
        return null;
    }
}

// Apply drum decisions
function applyDrumDecision(decision) {
    const prev = bandState.drums.pattern;
    switch (decision) {
        case 'push':
            bandState.drums.density = Math.min(1, bandState.drums.density + 0.2);
            bandState.drums.energy = Math.min(1, bandState.drums.energy + 0.15);
            bandState.drums.pattern = 'pushing';
            if (prev !== 'pushing') logMusicalEvent('drums', 'pushing forward');
            break;
        case 'pull-back':
            bandState.drums.density = Math.max(0.2, bandState.drums.density - 0.25);
            bandState.drums.energy = Math.max(0.2, bandState.drums.energy - 0.2);
            bandState.drums.pattern = 'sparse';
            if (prev !== 'sparse') logMusicalEvent('drums', 'pulling back');
            break;
        case 'fill':
            bandState.drums.lastFill = music.bar;
            bandState.drums.pattern = 'fill';
            logMusicalEvent('drums', 'fill!');
            // Fill affects next pattern generation
            break;
        case 'drop':
            bandState.drums.density = 0.15;
            bandState.drums.pattern = 'minimal';
            if (prev !== 'minimal') logMusicalEvent('drums', 'dropped out');
            break;
        case 'accent':
            bandState.drums.pattern = 'accenting';
            logMusicalEvent('drums', 'accent hit');
            break;
        default: // steady
            bandState.drums.pattern = 'steady';
            bandState.drums.density = 0.5 + music.intensity * 0.3;
    }
}

// Apply bass decisions
function applyBassDecision(decision) {
    switch (decision) {
        case 'walk':
            bandState.bass.walking = true;
            bandState.bass.activity = 0.8;
            logMusicalEvent('bass', 'started walking');
            break;
        case 'climb':
            bandState.bass.register = 'high';
            bandState.bass.activity = 0.7;
            logMusicalEvent('bass', 'climbing up');
            break;
        case 'descend':
            bandState.bass.register = 'low';
            bandState.bass.activity = 0.7;
            logMusicalEvent('bass', 'descending');
            break;
        case 'pedal':
            bandState.bass.walking = false;
            bandState.bass.activity = 0.3;
            bandState.bass.register = 'low';
            logMusicalEvent('bass', 'pedal tone');
            break;
        case 'rest':
            bandState.bass.activity = 0.1;
            logMusicalEvent('bass', 'resting');
            break;
        default: // root
            bandState.bass.walking = false;
            bandState.bass.activity = 0.5;
            bandState.bass.register = 'mid';
    }
}

// Apply pad decisions
function applyPadDecision(decision) {
    bandState.pad.voicing = decision || 'close';
    if (decision === 'sparse' || decision === 'shell') {
        bandState.pad.volume = 0.25;
    } else if (decision === 'rich' || decision === 'spread') {
        bandState.pad.volume = 0.55;
    } else if (decision === 'out') {
        bandState.pad.volume = 0.4;
        logMusicalEvent('pad', 'outside voicing');
    }
}

// Apply lead decisions
function applyLeadDecision(decision) {
    switch (decision) {
        case 'develop':
            bandState.lead.active = true;
            bandState.lead.developing = true;
            logMusicalEvent('lead', 'developing idea');
            break;
        case 'contrast':
            bandState.lead.active = true;
            bandState.lead.register = bandState.lead.register === 'high' ? 'low' : 'high';
            logMusicalEvent('lead', 'contrast - switched register');
            break;
        case 'space':
            bandState.lead.active = true;
            bandState.lead.developing = false;
            logMusicalEvent('lead', 'leaving space');
            break;
        case 'peak':
            bandState.lead.active = true;
            bandState.lead.register = 'high';
            bandState.tension = Math.min(1, bandState.tension + 0.2);
            logMusicalEvent('lead', 'PEAK moment!');
            break;
        case 'echo':
            bandState.lead.active = true;
            logMusicalEvent('lead', 'echoing previous');
            break;
        default: // rest
            bandState.lead.active = false;
            bandState.lead.developing = false;
    }
}

// Orchestra conductor - coordinates all minds
async function updateOrchestra() {
    const now = Date.now();
    if (now - lastAICall < aiCooldown) return;
    if (!aiEnabled) return;

    lastAICall = now;
    const context = buildMusicalContext();

    // Update direction based on recent tension
    bandState.barsInDirection++;
    if (bandState.barsInDirection > 8) {
        // Natural jazz arc - change direction
        if (bandState.direction === 'building' && bandState.tension > 0.7) {
            bandState.direction = 'releasing';
            bandState.barsInDirection = 0;
        } else if (bandState.direction === 'releasing' && bandState.tension < 0.3) {
            bandState.direction = 'floating';
            bandState.barsInDirection = 0;
        } else if (bandState.direction === 'floating') {
            bandState.direction = 'building';
            bandState.barsInDirection = 0;
        }
    }

    // Stagger AI calls to avoid overwhelming
    // Each agent decides every ~4 bars but offset from each other
    const agents = ['drums', 'bass', 'pad', 'lead'];
    const agentIndex = music.bar % 4;
    const agent = agents[agentIndex];

    const decision = await askJazzMind(agent, context);
    if (decision) {
        switch (agent) {
            case 'drums': applyDrumDecision(decision); break;
            case 'bass': applyBassDecision(decision); break;
            case 'pad': applyPadDecision(decision); break;
            case 'lead': applyLeadDecision(decision); break;
        }
    }

    // Tension evolves with the direction
    if (bandState.direction === 'building') {
        bandState.tension = Math.min(1, bandState.tension + 0.03 + field.energy * 0.05);
    } else if (bandState.direction === 'releasing') {
        bandState.tension = Math.max(0, bandState.tension - 0.04);
    } else {
        // Floating - gentle oscillation
        bandState.tension += (Math.random() - 0.5) * 0.06;
        bandState.tension = Math.max(0.2, Math.min(0.8, bandState.tension));
    }
}

// Update visual status display
function updateBandStatus() {
    const drums = document.getElementById('st-drums');
    const bass = document.getElementById('st-bass');
    const pad = document.getElementById('st-pad');
    const lead = document.getElementById('st-lead');
    const dir = document.getElementById('st-direction');

    if (drums) {
        drums.textContent = `drums: ${bandState.drums.pattern}`;
        drums.classList.toggle('active', bandState.drums.pattern !== 'steady');
    }
    if (bass) {
        const bassStatus = bandState.bass.walking ? 'walking' : bandState.bass.register;
        bass.textContent = `bass: ${bassStatus}`;
        bass.classList.toggle('active', bandState.bass.walking || bandState.bass.register !== 'mid');
    }
    if (pad) {
        pad.textContent = `pad: ${bandState.pad.voicing}`;
        pad.classList.toggle('active', bandState.pad.voicing !== 'close');
    }
    if (lead) {
        const leadStatus = bandState.lead.developing ? 'developing' : (bandState.lead.active ? 'playing' : 'rest');
        lead.textContent = `lead: ${leadStatus}`;
        lead.classList.toggle('active', bandState.lead.active);
    }
    if (dir) {
        const dirSymbol = { building: '/', releasing: '\\', floating: '~' }[bandState.direction] || '~';
        dir.textContent = dirSymbol + ' ' + Math.round(bandState.tension * 100) + '%';
    }
}

// Wire band state back to audio parameters
function applyBandToAudio() {
    // Update visual display
    updateBandStatus();
    // Drums - density affects ghost notes and hat probability
    if (pattern) {
        // Will be picked up on next pattern generation
    }

    // Bass - register affects frequency multiplier
    const bassRegisterMult = {
        low: 0.5,
        mid: 1,
        high: 2
    }[bandState.bass.register] || 1;

    // Bass - walking creates more movement
    if (bandState.bass.walking && Math.random() < 0.3) {
        bassSeq[music.bar % 4] = [0, 2, 3, 5, 7, -5][Math.floor(Math.random() * 6)];
    }

    // Pad - voicing affects oscillator spread
    const voicingOffsets = {
        close: [0, 3, 7, 10],
        spread: [0, 7, 12, 19],
        shell: [0, 7, 10, 0], // Root, 5th, 7th only
        rich: [0, 4, 7, 11, 14],
        sparse: [0, 7, 0, 0],
        out: [0, 6, 10, 15] // Tritone tension
    };

    // Lead - active state affects melody creation rate
    if (bandState.lead.active && !bandState.lead.developing && Math.random() < 0.15) {
        createMelody();
    } else if (bandState.lead.developing && Math.random() < 0.3) {
        createMelody();
    }

    // Global - tension affects master intensity
    music.intensity = music.intensity * 0.9 + bandState.tension * 0.1;
}

// ============ LOOP ============

function tick() {
    if (!running) return;
    const dt = 1 / 60;
    field.time += dt;
    field.energy *= 0.96;

    // Jazz Orchestra makes decisions
    updateOrchestra();
    applyBandToAudio();

    updateBeats();
    updateBass();
    updatePad();
    updateOrb(dt);
    updateMelodies(dt);

    draw();
    requestAnimationFrame(tick);
}

// ============ INIT ============

async function init() {
    ctx = new (window.AudioContext || window.webkitAudioContext)();
    initFX();
    initBass();
    initPad();
    initTexture();
    initDials();

    canvas = document.getElementById('c');
    vc = canvas.getContext('2d');
    resize();
    addEventListener('resize', resize);

    document.getElementById('loading').classList.remove('off');
    await loadSamples();
    document.getElementById('loading').classList.add('off');
    document.getElementById('dials').style.display = 'block';
    document.getElementById('band-status').style.display = 'block';

    updateHaze();

    // Check if Puter.js loaded
    if (window.puter?.ai) {
        console.log('[GUMP] Kimi K2 AI ready - Jazz Orchestra enabled');
    } else {
        console.log('[GUMP] AI not available - using generative patterns');
        aiEnabled = false;
    }
}

async function start() {
    document.getElementById('enter').classList.add('off');

    if (typeof DeviceMotionEvent?.requestPermission === 'function') {
        try { await DeviceMotionEvent.requestPermission(); } catch (e) {}
    }
    if (typeof DeviceOrientationEvent?.requestPermission === 'function') {
        try { await DeviceOrientationEvent.requestPermission(); } catch (e) {}
    }

    await init();

    addEventListener('devicemotion', onMotion);
    addEventListener('deviceorientation', onOrientation);
    canvas.addEventListener('mousemove', e => onMove(e.clientX / innerWidth, e.clientY / innerHeight));
    canvas.addEventListener('touchmove', e => { e.preventDefault(); onMove(e.touches[0].clientX / innerWidth, e.touches[0].clientY / innerHeight); }, { passive: false });
    canvas.addEventListener('touchstart', e => { e.preventDefault(); onMove(e.touches[0].clientX / innerWidth, e.touches[0].clientY / innerHeight); }, { passive: false });

    if (ctx.state === 'suspended') await ctx.resume();

    running = true;
    tick();
}

document.getElementById('enter').addEventListener('click', start);
</script>
</body>
</html>
