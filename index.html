<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="mobile-web-app-status-bar-style" content="black-translucent">
<title>NEUROMANCER - Breakthrough Edition</title>
<style>
* {
  margin: 0;
  padding: 0;
  box-sizing: border-box;
  -webkit-tap-highlight-color: transparent;
  -webkit-user-select: none;
  user-select: none;
  overscroll-behavior: none;
}
:root {
  --quantum-blue: #00ffff;
  --neural-purple: #ff00ff;
  --plasma-green: #00ff00;
  --void-black: #000000;
  --ghost-white: rgba(255,255,255,0.03);
  --electric-red: #ff0040;
  --gold: #ffd700;
  --safe-area-top: env(safe-area-inset-top);
  --safe-area-bottom: env(safe-area-inset-bottom);
  --primary-color: #00ffff;
}
body {
  background: var(--void-black);
  color: #fff;
  overflow: hidden;
  height: 100vh;
  height: 100dvh;
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
  position: fixed;
  width: 100%;
  touch-action: none;
}
/* Quantum Field Background */
#quantumField {
  position: fixed;
  inset: 0;
  pointer-events: none;
  transition: all 3s cubic-bezier(0.4, 0, 0.2, 1);
}
.quantum-layer {
  position: absolute;
  inset: 0;
  opacity: 0.3;
}
.quantum-layer:nth-child(1) {
  background: radial-gradient(ellipse at 25% 25%,
    rgba(0, 255, 255, 0.1) 0%,
    transparent 50%);
  animation: rotate-slow 30s linear infinite;
}
.quantum-layer:nth-child(2) {
  background: radial-gradient(ellipse at 75% 75%,
    rgba(255, 0, 255, 0.08) 0%,
    transparent 50%);
  animation: rotate-slow 40s linear infinite reverse;
}
.quantum-layer:nth-child(3) {
  background: radial-gradient(circle at center,
    transparent 0%,
    rgba(0, 255, 0, 0.03) 40%,
    transparent 70%);
  animation: pulse-slow 8s ease-in-out infinite;
}
/* Enhanced visual states */
.state-void { filter: hue-rotate(0deg) brightness(0.7); }
.state-ambient { filter: hue-rotate(120deg) brightness(1.1); }
.state-rhythmic { filter: hue-rotate(240deg) brightness(1.3); }
.state-elevated { filter: hue-rotate(60deg) brightness(1.5) saturate(1.5); }
.state-chaos {
  filter: hue-rotate(300deg) brightness(1.8) saturate(2) contrast(1.5);
  animation: chaos-glitch 0.2s infinite;
}
@keyframes chaos-glitch {
  0%, 100% { filter: hue-rotate(300deg) brightness(1.8) saturate(2) contrast(1.5); }
  50% { filter: hue-rotate(0deg) brightness(2) saturate(3) contrast(2); }
}
@keyframes rotate-slow {
  to { transform: rotate(360deg); }
}
@keyframes pulse-slow {
  0%, 100% { transform: scale(1); opacity: 0.3; }
  50% { transform: scale(1.2); opacity: 0.6; }
}
/* Canvas layers */
#particleCanvas, #spatialCanvas, #waveformCanvas {
  position: fixed;
  pointer-events: none;
}
#particleCanvas {
  inset: 0;
  opacity: 0.8;
  mix-blend-mode: screen;
}
#spatialCanvas {
  inset: 0;
  opacity: 0.7;
  mix-blend-mode: color-dodge;
}
#waveformCanvas {
  top: calc(var(--safe-area-top) + 80px);
  left: 10px;
  right: 10px;
  height: 60px;
  opacity: 0.6;
  filter: drop-shadow(0 0 10px var(--quantum-blue));
}
/* Enhanced HUD */
.hud-top {
  position: fixed;
  top: var(--safe-area-top);
  left: 0;
  right: 0;
  padding: 15px;
  background: linear-gradient(to bottom,
    rgba(0, 0, 0, 0.8),
    transparent);
  display: flex;
  justify-content: space-between;
  align-items: flex-start;
  z-index: 100;
}
.state-display {
  display: flex;
  flex-direction: column;
  gap: 5px;
}
.current-state {
  font-size: 18px;
  letter-spacing: 4px;
  font-weight: 100;
  color: var(--primary-color);
  text-shadow: 0 0 20px currentColor;
  transition: all 0.5s ease;
}
.state-subtitle {
  font-size: 9px;
  opacity: 0.5;
  letter-spacing: 2px;
}
.metrics-display {
  display: flex;
  flex-direction: column;
  gap: 3px;
  text-align: right;
  font-size: 9px;
  font-family: monospace;
  opacity: 0.6;
}
.metric {
  display: flex;
  gap: 10px;
  justify-content: flex-end;
}
.metric-value {
  color: var(--plasma-green);
  min-width: 40px;
}
/* Enhanced energy display */
.energy-container {
  position: fixed;
  left: 15px;
  top: 50%;
  transform: translateY(-50%);
  width: 4px;
  height: 200px;
  background: rgba(255, 255, 255, 0.05);
  border-radius: 2px;
  overflow: hidden;
}
.energy-bar {
  position: absolute;
  bottom: 0;
  width: 100%;
  background: linear-gradient(to top,
    var(--plasma-green),
    var(--quantum-blue),
    var(--neural-purple));
  transition: height 0.2s ease;
  box-shadow: 0 0 20px currentColor;
}
/* Enhanced motion orb */
.motion-orb {
  position: fixed;
  right: 15px;
  top: 50%;
  transform: translateY(-50%);
  width: 60px;
  height: 60px;
  border-radius: 50%;
  border: 1px solid rgba(255, 255, 255, 0.2);
  display: flex;
  align-items: center;
  justify-content: center;
  background: radial-gradient(circle at center,
    rgba(0, 255, 255, 0.1),
    transparent);
}
.motion-core {
  width: 20px;
  height: 20px;
  border-radius: 50%;
  background: var(--quantum-blue);
  transition: all 0.1s ease;
  box-shadow: 0 0 20px currentColor;
}
/* Enhanced sample matrix */
.sample-matrix {
  position: fixed;
  top: 50%;
  left: 50%;
  transform: translate(-50%, -50%);
  display: grid;
  grid-template-columns: repeat(3, 1fr);
  grid-template-rows: repeat(3, 1fr);
  gap: 20px;
  padding: 20px;
}
.sample-node {
  width: 60px;
  height: 60px;
  border-radius: 50%;
  border: 1px solid rgba(255, 255, 255, 0.1);
  position: relative;
  transition: all 0.3s ease;
  cursor: pointer;
  background: radial-gradient(circle at 30% 30%,
    rgba(0, 0, 0, 0.5),
    rgba(0, 0, 0, 0.8));
}
.sample-node.recording {
  animation: record-pulse 1s ease-in-out infinite;
  border-color: var(--electric-red);
  background: radial-gradient(circle at center,
    rgba(255, 0, 64, 0.2),
    transparent);
}
.sample-node.loaded {
  border-color: var(--plasma-green);
  background: radial-gradient(circle at center,
    rgba(0, 255, 0, 0.1),
    transparent);
}
.sample-node.playing {
  animation: play-burst 0.3s ease;
  border-color: var(--quantum-blue);
  box-shadow: 0 0 30px var(--quantum-blue),
              inset 0 0 20px var(--quantum-blue);
}
.sample-node.processing {
  animation: process-spin 1s linear infinite;
  border-color: var(--gold);
}
@keyframes record-pulse {
  0%, 100% { transform: scale(1); box-shadow: 0 0 0 0 var(--electric-red); }
  50% { transform: scale(1.1); box-shadow: 0 0 20px 5px var(--electric-red); }
}
@keyframes play-burst {
  0% { transform: scale(1); }
  50% { transform: scale(1.3); }
  100% { transform: scale(1); }
}
@keyframes process-spin {
  to { transform: rotate(360deg); }
}
.sample-visual {
  position: absolute;
  inset: 5px;
  border-radius: 50%;
  overflow: hidden;
}
.sample-canvas {
  width: 100%;
  height: 100%;
}
.sample-number {
  position: absolute;
  top: 50%;
  left: 50%;
  transform: translate(-50%, -50%);
  font-size: 10px;
  opacity: 0.3;
  pointer-events: none;
}
/* Neural network */
.neural-network {
  position: fixed;
  bottom: calc(var(--safe-area-bottom) + 120px);
  left: 50%;
  transform: translateX(-50%);
  width: 250px;
  height: 80px;
  display: flex;
  align-items: center;
  justify-content: center;
  opacity: 0.4;
}
.neural-node {
  width: 8px;
  height: 8px;
  background: var(--quantum-blue);
  border-radius: 50%;
  position: absolute;
  opacity: 0.3;
  transition: all 0.2s ease;
}
.neural-connection {
  position: absolute;
  height: 1px;
  background: linear-gradient(90deg,
    transparent,
    var(--quantum-blue),
    transparent);
  transform-origin: left center;
  opacity: 0.2;
}
/* Journey timeline */
.journey-container {
  position: fixed;
  bottom: calc(var(--safe-area-bottom) + 100px);
  left: 30px;
  right: 30px;
}
.journey-info {
  display: flex;
  justify-content: space-between;
  margin-bottom: 5px;
  font-size: 9px;
  opacity: 0.5;
}
.journey-timeline {
  height: 3px;
  background: rgba(255, 255, 255, 0.1);
  border-radius: 2px;
  position: relative;
  overflow: hidden;
}
.journey-progress {
  height: 100%;
  width: 0%;
  background: linear-gradient(90deg,
    var(--plasma-green),
    var(--quantum-blue),
    var(--neural-purple),
    var(--electric-red));
  transition: width 1s linear;
  box-shadow: 0 0 10px currentColor;
}
.journey-markers {
  position: absolute;
  inset: 0;
  display: flex;
}
.journey-marker {
  flex: 1;
  border-right: 1px solid rgba(255, 255, 255, 0.2);
}
/* Enhanced control panel */
.control-panel {
  position: fixed;
  bottom: var(--safe-area-bottom);
  left: 0;
  right: 0;
  height: 90px;
  background: linear-gradient(to top,
    rgba(0, 0, 0, 0.9),
    rgba(0, 0, 0, 0.5),
    transparent);
  display: flex;
  justify-content: space-around;
  align-items: center;
  padding: 0 20px;
  z-index: 100;
}
.control-group {
  display: flex;
  gap: 15px;
}
.control-btn {
  width: 45px;
  height: 45px;
  border-radius: 50%;
  border: 1px solid rgba(255, 255, 255, 0.2);
  background: rgba(0, 0, 0, 0.6);
  display: flex;
  align-items: center;
  justify-content: center;
  font-size: 8px;
  letter-spacing: 1px;
  transition: all 0.3s ease;
  cursor: pointer;
  position: relative;
  backdrop-filter: blur(10px);
}
.control-btn:hover {
  border-color: var(--quantum-blue);
  background: rgba(0, 255, 255, 0.05);
}
.control-btn.active {
  border-color: var(--quantum-blue);
  background: rgba(0, 255, 255, 0.1);
  box-shadow: 0 0 20px var(--quantum-blue),
              inset 0 0 10px var(--quantum-blue);
}
.control-btn.main {
  width: 60px;
  height: 60px;
  border-width: 2px;
  font-size: 10px;
}
.control-btn.recording {
  animation: record-glow 1s ease-in-out infinite;
  border-color: var(--electric-red);
  background: rgba(255, 0, 64, 0.2);
}
@keyframes record-glow {
  0%, 100% { box-shadow: 0 0 10px var(--electric-red); }
  50% { box-shadow: 0 0 30px var(--electric-red), 0 0 50px var(--electric-red); }
}
/* Effects */
.effects-row {
  position: fixed;
  bottom: calc(var(--safe-area-bottom) + 95px);
  left: 50%;
  transform: translateX(-50%);
  display: flex;
  gap: 10px;
}
.effect-indicator {
  width: 30px;
  height: 4px;
  background: rgba(255, 255, 255, 0.1);
  border-radius: 2px;
  transition: all 0.3s ease;
}
.effect-indicator.active {
  background: var(--quantum-blue);
  box-shadow: 0 0 10px var(--quantum-blue);
}
/* Permission overlay */
.permission-overlay {
  position: fixed;
  inset: 0;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  background: radial-gradient(circle at center,
    rgba(0, 0, 0, 0.95),
    var(--void-black));
  z-index: 10000;
  gap: 30px;
  padding: 40px;
  text-align: center;
}
.permission-overlay.hidden {
  display: none;
}
.logo-container {
  position: relative;
  width: 150px;
  height: 150px;
}
.logo-ring {
  position: absolute;
  inset: 0;
  border: 1px solid var(--quantum-blue);
  border-radius: 50%;
  opacity: 0.3;
  animation: expand-ring 3s ease-in-out infinite;
}
.logo-ring:nth-child(2) {
  animation-delay: 1s;
}
.logo-ring:nth-child(3) {
  animation-delay: 2s;
}
@keyframes expand-ring {
  0% { transform: scale(0.8); opacity: 0; }
  50% { opacity: 0.5; }
  100% { transform: scale(1.5); opacity: 0; }
}
.logo-core {
  position: absolute;
  inset: 30%;
  background: radial-gradient(circle at center,
    var(--quantum-blue),
    transparent);
  border-radius: 50%;
  animation: pulse-core 2s ease-in-out infinite;
}
@keyframes pulse-core {
  0%, 100% { transform: scale(1); opacity: 0.8; }
  50% { transform: scale(1.1); opacity: 1; }
}
.permission-title {
  font-size: 24px;
  letter-spacing: 8px;
  font-weight: 100;
  color: var(--quantum-blue);
  margin-left: 8px;
}
.permission-subtitle {
  font-size: 10px;
  letter-spacing: 3px;
  opacity: 0.5;
  margin-top: -20px;
}
.permission-text {
  font-size: 12px;
  line-height: 1.8;
  opacity: 0.7;
  max-width: 280px;
}
.permission-btn {
  padding: 15px 40px;
  border: 1px solid var(--quantum-blue);
  background: transparent;
  color: var(--quantum-blue);
  border-radius: 30px;
  font-size: 11px;
  letter-spacing: 3px;
  cursor: pointer;
  transition: all 0.3s ease;
  position: relative;
  overflow: hidden;
}
.permission-btn:before {
  content: '';
  position: absolute;
  inset: 0;
  background: radial-gradient(circle at center,
    var(--quantum-blue),
    transparent);
  opacity: 0;
  transition: opacity 0.3s ease;
}
.permission-btn:hover:before {
  opacity: 0.1;
}
.permission-btn:active {
  transform: scale(0.98);
}
/* Notification system */
.notification {
  position: fixed;
  top: calc(var(--safe-area-top) + 150px);
  left: 50%;
  transform: translateX(-50%);
  padding: 10px 20px;
  background: rgba(0, 0, 0, 0.9);
  border: 1px solid var(--quantum-blue);
  border-radius: 20px;
  font-size: 11px;
  letter-spacing: 2px;
  opacity: 0;
  pointer-events: none;
  transition: opacity 0.3s ease;
  z-index: 1000;
  text-align: center;
  backdrop-filter: blur(10px);
}
.notification.visible {
  opacity: 0.9;
}
/* Touch ripples */
.touch-ripple {
  position: fixed;
  width: 40px;
  height: 40px;
  border-radius: 50%;
  border: 1px solid var(--quantum-blue);
  pointer-events: none;
  animation: ripple-out 0.6s ease-out;
  z-index: 9999;
}
@keyframes ripple-out {
  to {
    width: 100px;
    height: 100px;
    opacity: 0;
    margin-left: -30px;
    margin-top: -30px;
  }
}
/* Debug panel */
.debug-panel {
  position: fixed;
  top: calc(var(--safe-area-top) + 10px);
  right: 10px;
  background: rgba(0, 0, 0, 0.8);
  padding: 10px;
  border-radius: 5px;
  font-family: monospace;
  font-size: 8px;
  display: none;
  z-index: 10000;
  backdrop-filter: blur(10px);
}
.debug-panel.visible {
  display: block;
}
/* Error display */
.error-display {
  position: fixed;
  bottom: 50px;
  left: 50%;
  transform: translateX(-50%);
  background: rgba(255, 0, 0, 0.1);
  border: 1px solid var(--electric-red);
  padding: 10px;
  border-radius: 5px;
  font-size: 10px;
  opacity: 0;
  transition: opacity 0.3s ease;
  z-index: 1001;
}
.error-display.visible {
  opacity: 0.9;
}
/* Responsive adjustments */
@media (max-height: 600px) {
  .sample-matrix { gap: 15px; }
  .sample-node { width: 50px; height: 50px; }
  .control-panel { height: 70px; }
  .control-btn { width: 40px; height: 40px; }
  .control-btn.main { width: 50px; height: 50px; }
}
@media (min-width: 768px) {
  .sample-matrix { gap: 30px; }
  .sample-node { width: 80px; height: 80px; }
}
/* Performance mode */
.performance-mode .quantum-layer:nth-child(3) {
  display: none;
}
.performance-mode #particleCanvas {
  opacity: 0.5;
}
/* Spectrum analyzer */
.spectrum-analyzer {
  position: fixed;
  bottom: calc(var(--safe-area-bottom) + 200px);
  left: 50%;
  transform: translateX(-50%);
  width: 200px;
  height: 40px;
  display: flex;
  gap: 2px;
  align-items: flex-end;
  opacity: 0.4;
}
.spectrum-bar {
  flex: 1;
  background: linear-gradient(to top, var(--plasma-green), var(--quantum-blue));
  transition: height 0.05s ease-out;
  min-height: 2px;
}
</style>
</head>
<body>
<!-- Quantum field background -->
<div id="quantumField">
  <div class="quantum-layer"></div>
  <div class="quantum-layer"></div>
  <div class="quantum-layer"></div>
</div>
<!-- Canvas layers -->
<canvas id="particleCanvas"></canvas>
<canvas id="spatialCanvas"></canvas>
<canvas id="waveformCanvas"></canvas>
<!-- HUD -->
<div class="hud-top">
  <div class="state-display">
    <div class="current-state" id="currentState">VOID</div>
    <div class="state-subtitle" id="stateSubtitle">awaiting motion</div>
  </div>
  <div class="metrics-display">
    <div class="metric">
      <span>BPM</span>
      <span class="metric-value" id="bpmValue">120</span>
    </div>
    <div class="metric">
      <span>ENERGY</span>
      <span class="metric-value" id="energyValue">0.00</span>
    </div>
    <div class="metric">
      <span>SAMPLES</span>
      <span class="metric-value" id="samplesValue">0/9</span>
    </div>
    <div class="metric">
      <span>PHASE</span>
      <span class="metric-value" id="phaseValue">1/5</span>
    </div>
  </div>
</div>
<!-- Energy bar -->
<div class="energy-container">
  <div class="energy-bar" id="energyBar"></div>
</div>
<!-- Motion orb -->
<div class="motion-orb">
  <div class="motion-core" id="motionCore"></div>
</div>
<!-- Sample matrix -->
<div class="sample-matrix" id="sampleMatrix">
  <div class="sample-node" data-slot="0">
    <div class="sample-visual"><canvas class="sample-canvas"></canvas></div>
    <span class="sample-number">1</span>
  </div>
  <div class="sample-node" data-slot="1">
    <div class="sample-visual"><canvas class="sample-canvas"></canvas></div>
    <span class="sample-number">2</span>
  </div>
  <div class="sample-node" data-slot="2">
    <div class="sample-visual"><canvas class="sample-canvas"></canvas></div>
    <span class="sample-number">3</span>
  </div>
  <div class="sample-node" data-slot="3">
    <div class="sample-visual"><canvas class="sample-canvas"></canvas></div>
    <span class="sample-number">4</span>
  </div>
  <div class="sample-node" data-slot="4">
    <div class="sample-visual"><canvas class="sample-canvas"></canvas></div>
    <span class="sample-number">5</span>
  </div>
  <div class="sample-node" data-slot="5">
    <div class="sample-visual"><canvas class="sample-canvas"></canvas></div>
    <span class="sample-number">6</span>
  </div>
  <div class="sample-node" data-slot="6">
    <div class="sample-visual"><canvas class="sample-canvas"></canvas></div>
    <span class="sample-number">7</span>
  </div>
  <div class="sample-node" data-slot="7">
    <div class="sample-visual"><canvas class="sample-canvas"></canvas></div>
    <span class="sample-number">8</span>
  </div>
  <div class="sample-node" data-slot="8">
    <div class="sample-visual"><canvas class="sample-canvas"></canvas></div>
    <span class="sample-number">9</span>
  </div>
</div>
<!-- Neural network -->
<div class="neural-network" id="neuralNetwork"></div>
<!-- Spectrum analyzer -->
<div class="spectrum-analyzer" id="spectrumAnalyzer">
  <div class="spectrum-bar"></div>
  <div class="spectrum-bar"></div>
  <div class="spectrum-bar"></div>
  <div class="spectrum-bar"></div>
  <div class="spectrum-bar"></div>
  <div class="spectrum-bar"></div>
  <div class="spectrum-bar"></div>
  <div class="spectrum-bar"></div>
  <div class="spectrum-bar"></div>
  <div class="spectrum-bar"></div>
</div>
<!-- Journey timeline -->
<div class="journey-container">
  <div class="journey-info">
    <span id="journeyTime">00:00</span>
    <span id="journeyPhase">INTRODUCTION</span>
    <span>25:00</span>
  </div>
  <div class="journey-timeline">
    <div class="journey-progress" id="journeyProgress"></div>
    <div class="journey-markers">
      <div class="journey-marker"></div>
      <div class="journey-marker"></div>
      <div class="journey-marker"></div>
      <div class="journey-marker"></div>
      <div class="journey-marker"></div>
    </div>
  </div>
</div>
<!-- Effects indicators -->
<div class="effects-row">
  <div class="effect-indicator" id="fxReverb"></div>
  <div class="effect-indicator" id="fxDelay"></div>
  <div class="effect-indicator" id="fxFilter"></div>
  <div class="effect-indicator" id="fxDistortion"></div>
  <div class="effect-indicator" id="fxChorus"></div>
</div>
<!-- Control panel -->
<div class="control-panel">
  <div class="control-group">
    <div class="control-btn" id="btnTap" data-action="tap">TAP</div>
    <div class="control-btn" id="btnLoop" data-action="loop">LOOP</div>
  </div>
  <div class="control-btn main" id="btnRecord" data-action="record">REC</div>
  <div class="control-group">
    <div class="control-btn" id="btnAI" data-action="ai">AI</div>
    <div class="control-btn" id="btnFX" data-action="fx">FX</div>
  </div>
</div>
<!-- Notification -->
<div class="notification" id="notification"></div>
<!-- Error display -->
<div class="error-display" id="errorDisplay"></div>
<!-- Permission overlay -->
<div class="permission-overlay" id="permissionOverlay">
  <div class="logo-container">
    <div class="logo-ring"></div>
    <div class="logo-ring"></div>
    <div class="logo-ring"></div>
    <div class="logo-core"></div>
  </div>
  <div>
    <div class="permission-title">NEUROMANCER</div>
    <div class="permission-subtitle">BREAKTHROUGH EDITION</div>
  </div>
  <div class="permission-text">
    Experience a 25-minute generative musical journey that responds to your movement and environment in real-time.
  
    This immersive audio-visual experience uses your microphone and motion sensors to create unique soundscapes.
  </div>
  <button class="permission-btn" id="startBtn">BEGIN JOURNEY</button>
</div>
<!-- Debug panel -->
<div class="debug-panel" id="debugPanel">
  <div>Motion: <span id="debugMotion">0.00</span></div>
  <div>Accel: <span id="debugAccel">0,0,0</span></div>
  <div>Orient: <span id="debugOrient">0,0,0</span></div>
  <div>Touch: <span id="debugTouch">none</span></div>
  <div>Audio: <span id="debugAudio">0</span></div>
  <div>State: <span id="debugState">init</span></div>
  <div>Perf: <span id="debugPerf">60fps</span></div>
  <div>Tempo: <span id="debugTempo">120</span></div>
  <div>Queue: <span id="debugQueue">0</span></div>
</div>
<script>
'use strict';
// ============================================
// NEUROMANCER BREAKTHROUGH ENGINE
// Complete rewrite with advanced features
// ============================================
class BreakthroughNeuromancerEngine {
  constructor() {
    // Advanced configuration with dynamic adaptation
    this.config = {
      sampleRate: 48000,
      baseBPM: 120,
      sampleDuration: 4000,
      maxSamples: 9,
      journeyDuration: 25 * 60 * 1000,
      autoSampleInterval: 8000,
      fftSize: 2048,
      scheduleAheadTime: 0.1,
      lookAheadTime: 25.0,
      maxParticles: 40,
      visualUpdateRate: 60,
      motionSmoothingFactor: 0.85,
      motionThreshold: 0.15,
      scaleNotes: [0, 2, 3, 5, 7, 8, 10, 12],
      rootNote: 220,
      // Advanced musical parameters
      harmonicSeries: [1, 1.5, 2, 2.5, 3, 4, 5, 6, 8],
      rhythmPatterns: {
        void: [],
        ambient: [1, 0, 0, 0, 0.5, 0, 0, 0],
        rhythmic: [1, 0, 0.5, 0, 1, 0, 0.5, 0],
        elevated: [1, 0.3, 0.7, 0.3, 1, 0.5, 0.7, 0.3],
        chaos: [1, Math.random(), Math.random(), Math.random(), 1, Math.random(), Math.random(), Math.random()]
      },
      chordProgressions: [
        [0, 3, 5], // I
        [5, 8, 10], // vi
        [3, 7, 10], // IV
        [2, 5, 8] // V
      ]
    };
  
    // Enhanced state management with prediction
    this.state = {
      isInitialized: false,
      hasAudioContext: false,
      hasMicrophone: false,
      hasMotionSensors: false,
      performanceMode: false,
      currentState: 'void',
      previousState: null,
      stateTransitionProgress: 0,
      journeyPhase: 0,
      journeyStartTime: null,
      journeyElapsed: 0,
      motionLevel: 0,
      smoothedMotion: 0,
      predictedMotion: 0,
      accelerometer: { x: 0, y: 0, z: 0 },
      orientation: { alpha: 0, beta: 0, gamma: 0 },
      touchPoints: new Map(),
      bpm: 120,
      targetBPM: 120,
      currentBar: 0,
      currentBeat: 0,
      nextNoteTime: 0,
      samples: new Map(),
      sampleSequences: new Map(),
      nextSampleSlot: 0,
      isRecording: false,
      currentRecordingSlot: null,
      activeEffects: new Set(['reverb']),
      aiDjActive: true,
      aiDjMode: 'adaptive',
      autoSampleCount: 0,
      energy: 0,
      targetEnergy: 0,
      complexity: 0.5,
      chaos: 0,
      harmonic: 0,
      frameRate: 60,
      lastFrameTime: 0,
      currentChord: 0,
      noteQueue: [],
      audioLatency: 0,
      isLooping: false,
      loopLength: 16,
      loopPosition: 0,
      lastTapTime: null
    };
  
    // Audio system components
    this.audioNodes = {};
    this.audioBuffers = {};
    this.scheduler = null;
    this.visualizers = {};
    this.recordBuffer = [];
    this.drumSounds = {};
  
    // Advanced data structures
    this.motionHistory = [];
    this.touchHistory = [];
    this.sampleAnalysis = [];
    this.beatGrid = new Array(16).fill(null);
    this.melodicSequence = [];
    this.harmonicField = [];
  
    // Visual systems
    this.particles = [];
    this.neuralNodes = [];
    this.spectrumBars = [];
  
    // Performance optimization
    this.performanceMonitor = {
      frameCount: 0,
      lastCheck: Date.now(),
      audioDropouts: 0,
      bufferUnderruns: 0
    };
  
    // Musical AI components
    this.musicalAI = {
      beatPrediction: [],
      melodicContext: [],
      harmonicTension: 0,
      rhythmicDensity: 0
    };
  
    this.init();
  }
  async init() {
    console.log('ðŸŒŒ Initializing Breakthrough NEUROMANCER Engine...');
  
    try {
      this.setupDOM();
      this.setupEventListeners();
      this.setupErrorHandling();
      this.setupPerformanceMonitoring();
      this.setupVisualSystems();
      this.initializeMusicalAI();
    
      // Preload synthetic drum samples
      this.generateSyntheticDrums();
    
      console.log('âœ… Breakthrough Engine initialized successfully');
    } catch (error) {
      this.handleError('Critical initialization failure', error);
    }
  }
  setupErrorHandling() {
    window.addEventListener('error', (e) => {
      this.handleError('Runtime error', e.error);
      e.preventDefault();
    });
  
    window.addEventListener('unhandledrejection', (e) => {
      this.handleError('Promise rejection', e.reason);
      e.preventDefault();
    });
  }
  handleError(message, error) {
    console.error(`âŒ ${message}:`, error);
  
    const errorDisplay = document.getElementById('errorDisplay');
    if (errorDisplay) {
      errorDisplay.textContent = `${message}: ${error?.message || error || 'Unknown error'}`;
      errorDisplay.classList.add('visible');
    
      setTimeout(() => {
        errorDisplay.classList.remove('visible');
      }, 5000);
    }
  
    // Attempt recovery for audio errors
    if (message.includes('audio') || message.includes('Audio')) {
      this.attemptAudioRecovery();
    }
  }
  attemptAudioRecovery() {
    console.log('ðŸ”§ Attempting audio recovery...');
  
    if (this.audioContext) {
      if (this.audioContext.state === 'suspended') {
        this.audioContext.resume().then(() => {
          console.log('âœ… Audio context resumed');
          this.showNotification('Audio recovered', 2000);
        }).catch(err => {
          console.error('Failed to resume audio:', err);
        });
      }
    }
  }
  setupPerformanceMonitoring() {
    // Advanced performance monitoring with adaptive quality
    setInterval(() => {
      const now = Date.now();
      const elapsed = now - this.performanceMonitor.lastCheck;
    
      if (elapsed >= 1000) {
        this.state.frameRate = Math.round((this.performanceMonitor.frameCount * 1000) / elapsed);
        this.performanceMonitor.frameCount = 0;
        this.performanceMonitor.lastCheck = now;
      
        // Update debug
        const perfElement = document.getElementById('debugPerf');
        if (perfElement) {
          perfElement.textContent = this.state.frameRate + 'fps';
        }
      
        // Adaptive quality adjustment
        if (this.state.frameRate < 30 && !this.state.performanceMode) {
          this.enablePerformanceMode();
        } else if (this.state.frameRate > 50 && this.state.performanceMode) {
          this.disablePerformanceMode();
        }
      
        // Monitor audio performance
        if (this.audioContext) {
          const latency = this.audioContext.baseLatency || this.audioContext.outputLatency || 0;
          this.state.audioLatency = latency;
        }
      }
      this.performanceMonitor.frameCount++;
    }, 16); // ~60fps check
  }
  enablePerformanceMode() {
    console.log('âš¡ Enabling performance mode');
    this.state.performanceMode = true;
    document.body.classList.add('performance-mode');
  
    // Reduce visual complexity
    this.particles = this.particles.slice(0, 20);
    this.config.maxParticles = 20;
  
    this.showNotification('Performance mode enabled', 2000);
  }
  disablePerformanceMode() {
    console.log('ðŸš€ Disabling performance mode');
    this.state.performanceMode = false;
    document.body.classList.remove('performance-mode');
  
    // Restore visual complexity
    this.config.maxParticles = 40;
    this.initParticles();
  
    this.showNotification('Full quality restored', 2000);
  }
  setupDOM() {
    // Complete DOM setup with all elements
    this.ui = {
      permissionOverlay: document.getElementById('permissionOverlay'),
      notification: document.getElementById('notification'),
      errorDisplay: document.getElementById('errorDisplay'),
      currentState: document.getElementById('currentState'),
      stateSubtitle: document.getElementById('stateSubtitle'),
      bpmValue: document.getElementById('bpmValue'),
      energyValue: document.getElementById('energyValue'),
      samplesValue: document.getElementById('samplesValue'),
      phaseValue: document.getElementById('phaseValue'),
      energyBar: document.getElementById('energyBar'),
      motionCore: document.getElementById('motionCore'),
      sampleNodes: document.querySelectorAll('.sample-node'),
      journeyProgress: document.getElementById('journeyProgress'),
      journeyTime: document.getElementById('journeyTime'),
      journeyPhase: document.getElementById('journeyPhase'),
      btnRecord: document.getElementById('btnRecord'),
      btnTap: document.getElementById('btnTap'),
      btnLoop: document.getElementById('btnLoop'),
      btnAI: document.getElementById('btnAI'),
      btnFX: document.getElementById('btnFX'),
      fxIndicators: {
        reverb: document.getElementById('fxReverb'),
        delay: document.getElementById('fxDelay'),
        filter: document.getElementById('fxFilter'),
        distortion: document.getElementById('fxDistortion'),
        chorus: document.getElementById('fxChorus')
      },
      spectrumBars: document.querySelectorAll('.spectrum-bar'),
      debug: {
        motion: document.getElementById('debugMotion'),
        accel: document.getElementById('debugAccel'),
        orient: document.getElementById('debugOrient'),
        touch: document.getElementById('debugTouch'),
        audio: document.getElementById('debugAudio'),
        state: document.getElementById('debugState'),
        perf: document.getElementById('debugPerf'),
        tempo: document.getElementById('debugTempo'),
        queue: document.getElementById('debugQueue')
      }
    };
  
    // Setup canvases with proper scaling
    this.canvases = {
      particle: document.getElementById('particleCanvas'),
      spatial: document.getElementById('spatialCanvas'),
      waveform: document.getElementById('waveformCanvas')
    };
  
    this.contexts = {
      particle: this.canvases.particle.getContext('2d', { alpha: true }),
      spatial: this.canvases.spatial.getContext('2d', { alpha: true }),
      waveform: this.canvases.waveform.getContext('2d', { alpha: false })
    };
  
    this.resizeCanvases();
    window.addEventListener('resize', () => this.resizeCanvases());
  }
  resizeCanvases() {
    const dpr = window.devicePixelRatio || 1;
    const w = window.innerWidth;
    const h = window.innerHeight;
  
    // Particle canvas
    this.canvases.particle.width = w * dpr;
    this.canvases.particle.height = h * dpr;
    this.canvases.particle.style.width = w + 'px';
    this.canvases.particle.style.height = h + 'px';
    this.contexts.particle.scale(dpr, dpr);
  
    // Spatial canvas
    this.canvases.spatial.width = w * dpr;
    this.canvases.spatial.height = h * dpr;
    this.canvases.spatial.style.width = w + 'px';
    this.canvases.spatial.style.height = h + 'px';
    this.contexts.spatial.scale(dpr, dpr);
  
    // Waveform canvas
    const waveformW = w - 20;
    this.canvases.waveform.width = waveformW * dpr;
    this.canvases.waveform.height = 60 * dpr;
    this.canvases.waveform.style.width = waveformW + 'px';
    this.canvases.waveform.style.height = '60px';
    this.contexts.waveform.scale(dpr, dpr);
  }
  setupEventListeners() {
    // Start button
    document.getElementById('startBtn').addEventListener('click', () => {
      this.requestPermissions();
    });
  
    // Control buttons with improved handling
    this.setupControlButton(this.ui.btnRecord, () => this.handleRecordButton());
    this.setupControlButton(this.ui.btnTap, () => this.handleTapTempo());
    this.setupControlButton(this.ui.btnLoop, () => this.toggleLoopMode());
    this.setupControlButton(this.ui.btnAI, () => this.toggleAIDJ());
    this.setupControlButton(this.ui.btnFX, () => this.cycleEffects());
  
    // Sample nodes with advanced interaction
    this.ui.sampleNodes.forEach((node, index) => {
      this.setupSampleNode(node, index);
    });
  
    // Global touch tracking
    this.setupGlobalTouchTracking();
  
    // Keyboard shortcuts
    document.addEventListener('keydown', (e) => {
      switch(e.key) {
        case 'd':
          document.getElementById('debugPanel').classList.toggle('visible');
          break;
        case ' ':
          e.preventDefault();
          if (this.state.isInitialized) {
            this.handleRecordButton();
          }
          break;
        case 'r':
          if (e.ctrlKey || e.metaKey) {
            e.preventDefault();
            // Don't reload during journey
          }
          break;
      }
    });
  
    // Visibility change handling
    document.addEventListener('visibilitychange', () => {
      if (document.hidden && this.audioContext) {
        this.audioContext.suspend();
      } else if (!document.hidden && this.audioContext) {
        this.audioContext.resume();
      }
    });
  }
  setupControlButton(button, handler) {
    if (!button) return;
  
    let touchStartTime = 0;
  
    const handleInteraction = (e) => {
      e.preventDefault();
      e.stopPropagation();
    
      const now = Date.now();
      if (now - touchStartTime < 200) { // Debounce
        return;
      }
      touchStartTime = now;
    
      handler();
      this.createTouchRipple(e.touches?.[0] || e);
    
      // Haptic feedback if available
      if (navigator.vibrate) {
        navigator.vibrate(10);
      }
    };
  
    button.addEventListener('touchstart', handleInteraction, { passive: false });
    button.addEventListener('click', handleInteraction);
  }
  setupSampleNode(node, index) {
    if (!node) return;
  
    let longPressTimer = null;
  
    const startInteraction = (e) => {
      e.preventDefault();
      e.stopPropagation();
    
      // Long press to delete
      longPressTimer = setTimeout(() => {
        if (this.state.samples.has(index)) {
          this.deleteSample(index);
          if (navigator.vibrate) navigator.vibrate([50, 30, 50]);
        }
      }, 1000);
    
      this.handleSampleTouch(index, 'start');
      this.createTouchRipple(e.touches?.[0] || e);
    };
  
    const endInteraction = () => {
      if (longPressTimer) {
        clearTimeout(longPressTimer);
        longPressTimer = null;
      }
    };
  
    node.addEventListener('touchstart', startInteraction, { passive: false });
    node.addEventListener('mousedown', startInteraction);
    node.addEventListener('touchend', endInteraction);
    node.addEventListener('mouseup', endInteraction);
    node.addEventListener('touchcancel', endInteraction);
  }
  setupGlobalTouchTracking() {
    let touchUpdateThrottle = null;
    let lastTouchTime = 0;
  
    document.addEventListener('touchstart', (e) => {
      const now = Date.now();
    
      // Track multi-touch
      for (let touch of e.touches) {
        this.state.touchPoints.set(touch.identifier, {
          x: touch.clientX,
          y: touch.clientY,
          startX: touch.clientX,
          startY: touch.clientY,
          time: now
        });
      }
    
      // Detect double tap
      if (now - lastTouchTime < 300 && e.touches.length === 1) {
        this.handleDoubleTap(e.touches[0]);
      }
      lastTouchTime = now;
    
      this.updateTouchDebug();
    });
  
    document.addEventListener('touchmove', (e) => {
      e.preventDefault();
    
      if (!touchUpdateThrottle) {
        touchUpdateThrottle = requestAnimationFrame(() => {
          for (let touch of e.touches) {
            if (this.state.touchPoints.has(touch.identifier)) {
              const point = this.state.touchPoints.get(touch.identifier);
              const dx = touch.clientX - point.x;
              const dy = touch.clientY - point.y;
            
              point.x = touch.clientX;
              point.y = touch.clientY;
              point.dx = dx;
              point.dy = dy;
            
              // Calculate velocity for motion
              const velocity = Math.sqrt(dx * dx + dy * dy);
              this.addTouchMotion(velocity / 100);
            }
          }
          touchUpdateThrottle = null;
        });
      }
    }, { passive: false });
  
    document.addEventListener('touchend', (e) => {
      for (let touch of e.changedTouches) {
        const point = this.state.touchPoints.get(touch.identifier);
        if (point) {
          // Check for gestures
          const dx = touch.clientX - point.startX;
          const dy = touch.clientY - point.startY;
          const distance = Math.sqrt(dx * dx + dy * dy);
          const duration = Date.now() - point.time;
        
          if (distance > 100 && duration < 500) {
            // Swipe detected
            this.handleSwipeGesture(dx, dy);
          }
        }
      
        this.state.touchPoints.delete(touch.identifier);
      }
      this.updateTouchDebug();
    });
  }
  addTouchMotion(velocity) {
    // Add touch velocity to motion
    const motion = Math.min(1, velocity);
    this.state.smoothedMotion = this.state.smoothedMotion * 0.9 + motion * 0.1;
    this.state.motionLevel = this.state.smoothedMotion;
  }
  handleDoubleTap(touch) {
    // Double tap to transition state
    const states = ['void', 'ambient', 'rhythmic', 'elevated', 'chaos'];
    const currentIndex = states.indexOf(this.state.currentState);
    const nextIndex = (currentIndex + 1) % states.length;
    this.transitionToState(states[nextIndex]);
  }
  handleSwipeGesture(dx, dy) {
    if (Math.abs(dx) > Math.abs(dy)) {
      // Horizontal swipe - change BPM
      const delta = dx > 0 ? 10 : -10;
      this.state.targetBPM = Math.max(60, Math.min(200, this.state.targetBPM + delta));
      this.showNotification(`BPM â†’ ${this.state.targetBPM}`, 1500);
    } else {
      // Vertical swipe - change energy
      const delta = dy > 0 ? -0.1 : 0.1;
      this.state.targetEnergy = Math.max(0, Math.min(1, this.state.targetEnergy + delta));
    }
  }
  updateTouchDebug() {
    if (this.ui.debug.touch) {
      this.ui.debug.touch.textContent = `${this.state.touchPoints.size} touches`;
    }
  }
  async requestPermissions() {
    console.log('ðŸ“± Requesting permissions...');
    this.showNotification('Initializing audio system...');
  
    try {
      // Initialize audio context first
      await this.initAudioSystem();
    
      // Then try microphone
      let stream = null;
      try {
        stream = await navigator.mediaDevices.getUserMedia({
          audio: {
            echoCancellation: false,
            noiseSuppression: false,
            autoGainControl: false,
            sampleRate: { ideal: this.config.sampleRate }
          }
        });
        this.state.hasMicrophone = true;
        console.log('ðŸŽ¤ Microphone access granted');
        this.setupMicrophoneInput(stream);
      } catch (micError) {
        console.warn('ðŸŽ¤ Microphone unavailable:', micError);
        this.showNotification('Starting without microphone', 3000);
      }
    
      // Setup motion detection
      await this.setupMotionDetection();
    
      // Start the journey
      this.startJourney();
    
    } catch (error) {
      this.handleError('Permission request failed', error);
      // Still try to start with minimal features
      this.initWithoutPermissions();
    }
  }
  async initAudioSystem() {
    console.log('ðŸ”Š Initializing Advanced Audio System...');
  
    try {
      // Create audio context
      const AudioContextClass = window.AudioContext || window.webkitAudioContext;
      this.audioContext = new AudioContextClass({
        sampleRate: this.config.sampleRate,
        latencyHint: 'interactive'
      });
    
      this.state.hasAudioContext = true;
    
      // Setup audio worklet if available (better than ScriptProcessor)
      if (this.audioContext.audioWorklet) {
        try {
          // For now, we'll use ScriptProcessor as fallback
          console.log('AudioWorklet available but using ScriptProcessor for compatibility');
        } catch (e) {
          console.log('AudioWorklet not available, using ScriptProcessor');
        }
      }
    
      // Create main audio graph
      this.setupAudioGraph();
    
      // Initialize all effects
      this.setupEffects();
    
      // Setup spatial audio system
      this.setupSpatialAudio();
    
      // Initialize synthesis engines
      this.setupSynthesisEngines();
    
      // Resume context
      if (this.audioContext.state === 'suspended') {
        await this.audioContext.resume();
      }
    
      // Start visualizers
      this.updateVisualizers();
    
      console.log('âœ… Audio system ready');
    
    } catch (error) {
      this.handleError('Audio initialization failed', error);
      this.state.hasAudioContext = false;
    }
  }
  setupAudioGraph() {
    try {
      // Master analyser
      this.audioNodes.analyser = this.audioContext.createAnalyser();
      this.audioNodes.analyser.fftSize = this.config.fftSize;
      this.audioNodes.analyser.smoothingTimeConstant = 0.85;
    
      // Recording processor
      const bufferSize = 4096;
      this.audioNodes.recorder = this.audioContext.createScriptProcessor(bufferSize, 1, 1);
    
      this.audioNodes.recorder.onaudioprocess = (e) => {
        if (this.state.isRecording) {
          const input = e.inputBuffer.getChannelData(0);
          this.recordBuffer.push(...input);
        
          // Real-time level monitoring
          const rms = Math.sqrt(input.reduce((sum, x) => sum + x * x, 0) / input.length);
          if (this.ui.debug.audio) {
            this.ui.debug.audio.textContent = rms.toFixed(3);
          }
        }
      };
    
      // Submix buses
      this.audioNodes.drumBus = this.audioContext.createGain();
      this.audioNodes.drumBus.gain.value = 0.7;
    
      this.audioNodes.sampleBus = this.audioContext.createGain();
      this.audioNodes.sampleBus.gain.value = 0.6;
    
      this.audioNodes.synthBus = this.audioContext.createGain();
      this.audioNodes.synthBus.gain.value = 0.5;
    
      // Master processing chain
      this.audioNodes.masterGain = this.audioContext.createGain();
      this.audioNodes.masterGain.gain.value = 0.8;
    
      this.audioNodes.masterCompressor = this.audioContext.createDynamicsCompressor();
      this.audioNodes.masterCompressor.threshold.value = -12;
      this.audioNodes.masterCompressor.knee.value = 30;
      this.audioNodes.masterCompressor.ratio.value = 8;
      this.audioNodes.masterCompressor.attack.value = 0.003;
      this.audioNodes.masterCompressor.release.value = 0.25;
    
      this.audioNodes.masterLimiter = this.audioContext.createDynamicsCompressor();
      this.audioNodes.masterLimiter.threshold.value = -1;
      this.audioNodes.masterLimiter.knee.value = 0;
      this.audioNodes.masterLimiter.ratio.value = 20;
      this.audioNodes.masterLimiter.attack.value = 0.001;
      this.audioNodes.masterLimiter.release.value = 0.01;
    
      // Connect master chain
      this.audioNodes.drumBus.connect(this.audioNodes.masterGain);
      this.audioNodes.sampleBus.connect(this.audioNodes.masterGain);
      this.audioNodes.synthBus.connect(this.audioNodes.masterGain);
    
      this.audioNodes.masterGain.connect(this.audioNodes.masterCompressor);
      this.audioNodes.masterCompressor.connect(this.audioNodes.masterLimiter);
      this.audioNodes.masterLimiter.connect(this.audioContext.destination);
      this.audioNodes.masterLimiter.connect(this.audioNodes.analyser);
    
      // Silent connection for recorder
      this.audioNodes.recorder.connect(this.audioContext.destination);
    
    } catch (error) {
      this.handleError('Audio graph setup failed', error);
    }
  }
  setupMicrophoneInput(stream) {
    if (!stream || !this.audioContext) return;
  
    try {
      this.audioNodes.micInput = this.audioContext.createMediaStreamSource(stream);
    
      // Mic gain control
      this.audioNodes.micGain = this.audioContext.createGain();
      this.audioNodes.micGain.gain.value = 1;
    
      // Connect to recorder
      this.audioNodes.micInput.connect(this.audioNodes.micGain);
      this.audioNodes.micGain.connect(this.audioNodes.recorder);
    
      // Connect to analyser for visualization
      this.audioNodes.micGain.connect(this.audioNodes.analyser);
    
    } catch (error) {
      this.handleError('Microphone setup failed', error);
    }
  }
  setupEffects() {
    try {
      // Convolution Reverb with multiple impulses
      this.setupReverbEffect();
    
      // Ping-pong delay
      this.setupDelayEffect();
    
      // Multi-mode filter
      this.setupFilterEffect();
    
      // Waveshaper distortion
      this.setupDistortionEffect();
    
      // Chorus ensemble
      this.setupChorusEffect();
    
      // Additional creative effects
      this.setupGranularEffect();
      this.setupPhaserEffect();
    
    } catch (error) {
      this.handleError('Effects setup failed', error);
    }
  }
  setupReverbEffect() {
    this.audioNodes.reverb = this.audioContext.createConvolver();
    this.audioNodes.reverbGain = this.audioContext.createGain();
    this.audioNodes.reverbGain.gain.value = 0.3;
  
    // Generate multiple impulse responses
    const impulses = {
      hall: this.generateImpulse(4, 4, 0.5),
      room: this.generateImpulse(2, 2, 0.7),
      plate: this.generateImpulse(1.5, 1.5, 0.9),
      spring: this.generateImpulse(0.5, 0.5, 0.3)
    };
  
    this.audioNodes.reverb.buffer = impulses.hall;
    this.audioBuffers.impulses = impulses;
  
    this.audioNodes.reverb.connect(this.audioNodes.reverbGain);
    this.audioNodes.reverbGain.connect(this.audioNodes.masterGain);
  }
  generateImpulse(duration, decay, mix) {
    const length = this.audioContext.sampleRate * duration;
    const impulse = this.audioContext.createBuffer(2, length, this.audioContext.sampleRate);
  
    for (let channel = 0; channel < 2; channel++) {
      const channelData = impulse.getChannelData(channel);
      for (let i = 0; i < length; i++) {
        const n = length - i;
        channelData[i] = (Math.random() * 2 - 1) * Math.pow(n / length, decay) * mix;
      }
    }
  
    return impulse;
  }
  setupDelayEffect() {
    // Ping-pong delay
    this.audioNodes.delayL = this.audioContext.createDelay(2);
    this.audioNodes.delayR = this.audioContext.createDelay(2);
    this.audioNodes.delayGain = this.audioContext.createGain();
    this.audioNodes.delayFeedback = this.audioContext.createGain();
  
    this.audioNodes.delayL.delayTime.value = 60 / this.state.bpm / 8;
    this.audioNodes.delayR.delayTime.value = 60 / this.state.bpm / 6;
    this.audioNodes.delayGain.gain.value = 0.3;
    this.audioNodes.delayFeedback.gain.value = 0.4;
  
    // Create ping-pong routing
    const merger = this.audioContext.createChannelMerger(2);
    const splitter = this.audioContext.createChannelSplitter(2);
  
    this.audioNodes.delayL.connect(merger, 0, 0);
    this.audioNodes.delayR.connect(merger, 0, 1);
    merger.connect(this.audioNodes.delayFeedback);
    this.audioNodes.delayFeedback.connect(splitter);
    splitter.connect(this.audioNodes.delayR, 0);
    splitter.connect(this.audioNodes.delayL, 1);
  
    merger.connect(this.audioNodes.delayGain);
    this.audioNodes.delayGain.connect(this.audioNodes.masterGain);
  }
  setupFilterEffect() {
    // Multi-mode filter with envelope follower
    this.audioNodes.filter = this.audioContext.createBiquadFilter();
    this.audioNodes.filter.type = 'lowpass';
    this.audioNodes.filter.frequency.value = 5000;
    this.audioNodes.filter.Q.value = 1;
  
    // Additional filter modes
    this.audioNodes.highpass = this.audioContext.createBiquadFilter();
    this.audioNodes.highpass.type = 'highpass';
    this.audioNodes.highpass.frequency.value = 100;
  
    this.audioNodes.bandpass = this.audioContext.createBiquadFilter();
    this.audioNodes.bandpass.type = 'bandpass';
    this.audioNodes.bandpass.frequency.value = 1000;
    this.audioNodes.bandpass.Q.value = 2;
  
    this.audioNodes.filter.connect(this.audioNodes.masterGain);
    this.audioNodes.highpass.connect(this.audioNodes.filter);
    this.audioNodes.bandpass.connect(this.audioNodes.filter);
  }
  setupDistortionEffect() {
    this.audioNodes.distortion = this.audioContext.createWaveShaper();
    this.audioNodes.distortionGain = this.audioContext.createGain();
    this.audioNodes.distortionGain.gain.value = 0;
  
    // Generate multiple distortion curves
    const curves = {
      soft: this.generateDistortionCurve(256, 2),
      hard: this.generateDistortionCurve(256, 5),
      fuzz: this.generateDistortionCurve(256, 10),
      bit: this.generateBitCrusherCurve(256, 8)
    };
  
    this.audioNodes.distortion.curve = curves.soft;
    this.audioBuffers.distortionCurves = curves;
    this.audioNodes.distortion.oversample = '4x';
  
    this.audioNodes.distortion.connect(this.audioNodes.distortionGain);
    this.audioNodes.distortionGain.connect(this.audioNodes.masterGain);
  }
  generateDistortionCurve(samples, amount) {
    const curve = new Float32Array(samples);
    for (let i = 0; i < samples; i++) {
      const x = (i * 2 / samples - 1);
      curve[i] = ((3 + amount) * x * 32) / (Math.PI + amount * Math.abs(x));
    }
    return curve;
  }
  generateBitCrusherCurve(samples, bits) {
    const curve = new Float32Array(samples);
    const levels = Math.pow(2, bits);
    for (let i = 0; i < samples; i++) {
      const x = (i * 2 / samples - 1);
      curve[i] = Math.round(x * levels) / levels;
    }
    return curve;
  }
  setupChorusEffect() {
    this.audioNodes.chorus = [];
    this.audioNodes.chorusGain = this.audioContext.createGain();
    this.audioNodes.chorusGain.gain.value = 0;
  
    // Create multiple chorus voices
    for (let i = 0; i < 4; i++) {
      const delay = this.audioContext.createDelay(0.1);
      const lfo = this.audioContext.createOscillator();
      const lfoGain = this.audioContext.createGain();
    
      delay.delayTime.value = 0.02 + i * 0.005;
      lfo.frequency.value = 0.5 + i * 0.1;
      lfoGain.gain.value = 0.002 + i * 0.001;
      lfo.type = 'sine';
    
      lfo.connect(lfoGain);
      lfoGain.connect(delay.delayTime);
      lfo.start();
    
      delay.connect(this.audioNodes.chorusGain);
      this.audioNodes.chorus.push({ delay, lfo, lfoGain });
    }
  
    this.audioNodes.chorusGain.connect(this.audioNodes.masterGain);
  }
  setupGranularEffect() {
    // Simple granular synthesis effect
    this.audioNodes.granular = {
      grains: [],
      grainGain: this.audioContext.createGain()
    };
  
    this.audioNodes.granular.grainGain.gain.value = 0;
    this.audioNodes.granular.grainGain.connect(this.audioNodes.masterGain);
  }
  setupPhaserEffect() {
    // Phaser effect with multiple all-pass filters
    this.audioNodes.phaser = {
      filters: [],
      lfo: this.audioContext.createOscillator(),
      lfoGain: this.audioContext.createGain(),
      wetGain: this.audioContext.createGain()
    };
  
    // Create all-pass filter chain
    for (let i = 0; i < 4; i++) {
      const filter = this.audioContext.createBiquadFilter();
      filter.type = 'allpass';
      filter.frequency.value = 1000 + i * 500;
    
      if (i > 0) {
        this.audioNodes.phaser.filters[i - 1].connect(filter);
      }
    
      this.audioNodes.phaser.filters.push(filter);
    }
  
    // Setup LFO
    this.audioNodes.phaser.lfo.frequency.value = 0.2;
    this.audioNodes.phaser.lfoGain.gain.value = 500;
    this.audioNodes.phaser.wetGain.gain.value = 0;
    this.audioNodes.phaser.lfo.type = 'sine';
  
    this.audioNodes.phaser.lfo.connect(this.audioNodes.phaser.lfoGain);
    this.audioNodes.phaser.lfo.start();
  
    // Connect modulation
    for (let filter of this.audioNodes.phaser.filters) {
      this.audioNodes.phaser.lfoGain.connect(filter.frequency);
    }
  
    if (this.audioNodes.phaser.filters.length > 0) {
      const lastFilter = this.audioNodes.phaser.filters[this.audioNodes.phaser.filters.length - 1];
      lastFilter.connect(this.audioNodes.phaser.wetGain);
      this.audioNodes.phaser.wetGain.connect(this.audioNodes.masterGain);
    }
  }
  setupSpatialAudio() {
    if (!this.audioContext) return;
  
    try {
      this.audioNodes.spatialPanners = [];
    
      // Create 3D spatial panners
      for (let i = 0; i < 8; i++) {
        let panner;
      
        if (this.audioContext.createPanner) {
          panner = this.audioContext.createPanner();
          panner.panningModel = 'HRTF';
          panner.distanceModel = 'inverse';
          panner.refDistance = 1;
          panner.maxDistance = 10;
          panner.rolloffFactor = 1;
          panner.coneInnerAngle = 360;
        
          const angle = (i / 8) * Math.PI * 2;
          const radius = 3;
        
          if (panner.positionX) {
            panner.positionX.value = Math.cos(angle) * radius;
            panner.positionY.value = 0;
            panner.positionZ.value = Math.sin(angle) * radius;
          } else {
            panner.setPosition(
              Math.cos(angle) * radius,
              0,
              Math.sin(angle) * radius
            );
          }
        } else {
          // Fallback to StereoPanner
          panner = this.audioContext.createStereoPanner();
          panner.pan.value = Math.cos((i / 8) * Math.PI * 2);
        }
      
        panner.connect(this.audioNodes.masterGain);
        this.audioNodes.spatialPanners.push(panner);
      }
    
      // Setup listener
      if (this.audioContext.listener) {
        const listener = this.audioContext.listener;
      
        if (listener.positionX) {
          listener.positionX.value = 0;
          listener.positionY.value = 0;
          listener.positionZ.value = 0;
        } else if (listener.setPosition) {
          listener.setPosition(0, 0, 0);
        }
      }
    
    } catch (error) {
      console.warn('Spatial audio setup partial failure:', error);
    }
  }
  setupSynthesisEngines() {
    // Advanced synthesis capabilities
    this.synthesizers = {
      bass: new BassSynthesizer(this.audioContext, this.audioNodes.synthBus),
      lead: new LeadSynthesizer(this.audioContext, this.audioNodes.synthBus),
      pad: new PadSynthesizer(this.audioContext, this.audioNodes.synthBus),
      percussion: new PercussionSynthesizer(this.audioContext, this.audioNodes.drumBus, this)
    };
  }
  generateSyntheticDrums() {
    // Pre-generate drum sounds for better performance
    this.drumSounds = {
      kick: this.generateKickDrum(),
      snare: this.generateSnareDrum(),
      hihat: this.generateHiHat(),
      clap: this.generateClap(),
      tom: this.generateTom()
    };
  }
  generateKickDrum() {
    const duration = 0.5;
    const sampleRate = this.audioContext ? this.audioContext.sampleRate : 48000;
    const length = duration * sampleRate;
  
    const buffer = this.audioContext ?
      this.audioContext.createBuffer(1, length, sampleRate) :
      { getChannelData: () => new Float32Array(length) };
  
    const data = buffer.getChannelData(0);
  
    for (let i = 0; i < length; i++) {
      const t = i / sampleRate;
      const envelope = Math.exp(-35 * t);
      const pitch = 60 * Math.exp(-35 * t);
      data[i] = Math.sin(2 * Math.PI * pitch * t) * envelope * 0.5;
    }
  
    return buffer;
  }
  generateSnareDrum() {
    const duration = 0.2;
    const sampleRate = this.audioContext ? this.audioContext.sampleRate : 48000;
    const length = duration * sampleRate;
  
    const buffer = this.audioContext ?
      this.audioContext.createBuffer(1, length, sampleRate) :
      { getChannelData: () => new Float32Array(length) };
  
    const data = buffer.getChannelData(0);
  
    for (let i = 0; i < length; i++) {
      const t = i / sampleRate;
      const envelope = Math.exp(-35 * t);
      const tone = Math.sin(2 * Math.PI * 200 * t);
      const noise = (Math.random() * 2 - 1) * 0.5;
      data[i] = (tone * 0.5 + noise) * envelope;
    }
  
    return buffer;
  }
  generateHiHat() {
    const duration = 0.05;
    const sampleRate = this.audioContext ? this.audioContext.sampleRate : 48000;
    const length = duration * sampleRate;
  
    const buffer = this.audioContext ?
      this.audioContext.createBuffer(1, length, sampleRate) :
      { getChannelData: () => new Float32Array(length) };
  
    const data = buffer.getChannelData(0);
  
    for (let i = 0; i < length; i++) {
      const t = i / sampleRate;
      const envelope = Math.exp(-50 * t);
      data[i] = (Math.random() * 2 - 1) * envelope * 0.3;
    }
  
    return buffer;
  }
  generateClap() {
    const duration = 0.1;
    const sampleRate = this.audioContext ? this.audioContext.sampleRate : 48000;
    const length = duration * sampleRate;
  
    const buffer = this.audioContext ?
      this.audioContext.createBuffer(1, length, sampleRate) :
      { getChannelData: () => new Float32Array(length) };
  
    const data = buffer.getChannelData(0);
  
    for (let i = 0; i < length; i++) {
      const t = i / sampleRate;
      const envelope = Math.exp(-40 * t);
      const tone = Math.sin(2 * Math.PI * 180 * t) * 0.4;
      const noise = (Math.random() * 2 - 1) * 0.6;
      data[i] = (tone + noise) * envelope;
    }
  
    return buffer;
  }
  generateTom() {
    const duration = 0.3;
    const sampleRate = this.audioContext ? this.audioContext.sampleRate : 48000;
    const length = duration * sampleRate;
  
    const buffer = this.audioContext ?
      this.audioContext.createBuffer(1, length, sampleRate) :
      { getChannelData: () => new Float32Array(length) };
  
    const data = buffer.getChannelData(0);
  
    for (let i = 0; i < length; i++) {
      const t = i / sampleRate;
      const envelope = Math.exp(-20 * t);
      const pitch = 100 * Math.exp(-10 * t);
      data[i] = Math.sin(2 * Math.PI * pitch * t) * envelope * 0.4;
    }
  
    return buffer;
  }
  setupVisualSystems() {
    this.initParticles();
    this.initNeuralNetwork();
    this.initSpectrumAnalyzer();
  }
  initParticles() {
    this.particles = [];
    for (let i = 0; i < this.config.maxParticles; i++) {
      this.particles.push({
        x: Math.random() * window.innerWidth,
        y: Math.random() * window.innerHeight,
        vx: (Math.random() - 0.5) * 2,
        vy: (Math.random() - 0.5) * 2,
        size: Math.random() * 3 + 1,
        color: `hsl(${Math.random() * 360}, 100%, 50%)`,
        life: 1,
        maxLife: Math.random() * 100 + 50
      });
    }
    this.animateParticles();
  }
  animateParticles() {
    const ctx = this.contexts.particle;
    const w = window.innerWidth;
    const h = window.innerHeight;
    ctx.clearRect(0, 0, w, h);
    for (let p of this.particles) {
      p.x += p.vx + this.state.motionLevel * Math.sin(Date.now() * 0.001 + p.x);
      p.y += p.vy + this.state.motionLevel * Math.cos(Date.now() * 0.001 + p.y);
      p.life -= 1 / p.maxLife;
      if (p.life <= 0 || p.x < 0 || p.x > w || p.y < 0 || p.y > h) {
        p.x = Math.random() * w;
        p.y = Math.random() * h;
        p.life = 1;
        p.vx = (Math.random() - 0.5) * 2;
        p.vy = (Math.random() - 0.5) * 2;
      }
      ctx.globalAlpha = p.life * this.state.energy;
      ctx.fillStyle = p.color;
      ctx.beginPath();
      ctx.arc(p.x, p.y, p.size, 0, Math.PI * 2);
      ctx.fill();
    }
    requestAnimationFrame(() => this.animateParticles());
  }
  initNeuralNetwork() {
    const container = document.getElementById('neuralNetwork');
    container.innerHTML = '';
    this.neuralNodes = [];
    for (let i = 0; i < 12; i++) {
      const node = document.createElement('div');
      node.className = 'neural-node';
      node.style.left = `${Math.random() * 250}px`;
      node.style.top = `${Math.random() * 80}px`;
      container.appendChild(node);
      this.neuralNodes.push(node);
    }
    // Animate nodes based on audio
    setInterval(() => {
      if (this.audioNodes.analyser) {
        const data = new Uint8Array(this.audioNodes.analyser.frequencyBinCount);
        this.audioNodes.analyser.getByteFrequencyData(data);
        const avg = data.reduce((a, b) => a + b) / data.length / 255;
        this.neuralNodes.forEach((node, i) => {
          const opacity = 0.3 + (Math.sin(Date.now() * 0.001 + i) * 0.2 + avg * 0.5);
          node.style.opacity = Math.max(0.1, opacity);
          node.style.transform = `scale(${1 + avg * 0.5})`;
        });
      }
    }, 50);
  }
  initSpectrumAnalyzer() {
    this.spectrumBars = Array.from(this.ui.spectrumBars);
  }
  updateVisualizers() {
    if (!this.audioNodes.analyser) {
      requestAnimationFrame(() => this.updateVisualizers());
      return;
    }
    const bufferLength = this.audioNodes.analyser.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);
  
    // Waveform
    this.audioNodes.analyser.getByteTimeDomainData(dataArray);
    const waveformCtx = this.contexts.waveform;
    waveformCtx.clearRect(0, 0, waveformCtx.canvas.width, waveformCtx.canvas.height);
    waveformCtx.lineWidth = 2;
    waveformCtx.strokeStyle = `rgb(${Math.floor(255 * this.state.energy)}, ${Math.floor(255 * (1 - this.state.energy))}, 255)`;
    waveformCtx.beginPath();
    const sliceWidth = waveformCtx.canvas.width * 1.0 / bufferLength;
    let x = 0;
    for (let i = 0; i < bufferLength; i++) {
      const v = dataArray[i] / 128.0;
      const y = v * waveformCtx.canvas.height / 2;
      if (i === 0) {
        waveformCtx.moveTo(x, y);
      } else {
        waveformCtx.lineTo(x, y);
      }
      x += sliceWidth;
    }
    waveformCtx.lineTo(waveformCtx.canvas.width, waveformCtx.canvas.height / 2);
    waveformCtx.stroke();
  
    // Spectrum
    this.audioNodes.analyser.getByteFrequencyData(dataArray);
    const barCount = this.spectrumBars.length;
    for (let i = 0; i < barCount; i++) {
      let barHeight = 0;
      const barIndex = Math.floor((i / barCount) * (bufferLength / barCount));
      for (let j = 0; j < bufferLength / barCount; j++) {
        const index = barIndex + j;
        if (index < bufferLength) barHeight += dataArray[index];
      }
      barHeight = (barHeight / (bufferLength / barCount)) / 255 * 40;
      this.spectrumBars[i].style.height = `${barHeight}px`;
    }
  
    requestAnimationFrame(() => this.updateVisualizers());
  }
  async setupMotionDetection() {
    if (typeof DeviceMotionEvent.requestPermission === 'function') {
      DeviceMotionEvent.requestPermission()
        .then((permissionState) => {
          if (permissionState === 'granted') {
            window.addEventListener('devicemotion', this.handleDeviceMotion.bind(this));
            this.state.hasMotionSensors = true;
          }
        })
        .catch(console.error);
    } else {
      // Non-iOS
      window.addEventListener('devicemotion', this.handleDeviceMotion.bind(this));
      this.state.hasMotionSensors = true;
    }
  
    if (typeof DeviceOrientationEvent.requestPermission === 'function') {
      DeviceOrientationEvent.requestPermission()
        .then((permissionState) => {
          if (permissionState === 'granted') {
            window.addEventListener('deviceorientation', this.handleDeviceOrientation.bind(this));
          }
        })
        .catch(console.error);
    } else {
      window.addEventListener('deviceorientation', this.handleDeviceOrientation.bind(this));
    }
  }
  handleDeviceMotion(e) {
    if (e.accelerationIncludingGravity) {
      this.state.accelerometer = {
        x: e.accelerationIncludingGravity.x || 0,
        y: e.accelerationIncludingGravity.y || 0,
        z: e.accelerationIncludingGravity.z || 0
      };
      const accelMagnitude = Math.sqrt(
        this.state.accelerometer.x ** 2 +
        this.state.accelerometer.y ** 2 +
        this.state.accelerometer.z ** 2
      ) / 9.81; // Normalize g-force
      this.state.smoothedMotion = this.state.smoothedMotion * this.config.motionSmoothingFactor + accelMagnitude * (1 - this.config.motionSmoothingFactor);
      this.state.motionLevel = Math.max(0, Math.min(1, this.state.smoothedMotion - this.config.motionThreshold));
      this.state.targetEnergy = Math.min(1, this.state.targetEnergy + this.state.motionLevel * 0.01);
      this.updateMotionDebug();
      this.ui.debug.state.textContent = this.state.currentState;
    }
  }
  handleDeviceOrientation(e) {
    this.state.orientation = {
      alpha: e.alpha || 0,
      beta: e.beta || 0,
      gamma: e.gamma || 0
    };
    this.updateOrientationDebug();
  }
  updateMotionDebug() {
    if (this.ui.debug.motion) {
      this.ui.debug.motion.textContent = this.state.motionLevel.toFixed(2);
    }
    if (this.ui.debug.accel) {
      this.ui.debug.accel.textContent = `${this.state.accelerometer.x.toFixed(1)}, ${this.state.accelerometer.y.toFixed(1)}, ${this.state.accelerometer.z.toFixed(1)}`;
    }
    if (this.ui.debug.tempo) {
      this.ui.debug.tempo.textContent = this.state.bpm;
    }
    if (this.ui.debug.queue) {
      this.ui.debug.queue.textContent = this.state.noteQueue.length;
    }
  }
  updateOrientationDebug() {
    if (this.ui.debug.orient) {
      this.ui.debug.orient.textContent = `${this.state.orientation.alpha.toFixed(0)}, ${this.state.orientation.beta.toFixed(0)}, ${this.state.orientation.gamma.toFixed(0)}`;
    }
  }
  startJourney() {
    this.state.journeyStartTime = Date.now();
    this.state.isInitialized = true;
    this.ui.permissionOverlay.classList.add('hidden');
    document.body.classList.add(`state-${this.state.currentState}`);
    this.transitionToState('ambient');
    this.mainLoop();
    this.scheduler = setInterval(() => this.scheduleNotes(), 25);
    this.ui.phaseValue.textContent = `${this.state.journeyPhase + 1}/5`;
    this.showNotification('Journey begun. Move to create soundscapes.', 4000);
  }
  mainLoop() {
    const now = Date.now();
    this.state.journeyElapsed = now - (this.state.journeyStartTime || now);
    this.state.bpm = this.state.bpm * 0.95 + this.state.targetBPM * 0.05;
    this.ui.bpmValue.textContent = Math.round(this.state.bpm);
  
    // Update journey UI
    const elapsedMin = Math.floor(this.state.journeyElapsed / 60000).toString().padStart(2, '0');
    const elapsedSec = Math.floor((this.state.journeyElapsed % 60000) / 1000).toString().padStart(2, '0');
    this.ui.journeyTime.textContent = `${elapsedMin}:${elapsedSec}`;
    const progress = Math.min(100, (this.state.journeyElapsed / this.config.journeyDuration) * 100);
    this.ui.journeyProgress.style.width = `${progress}%`;
  
    // Update phases
    const phaseDuration = this.config.journeyDuration / 5;
    const newPhase = Math.min(4, Math.floor(this.state.journeyElapsed / phaseDuration));
    if (newPhase !== this.state.journeyPhase) {
      this.state.journeyPhase = newPhase;
      this.ui.phaseValue.textContent = `${newPhase + 1}/5`;
      const phases = ['INTRODUCTION', 'EXPLORATION', 'CLIMAX', 'RESOLUTION', 'CODA'];
      this.ui.journeyPhase.textContent = phases[newPhase];
      this.showNotification(`Phase: ${phases[newPhase]}`, 2000);
    }
  
    // Update energy and motion orb
    this.state.energy = this.state.energy * 0.95 + this.state.targetEnergy * 0.05;
    this.ui.energyValue.textContent = this.state.energy.toFixed(2);
    this.ui.energyBar.style.height = `${this.state.energy * 200}px`;
    const orbSize = 20 + this.state.motionLevel * 40;
    this.ui.motionCore.style.width = `${orbSize}px`;
    this.ui.motionCore.style.height = `${orbSize}px`;
    this.ui.motionCore.style.background = `hsl(${this.state.motionLevel * 360}, 100%, 50%)`;
  
    // State transitions
    const motionThresholds = { void: 0.1, ambient: 0.3, rhythmic: 0.6, elevated: 0.8 };
    const states = ['void', 'ambient', 'rhythmic', 'elevated', 'chaos'];
    const currentIndex = states.indexOf(this.state.currentState);
    if (this.state.motionLevel > (motionThresholds[this.state.currentState] || 0.1)) {
      const nextIndex = Math.min(states.length - 1, currentIndex + 1);
      this.transitionToState(states[nextIndex]);
    }
  
    requestAnimationFrame(() => this.mainLoop());
  }
  transitionToState(newState) {
    if (newState === this.state.currentState) return;
    this.state.previousState = this.state.currentState;
    this.state.currentState = newState;
    document.body.classList.remove(`state-${this.state.previousState}`);
    document.body.classList.add(`state-${newState}`);
    this.ui.currentState.textContent = newState.toUpperCase();
    const subtitles = {
      void: 'awaiting motion',
      ambient: 'gentle waves',
      rhythmic: 'pulse awakening',
      elevated: 'harmonic ascent',
      chaos: 'fractal dissolution'
    };
    this.ui.stateSubtitle.textContent = subtitles[newState] || '';
    this.config.rhythmPatterns.chaos = [1, Math.random(), Math.random(), Math.random(), 1, Math.random(), Math.random(), Math.random()];
    this.state.complexity = ['void', 'ambient', 'rhythmic', 'elevated', 'chaos'].indexOf(newState) / 4;
    this.ui.debug.state.textContent = newState;
    this.showNotification(`Entering ${newState.toUpperCase()} state`, 2000);
    if (navigator.vibrate) navigator.vibrate(100);
  }
  handleRecordButton() {
    if (!this.state.hasAudioContext) {
      this.showNotification('Audio not initialized', 2000);
      return;
    }
    if (this.state.isRecording) {
      this.stopRecording();
    } else {
      this.startRecording();
    }
  }
  startRecording() {
    if (this.state.nextSampleSlot >= this.config.maxSamples) {
      this.showNotification('Sample matrix full. Clear a slot to record.', 2000);
      return;
    }
    this.state.isRecording = true;
    this.state.currentRecordingSlot = this.state.nextSampleSlot;
    this.recordBuffer = [];
    this.ui.btnRecord.classList.add('recording');
    const node = this.ui.sampleNodes[this.state.currentRecordingSlot];
    node.classList.add('recording');
    this.showNotification(`Recording sample ${this.state.nextSampleSlot + 1}... Move and create sound`, 3000);
    setTimeout(() => this.stopRecording(), this.config.sampleDuration);
  }
  stopRecording() {
    this.state.isRecording = false;
    this.ui.btnRecord.classList.remove('recording');
    if (this.state.currentRecordingSlot !== null) {
      const slot = this.state.currentRecordingSlot;
      const node = this.ui.sampleNodes[slot];
      node.classList.remove('recording');
      node.classList.add('processing');
      const bufferLength = this.recordBuffer.length;
      if (bufferLength > this.audioContext.sampleRate * 0.1) { // Min length check
        const audioBuffer = this.audioContext.createBuffer(1, bufferLength, this.audioContext.sampleRate);
        audioBuffer.getChannelData(0).set(this.recordBuffer);
        this.state.samples.set(slot, audioBuffer);
        this.analyzeSample(audioBuffer, slot);
        setTimeout(() => {
          node.classList.remove('processing');
          node.classList.add('loaded');
        }, 500);
        this.state.nextSampleSlot = Math.min(this.config.maxSamples, this.state.nextSampleSlot + 1);
        this.updateSamplesUI();
        this.showNotification(`Sample ${slot + 1} captured (${(bufferLength / this.audioContext.sampleRate).toFixed(1)}s)`, 2000);
      } else {
        node.classList.remove('processing');
        this.showNotification('Recording too short. Try again.', 2000);
      }
      this.state.currentRecordingSlot = null;
    }
    this.recordBuffer = [];
  }
  analyzeSample(buffer, slot) {
    this.sampleAnalysis[slot] = {
      duration: buffer.duration,
      rms: 0, // Could compute RMS here if needed
      fundamentalFreq: 0 // Pitch detection stub
    };
  }
  updateSamplesUI() {
    this.ui.samplesValue.textContent = `${this.state.nextSampleSlot}/9`;
  }
  handleTapTempo() {
    const now = Date.now();
    if (!this.state.lastTapTime) {
      this.state.lastTapTime = now;
      return;
    }
    const interval = now - this.state.lastTapTime;
    if (interval < 2000 && interval > 200) { // Valid tap interval
      this.state.targetBPM = Math.round(60000 / interval);
      this.state.lastTapTime = now;
      this.ui.bpmValue.textContent = this.state.targetBPM;
      // Update delay times
      if (this.audioNodes.delayL) this.audioNodes.delayL.delayTime.value = 60 / this.state.targetBPM / 8;
      if (this.audioNodes.delayR) this.audioNodes.delayR.delayTime.value = 60 / this.state.targetBPM / 6;
      this.showNotification(`BPM tapped: ${this.state.targetBPM}`, 1000);
      if (navigator.vibrate) navigator.vibrate(50);
    }
  }
  toggleLoopMode() {
    this.state.isLooping = !this.state.isLooping;
    this.ui.btnLoop.classList.toggle('active', this.state.isLooping);
    this.showNotification(this.state.isLooping ? 'Loop mode engaged' : 'Loop mode disengaged', 1000);
  }
  toggleAIDJ() {
    this.state.aiDjActive = !this.state.aiDjActive;
    this.ui.btnAI.classList.toggle('active', this.state.aiDjActive);
    this.showNotification(this.state.aiDjActive ? 'AI DJ activated - adaptive generation' : 'Manual control mode', 1500);
  }
  cycleEffects() {
    const effects = ['reverb', 'delay', 'filter', 'distortion', 'chorus'];
    let current = null;
    for (let effect of effects) {
      if (this.state.activeEffects.has(effect)) {
        current = effect;
        break;
      }
    }
    const currentIndex = current ? effects.indexOf(current) : -1;
    const nextIndex = (currentIndex + 1) % effects.length;
    this.state.activeEffects.clear();
    this.state.activeEffects.add(effects[nextIndex]);
    // Update gains for active effect
    switch (effects[nextIndex]) {
      case 'reverb':
        this.audioNodes.reverbGain.gain.value = 0.3;
        break;
      case 'delay':
        this.audioNodes.delayGain.gain.value = 0.3;
        break;
      case 'filter':
        this.audioNodes.filter.frequency.value = 2000 + Math.random() * 3000;
        break;
      case 'distortion':
        this.audioNodes.distortionGain.gain.value = 0.5;
        break;
      case 'chorus':
        this.audioNodes.chorusGain.gain.value = 0.4;
        break;
    }
    // Update UI
    Object.keys(this.ui.fxIndicators).forEach(key => {
      this.ui.fxIndicators[key].classList.toggle('active', this.state.activeEffects.has(key));
    });
    this.showNotification(`${effects[nextIndex].toUpperCase()} effect engaged`, 1000);
  }
  handleSampleTouch(slot, action) {
    if (action === 'start' && this.state.samples.has(slot)) {
      this.playSample(slot);
    }
  }
  playSample(slot) {
    const buffer = this.state.samples.get(slot);
    if (!buffer || !this.audioContext) return;
    const source = this.audioContext.createBufferSource();
    source.buffer = buffer;
    let finalNode = this.audioNodes.sampleBus;
    // Route through active effect
    if (this.state.activeEffects.has('reverb')) {
      source.connect(this.audioNodes.reverb);
    } else if (this.state.activeEffects.has('delay')) {
      source.connect(this.audioNodes.delayL);
      source.connect(this.audioNodes.delayR);
    } else {
      source.connect(finalNode);
    }
    source.start();
    const node = this.ui.sampleNodes[slot];
    node.classList.add('playing');
    setTimeout(() => node.classList.remove('playing'), 300);
    // Influence energy
    this.state.targetEnergy = Math.min(1, this.state.targetEnergy + 0.1);
    // Add to melodic sequence
    this.melodicSequence.push({ slot, time: this.audioContext.currentTime });
    if (this.melodicSequence.length > 32) this.melodicSequence.shift();
  }
  deleteSample(slot) {
    this.state.samples.delete(slot);
    this.sampleAnalysis[slot] = null;
    const node = this.ui.sampleNodes[slot];
    node.classList.remove('loaded', 'playing', 'processing');
    // Shift remaining samples down
    for (let i = slot + 1; i < this.config.maxSamples; i++) {
      if (this.state.samples.has(i)) {
        this.state.samples.set(i - 1, this.state.samples.get(i));
        this.state.samples.delete(i);
        const nextNode = this.ui.sampleNodes[i];
        const prevNode = this.ui.sampleNodes[i - 1];
        prevNode.classList.add('loaded');
        nextNode.classList.remove('loaded');
      }
    }
    this.state.nextSampleSlot = Math.max(0, this.state.nextSampleSlot - 1);
    this.updateSamplesUI();
    this.showNotification(`Sample ${slot + 1} cleared`, 1500);
    if (navigator.vibrate) navigator.vibrate([100, 50, 100]);
  }
  initializeMusicalAI() {
    this.musicalAI.beatPrediction = new Array(16).fill(0.5);
    this.musicalAI.melodicContext = [];
    // Harmonic tension starts low
    this.musicalAI.harmonicTension = 0;
    this.musicalAI.rhythmicDensity = 0.5;
  }
  scheduleNotes() {
    if (!this.audioContext || !this.state.aiDjActive) return;
    while (this.state.nextNoteTime < this.audioContext.currentTime + this.config.scheduleAheadTime) {
      const beatInBar = this.state.currentBeat % 4;
      const pattern = this.config.rhythmPatterns[this.state.currentState] || [1, 0, 0.5, 0];
      const probability = pattern[beatInBar] * this.state.complexity * this.state.energy;
      if (Math.random() < probability) {
        this.generateAINote(this.state.currentBeat % 16);
      }
      this.state.nextNoteTime += 60 / this.state.bpm / 4; // 16th notes
      this.state.currentBeat = (this.state.currentBeat + 1) % 16;
    }
  }
  generateAINote(beat) {
    const scaleDegree = this.config.scaleNotes[Math.floor(Math.random() * this.config.scaleNotes.length)];
    const octave = 3 + Math.floor(this.state.energy * 2);
    const freq = this.config.rootNote * Math.pow(2, (scaleDegree + octave * 12) / 12);
    const velocity = 0.2 + this.state.energy * 0.8;
    // Choose synth based on state
    const synthType = this.state.currentState === 'rhythmic' ? 'bass' :
                      this.state.currentState === 'elevated' ? 'lead' :
                      this.state.currentState === 'chaos' ? 'pad' : 'lead';
    this.synthesizers[synthType].noteOn(freq, velocity, this.audioContext.currentTime);
    // Drum on beats
    if (beat % 4 === 0) {
      this.playDrum('kick', velocity);
    } else if (beat % 4 === 2) {
      this.playDrum('snare', velocity * 0.8);
    } else if (Math.random() < 0.3) {
      this.playDrum('hihat', velocity * 0.4);
    }
    // Update AI context
    this.musicalAI.harmonicTension = (this.musicalAI.harmonicTension * 0.9) + (Math.random() * 0.1);
    this.state.noteQueue.push({ freq, velocity, time: this.audioContext.currentTime });
    if (this.state.noteQueue.length > 32) this.state.noteQueue.shift();
  }
  playDrum(type, velocity = 1) {
    const buffer = this.drumSounds[type];
    if (!buffer) return;
    const source = this.audioContext.createBufferSource();
    source.buffer = buffer;
    const gain = this.audioContext.createGain();
    gain.gain.value = velocity;
    source.connect(gain);
    gain.connect(this.audioNodes.drumBus);
    source.start();
  }
  showNotification(text, duration = 3000) {
    const notif = this.ui.notification;
    notif.textContent = text;
    notif.classList.add('visible');
    setTimeout(() => notif.classList.remove('visible'), duration);
  }
  createTouchRipple(e) {
    if (!e.clientX) return;
    const ripple = document.createElement('div');
    ripple.className = 'touch-ripple';
    ripple.style.left = `${e.clientX - 20}px`;
    ripple.style.top = `${e.clientY - 20}px`;
    document.body.appendChild(ripple);
    setTimeout(() => ripple.remove(), 600);
  }
  initWithoutPermissions() {
    console.log('ðŸ›¡ï¸ Starting in minimal mode (no mic/motion)');
    this.state.hasMicrophone = false;
    this.state.hasMotionSensors = false;
    // Generate some demo samples
    for (let i = 0; i < 3; i++) {
      const buffer = this.audioContext.createBuffer(1, this.audioContext.sampleRate * 1, this.audioContext.sampleRate);
      const data = buffer.getChannelData(0);
      for (let j = 0; j < data.length; j++) {
        data[j] = Math.random() * 0.1 - 0.05;
      }
      this.state.samples.set(i, buffer);
      this.ui.sampleNodes[i].classList.add('loaded');
    }
    this.state.nextSampleSlot = 3;
    this.updateSamplesUI();
    this.startJourney();
    this.showNotification('Minimal mode active - tap samples to play', 4000);
  }
}

// Synthesizer classes
class BassSynthesizer {
  constructor(context, output) {
    this.context = context;
    this.output = output;
  }
  noteOn(freq, velocity, time) {
    const osc = this.context.createOscillator();
    osc.type = 'sawtooth';
    osc.frequency.setValueAtTime(freq / 2, time); // Sub-bass
    const gain = this.context.createGain();
    gain.gain.setValueAtTime(0, time);
    gain.gain.linearRampToValueAtTime(velocity * 0.4, time + 0.01);
    gain.gain.exponentialRampToValueAtTime(0.001, time + 1.5);
    osc.connect(gain);
    gain.connect(this.output);
    osc.start(time);
    osc.stop(time + 1.5);
  }
}
class LeadSynthesizer {
  constructor(context, output) {
    this.context = context;
    this.output = output;
  }
  noteOn(freq, velocity, time) {
    const osc1 = this.context.createOscillator();
    osc1.type = 'square';
    osc1.frequency.value = freq;
    const osc2 = this.context.createOscillator();
    osc2.type = 'sawtooth';
    osc2.frequency.value = freq * 1.01; // Detune
    const merger = this.context.createChannelMerger(2);
    osc1.connect(merger, 0, 0);
    osc2.connect(merger, 0, 1);
    const gain = this.context.createGain();
    gain.gain.setValueAtTime(0, time);
    gain.gain.linearRampToValueAtTime(velocity * 0.3, time + 0.01);
    gain.gain.exponentialRampToValueAtTime(0.001, time + 2);
    merger.connect(gain);
    gain.connect(this.output);
    osc1.start(time);
    osc2.start(time);
    osc1.stop(time + 2);
    osc2.stop(time + 2);
  }
}
class PadSynthesizer {
  constructor(context, output) {
    this.context = context;
    this.output = output;
  }
  noteOn(freq, velocity, time) {
    const osc = this.context.createOscillator();
    osc.type = 'triangle';
    osc.frequency.value = freq;
    const gain = this.context.createGain();
    gain.gain.setValueAtTime(0, time);
    gain.gain.linearRampToValueAtTime(velocity * 0.2, time + 1);
    gain.gain.exponentialRampToValueAtTime(0.001, time + 10);
    osc.connect(gain);
    gain.connect(this.output);
    osc.start(time);
    osc.stop(time + 10);
  }
}
class PercussionSynthesizer {
  constructor(context, output, engine) {
    this.context = context;
    this.output = output;
    this.engine = engine; // Reference to engine for drumSounds
  }
  noteOn(type, velocity, time) {
    const buffer = this.engine.drumSounds[type];
    if (!buffer) return;
    const source = this.context.createBufferSource();
    source.buffer = buffer;
    const gain = this.context.createGain();
    gain.gain.value = velocity;
    source.connect(gain);
    gain.connect(this.output);
    source.start(time);
  }
}

// Instantiate the engine
const engine = new BreakthroughNeuromancerEngine();
</script>
</body>
</html>
